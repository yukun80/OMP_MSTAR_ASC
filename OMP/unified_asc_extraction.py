"""
Unified ASC Extraction Algorithm - åŸºäºæ–¹æ¡ˆä¸€é‡æ„
===============================================

è¿™ä¸ªè„šæœ¬å®ç°äº†åŸºäºdoc/next_work_goal.mdæ–¹æ¡ˆä¸€çš„ç»Ÿä¸€ASCæå–ç®—æ³•ï¼š
- æŠ›å¼ƒæœ‰ç¼ºé™·çš„ä¸¤é˜¶æ®µæ¶æ„
- ä½¿ç”¨åŒ…å«æ‰€æœ‰alphaå€¼çš„å…¨å‚æ•°å­—å…¸è¿›è¡Œå•é˜¶æ®µè¿­ä»£å¼"åŒ¹é…-ä¼˜åŒ–-å‡å»"
- ç›´æ¥è°ƒç”¨asc_extraction_fixed_v2.pyä¸­å·²å®ç°çš„æ ¸å¿ƒç®—æ³•

æ ¸å¿ƒç†å¿µï¼šè®©ç®—æ³•åœ¨æ¯ä¸€æ­¥éƒ½èƒ½ä½¿ç”¨æœ€åŒ¹é…çš„ç‰©ç†æ¨¡å‹ï¼Œé¿å…æ¨¡å‹å¤±é…é—®é¢˜ã€‚
"""

import numpy as np
import matplotlib.pyplot as plt
from typing import List, Dict, Tuple
import time
import os

from asc_extraction_fixed_v2 import ASCExtractionFixedV2, verify_coordinate_system, visualize_extraction_results
from demo_high_precision import find_best_mstar_file


class UnifiedASCExtractor:
    """
    ç»Ÿä¸€ASCæå–å™¨ - å®ç°æ–¹æ¡ˆä¸€çš„å•é˜¶æ®µå…¨å‚æ•°æå–ç­–ç•¥
    """

    def __init__(
        self,
        image_size: Tuple[int, int] = (128, 128),
        max_scatterers: int = 20,
        adaptive_threshold: float = 0.05,
        max_iterations: int = 30,
        position_samples: int = 32,
        target_focused: bool = True,
    ):
        """
        åˆå§‹åŒ–ç»Ÿä¸€æå–å™¨

        Args:
            image_size: å›¾åƒå°ºå¯¸
            max_scatterers: æœ€å¤§æ•£å°„ä¸­å¿ƒæ•°
            adaptive_threshold: è‡ªé€‚åº”åœæ­¢é˜ˆå€¼ (èƒ½é‡æ¯”ä¾‹)
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            position_samples: ä½ç½®é‡‡æ ·å¯†åº¦
            target_focused: æ˜¯å¦å¯ç”¨ç›®æ ‡å¯¼å‘æ¨¡å¼
        """
        self.image_size = image_size
        self.max_scatterers = max_scatterers
        self.adaptive_threshold = adaptive_threshold
        self.max_iterations = max_iterations
        self.position_samples = position_samples
        self.target_focused = target_focused

        print(f"ğŸš€ ç»Ÿä¸€ASCæå–å™¨åˆå§‹åŒ–")
        print(f"   ç®—æ³•ç­–ç•¥: å•é˜¶æ®µå…¨å‚æ•°è¿­ä»£æå–")
        print(f"   ä½ç½®é‡‡æ ·: {position_samples}Ã—{position_samples}")
        print(f"   ç›®æ ‡å¯¼å‘: {'å¯ç”¨' if target_focused else 'ç¦ç”¨'}")

    def create_core_extractor(self) -> ASCExtractionFixedV2:
        """
        åˆ›å»ºæ ¸å¿ƒæå–å™¨å®ä¾‹ - å…³é”®ï¼šä½¿ç”¨å…¨å‚æ•°å­—å…¸
        """
        if self.target_focused:
            # ç›®æ ‡å¯¼å‘æ¨¡å¼ï¼šæ›´å¯†é›†çš„ä½ç½®é‡‡æ ·ï¼Œé€‚åº¦çš„å‚æ•°èŒƒå›´
            return ASCExtractionFixedV2(
                image_size=self.image_size,
                extraction_mode="progressive",  # ç¡®ä¿ä½¿ç”¨å…¨å‚æ•°å­—å…¸
                adaptive_threshold=self.adaptive_threshold,
                max_iterations=self.max_iterations,
                max_scatterers=self.max_scatterers,
                # ä¼˜åŒ–çš„å‚æ•°é…ç½®
                alpha_values=[-1.0, -0.5, 0.0, 0.5, 1.0],  # åŒ…å«æ‰€æœ‰ä¸»è¦æ•£å°„ç±»å‹
                length_values=[0.0, 0.1, 0.5],  # é€‚é‡çš„é•¿åº¦å‚æ•°
                phi_bar_values=[0.0, np.pi / 4, np.pi / 2],  # ä¸»è¦æ–¹å‘è§’
                position_samples=self.position_samples,
            )
        else:
            # æ ‡å‡†æ¨¡å¼ï¼šä½¿ç”¨é»˜è®¤çš„æ¸è¿›å¼é…ç½®
            return ASCExtractionFixedV2(
                image_size=self.image_size,
                extraction_mode="progressive",
                adaptive_threshold=self.adaptive_threshold,
                max_iterations=self.max_iterations,
                max_scatterers=self.max_scatterers,
                position_samples=self.position_samples,
            )

    def extract_scatterers(self, complex_image: np.ndarray) -> List[Dict]:
        """
        æ‰§è¡Œç»Ÿä¸€çš„ASCæ•£å°„ä¸­å¿ƒæå–

        Args:
            complex_image: å¤æ•°SARå›¾åƒ

        Returns:
            æå–åˆ°çš„æ•£å°„ä¸­å¿ƒåˆ—è¡¨
        """
        print("\n" + "=" * 70)
        print("ğŸ¯ ç»Ÿä¸€ASCæå– - å•é˜¶æ®µå…¨å‚æ•°ç­–ç•¥")
        print("=" * 70)

        # 1. åˆ›å»ºæ ¸å¿ƒæå–å™¨ (å…³é”®ï¼šä½¿ç”¨å…¨å‚æ•°å­—å…¸)
        print("\nğŸ”§ åˆå§‹åŒ–æ ¸å¿ƒæå–å™¨...")
        core_extractor = self.create_core_extractor()

        # 2. åæ ‡ç³»éªŒè¯
        print("\nğŸ” éªŒè¯åæ ‡ç³»ä¿®å¤...")
        if not verify_coordinate_system(core_extractor):
            print("âŒ åæ ‡ç³»éªŒè¯å¤±è´¥ï¼Œç®—æ³•å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
            return []
        print("âœ… åæ ‡ç³»éªŒè¯é€šè¿‡")

        # 3. æ‰§è¡Œæ ¸å¿ƒæå–ç®—æ³• (ç›´æ¥ä½¿ç”¨å·²ç»å®ç°çš„å®Œæ•´ç®—æ³•)
        print("\nğŸš€ å¼€å§‹å•é˜¶æ®µå…¨å‚æ•°æå–...")
        print("   ç­–ç•¥: è¿­ä»£å¼'åŒ¹é…-ä¼˜åŒ–-å‡å»'å¾ªç¯")
        print("   å­—å…¸: åŒ…å«æ‰€æœ‰alphaå€¼çš„å…¨å‚æ•°åŸå­")

        start_time = time.time()
        scatterers = core_extractor.extract_asc_scatterers_v2(complex_image)
        extraction_time = time.time() - start_time

        # 4. ç»“æœåˆ†æ
        print(f"\nğŸ“Š æå–å®Œæˆ (è€—æ—¶: {extraction_time:.2f}s)")

        if not scatterers:
            print("âŒ æœªæå–åˆ°ä»»ä½•æ•£å°„ä¸­å¿ƒ")
            return []

        # æŒ‰å¹…åº¦æ’åº
        scatterers.sort(key=lambda s: s["estimated_amplitude"], reverse=True)

        # è¯¦ç»†åˆ†æ
        self._analyze_extraction_results(scatterers)

        return scatterers

    def _analyze_extraction_results(self, scatterers: List[Dict]):
        """
        è¯¦ç»†åˆ†ææå–ç»“æœçš„è´¨é‡å’Œåˆ†å¸ƒ
        """
        print(f"\nğŸ“ˆ æå–ç»“æœè¯¦ç»†åˆ†æ:")
        print(f"   æ•£å°„ä¸­å¿ƒæ€»æ•°: {len(scatterers)}")

        # æ•£å°„ç±»å‹åˆ†å¸ƒ
        type_dist = {}
        alpha_dist = {}
        opt_success_count = 0

        for sc in scatterers:
            stype = sc["scattering_type"]
            alpha = sc["alpha"]
            type_dist[stype] = type_dist.get(stype, 0) + 1
            alpha_dist[alpha] = alpha_dist.get(alpha, 0) + 1
            if sc.get("optimization_success", False):
                opt_success_count += 1

        print(f"   æ•£å°„ç±»å‹åˆ†å¸ƒ: {type_dist}")
        print(f"   Î±å‚æ•°åˆ†å¸ƒ: {alpha_dist}")
        print(f"   ä¼˜åŒ–æˆåŠŸç‡: {opt_success_count}/{len(scatterers)} ({opt_success_count/len(scatterers)*100:.1f}%)")

        # ä½ç½®åˆ†å¸ƒåˆ†æ
        positions = [(sc["x"], sc["y"]) for sc in scatterers]
        x_coords = [pos[0] for pos in positions]
        y_coords = [pos[1] for pos in positions]

        x_center, y_center = np.mean(x_coords), np.mean(y_coords)
        x_std, y_std = np.std(x_coords), np.std(y_coords)

        print(f"   ä½ç½®ä¸­å¿ƒ: ({x_center:.3f}, {y_center:.3f})")
        print(f"   ä½ç½®æ ‡å‡†å·®: X={x_std:.3f}, Y={y_std:.3f}")

        # å¹…åº¦åˆ†æ
        amplitudes = [sc["estimated_amplitude"] for sc in scatterers]
        print(f"   å¹…åº¦èŒƒå›´: {np.min(amplitudes):.3f} - {np.max(amplitudes):.3f}")
        print(f"   å¹³å‡å¹…åº¦: {np.mean(amplitudes):.3f}")

        # è´¨é‡è¯„ä¼°
        self._assess_extraction_quality(scatterers, x_std, y_std, opt_success_count)

    def _assess_extraction_quality(self, scatterers: List[Dict], x_std: float, y_std: float, opt_success_count: int):
        """
        è¯„ä¼°æå–è´¨é‡
        """
        print(f"\nğŸ† è´¨é‡è¯„ä¼°:")

        quality_score = 0

        # 1. æ•°é‡åˆç†æ€§ (10-25ä¸ªä¸ºä¼˜ç§€)
        num_scatterers = len(scatterers)
        if 10 <= num_scatterers <= 25:
            quality_score += 25
            print(f"   âœ… æ•£å°„ä¸­å¿ƒæ•°é‡ä¼˜ç§€ ({num_scatterers}) +25åˆ†")
        elif 5 <= num_scatterers <= 35:
            quality_score += 15
            print(f"   âš ï¸ æ•£å°„ä¸­å¿ƒæ•°é‡åˆç† ({num_scatterers}) +15åˆ†")
        else:
            print(f"   âŒ æ•£å°„ä¸­å¿ƒæ•°é‡å¼‚å¸¸ ({num_scatterers})")

        # 2. ç©ºé—´é›†ä¸­åº¦ (æ ‡å‡†å·® < 0.3ä¸ºä¼˜ç§€)
        spatial_score = 0
        if x_std < 0.25 and y_std < 0.25:
            spatial_score = 25
            print(f"   âœ… ç©ºé—´é›†ä¸­åº¦ä¼˜ç§€ (X:{x_std:.3f}, Y:{y_std:.3f}) +25åˆ†")
        elif x_std < 0.4 and y_std < 0.4:
            spatial_score = 15
            print(f"   âš ï¸ ç©ºé—´é›†ä¸­åº¦è‰¯å¥½ (X:{x_std:.3f}, Y:{y_std:.3f}) +15åˆ†")
        else:
            print(f"   âŒ ç©ºé—´åˆ†å¸ƒè¿‡äºåˆ†æ•£ (X:{x_std:.3f}, Y:{y_std:.3f})")
        quality_score += spatial_score

        # 3. ä¼˜åŒ–æˆåŠŸç‡
        opt_rate = opt_success_count / len(scatterers) if scatterers else 0
        if opt_rate > 0.8:
            quality_score += 30
            print(f"   âœ… ä¼˜åŒ–æˆåŠŸç‡ä¼˜ç§€ ({opt_rate:.1%}) +30åˆ†")
        elif opt_rate > 0.6:
            quality_score += 20
            print(f"   âš ï¸ ä¼˜åŒ–æˆåŠŸç‡è‰¯å¥½ ({opt_rate:.1%}) +20åˆ†")
        else:
            print(f"   âŒ ä¼˜åŒ–æˆåŠŸç‡åä½ ({opt_rate:.1%})")

        # 4. ç‰©ç†åˆç†æ€§ (å¼ºæ•£å°„ç±»å‹å æ¯”)
        strong_scattering_count = sum(1 for sc in scatterers if sc["alpha"] in [-1.0, -0.5])
        strong_ratio = strong_scattering_count / len(scatterers) if scatterers else 0
        if strong_ratio > 0.5:
            quality_score += 20
            print(f"   âœ… å¼ºæ•£å°„ç±»å‹å æ¯”åˆç† ({strong_ratio:.1%}) +20åˆ†")
        elif strong_ratio > 0.3:
            quality_score += 10
            print(f"   âš ï¸ å¼ºæ•£å°„ç±»å‹å æ¯”ä¸€èˆ¬ ({strong_ratio:.1%}) +10åˆ†")
        else:
            print(f"   âŒ å¼ºæ•£å°„ç±»å‹å æ¯”åä½ ({strong_ratio:.1%})")

        print(f"\nğŸ–ï¸ æ€»ä½“è´¨é‡è¯„åˆ†: {quality_score}/100")

        if quality_score >= 80:
            print("   âœ… ç®—æ³•é‡æ„æˆåŠŸï¼æ•£å°„ä¸­å¿ƒæå–è´¨é‡ä¼˜ç§€")
            return "ä¼˜ç§€"
        elif quality_score >= 60:
            print("   âš ï¸ ç®—æ³•åŸºæœ¬æˆåŠŸï¼Œæ•£å°„ä¸­å¿ƒæå–è´¨é‡è‰¯å¥½")
            return "è‰¯å¥½"
        else:
            print("   âŒ ç®—æ³•ä»éœ€æ”¹è¿›ï¼Œæ•£å°„ä¸­å¿ƒæå–è´¨é‡ä¸ä½³")
            return "éœ€æ”¹è¿›"


def main():
    """
    ä¸»è¿è¡Œå‡½æ•° - ç»Ÿä¸€ASCæå–ç®—æ³•æ¼”ç¤º
    """
    print("ğŸ¯ ç»Ÿä¸€ASCæå–ç®—æ³• - åŸºäºæ–¹æ¡ˆä¸€é‡æ„")
    print("=" * 70)
    print("æ ¸å¿ƒæ”¹è¿›ï¼š")
    print("  âŒ ç§»é™¤æœ‰ç¼ºé™·çš„ä¸¤é˜¶æ®µæ¶æ„")
    print("  âœ… ä½¿ç”¨å…¨å‚æ•°å­—å…¸çš„å•é˜¶æ®µè¿­ä»£æå–")
    print("  âœ… é¿å…æ¨¡å‹å¤±é…é—®é¢˜")
    print("=" * 70)

    # 1. æ•°æ®å‡†å¤‡
    mstar_file = find_best_mstar_file()
    if not mstar_file:
        print("âŒ æ— æ³•æ‰¾åˆ°MSTARæ•°æ®æ–‡ä»¶")
        return

    print(f"ğŸ“‚ ä½¿ç”¨æ•°æ®æ–‡ä»¶: {mstar_file}")

    # 2. åˆ›å»ºç»Ÿä¸€æå–å™¨
    extractor = UnifiedASCExtractor(
        image_size=(128, 128),
        max_scatterers=20,
        adaptive_threshold=0.05,  # 5% çš„ä¸¥æ ¼é˜ˆå€¼
        position_samples=32,  # å¹³è¡¡ç²¾åº¦å’Œè®¡ç®—æ•ˆç‡
        target_focused=True,  # å¯ç”¨ç›®æ ‡å¯¼å‘æ¨¡å¼
    )

    # 3. åŠ è½½æ•°æ®
    print("\nğŸ“Š åŠ è½½MSTARæ•°æ®...")
    core_extractor = extractor.create_core_extractor()
    try:
        magnitude, complex_image = core_extractor.load_mstar_data_robust(mstar_file)
        print("âœ… æ•°æ®åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return

    # 4. æ‰§è¡Œæå–
    scatterers = extractor.extract_scatterers(complex_image)

    # 5. å¯è§†åŒ–ç»“æœ
    if scatterers:
        print("\nğŸ¨ ç”Ÿæˆæå–ç»“æœå¯è§†åŒ–...")
        visualize_extraction_results(complex_image, scatterers, save_path="unified_extraction_result.png")
        print("âœ… ç»“æœå·²ä¿å­˜åˆ°: unified_extraction_result.png")
    else:
        print("âŒ æœªæå–åˆ°æ•£å°„ä¸­å¿ƒï¼Œæ— æ³•å¯è§†åŒ–")

    print(f"\nğŸ‰ ç»Ÿä¸€ASCæå–ç®—æ³•è¿è¡Œå®Œæˆ")


if __name__ == "__main__":
    main()
