#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Advanced Attribute Scattering Center (ASC) Extraction System
é«˜çº§å±æ€§æ•£å°„ä¸­å¿ƒæå–ç³»ç»Ÿ

åŸºäºç‰©ç†ç²¾ç¡®æ¨¡å‹çš„è‡ªé€‚åº”ASCå‚æ•°æå–ç®—æ³•
æ”¯æŒå®Œæ•´çš„ASCå‚æ•°: {A, Î±, x, y, L, Ï†_bar}

Reference:
- ASC Model: AÂ·f^Î±Â·sinc(LÂ·fÂ·sin(Î¸))Â·exp(jÂ·Ï†_bar)
- Adaptive extraction similar to CLEAN algorithm
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize
from sklearn.linear_model import OrthogonalMatchingPursuit
from scipy.io import loadmat
import struct
from typing import Tuple, List, Dict, Optional
import warnings
import time

warnings.filterwarnings("ignore")


class ASCExtractionAdvanced:
    """
    é«˜çº§å±æ€§æ•£å°„ä¸­å¿ƒæå–ç³»ç»Ÿ

    æ ¸å¿ƒç‰¹æ€§:
    1. å®Œæ•´çš„ASCç‰©ç†æ¨¡å‹: AÂ·f^Î±Â·sinc(LÂ·fÂ·sin(Î¸))Â·exp(jÂ·Ï†_bar)
    2. è‡ªé€‚åº”è¿­ä»£æå– (ç±»ä¼¼CLEANç®—æ³•)
    3. å¤šå‚æ•°å­—å…¸: åŒ…å«ä¸åŒÎ±å€¼å’ŒLå€¼çš„å¤åˆå­—å…¸
    4. åå¤„ç†ä¼˜åŒ–: ç²¾ç¡®ä¼°è®¡è¿ç»­å‚æ•°
    """

    def __init__(
        self,
        image_size: Tuple[int, int] = (128, 128),
        adaptive_threshold: float = 0.01,
        max_iterations: int = 100,
        min_scatterers: int = 5,
        max_scatterers: int = 80,
        precision_mode: str = "balanced",  # æ–°å¢ç²¾åº¦æ¨¡å¼å‚æ•°
    ):
        """
        åˆå§‹åŒ–ASCæå–ç³»ç»Ÿ

        Args:
            image_size: SARå›¾åƒå°ºå¯¸
            adaptive_threshold: è‡ªé€‚åº”åœæ­¢é˜ˆå€¼ (ç›¸å¯¹äºæœ€å¤§å€¼)
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            min_scatterers: æœ€å°‘æ•£å°„ä¸­å¿ƒæ•°
            max_scatterers: æœ€å¤šæ•£å°„ä¸­å¿ƒæ•°
            precision_mode: ç²¾åº¦æ¨¡å¼
                - "fast": å¿«é€Ÿæ¨¡å¼ (16Ã—16ä½ç½®é‡‡æ ·)
                - "balanced": å¹³è¡¡æ¨¡å¼ (32Ã—32ä½ç½®é‡‡æ · + ç²¾åŒ–)
                - "high": é«˜ç²¾åº¦æ¨¡å¼ (48Ã—48ä½ç½®é‡‡æ · + å¤šæ­¥ç²¾åŒ–)
                - "ultra": è¶…é«˜ç²¾åº¦æ¨¡å¼ (64Ã—64ä½ç½®é‡‡æ · + å…¨å±€ä¼˜åŒ–)
        """
        self.image_size = image_size
        self.adaptive_threshold = adaptive_threshold
        self.max_iterations = max_iterations
        self.min_scatterers = min_scatterers
        self.max_scatterers = max_scatterers
        self.precision_mode = precision_mode

        # SARç³»ç»Ÿå‚æ•°
        self.fc = 1e10  # ä¸­å¿ƒé¢‘ç‡ 10GHz
        self.B = 1e9  # å¸¦å®½ 1GHz
        self.omega = np.pi / 3  # åˆæˆå­”å¾„è§’

        # ASCæ¨¡å‹å‚æ•°èŒƒå›´
        self.alpha_values = [-1.0, -0.5, 0.0, 0.5, 1.0]  # é¢‘ç‡ä¾èµ–å› å­
        self.length_values = np.logspace(-2, 0, 5)  # é•¿åº¦å‚æ•° [0.01, 1.0]

        # æ ¹æ®ç²¾åº¦æ¨¡å¼é…ç½®å‚æ•°
        self._configure_precision_settings()

        print(f"ğŸ¯ é«˜çº§ASCæå–ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"   ç²¾åº¦æ¨¡å¼: {precision_mode}")
        print(f"   è‡ªé€‚åº”é˜ˆå€¼: {adaptive_threshold}")
        print(f"   è¿­ä»£èŒƒå›´: {min_scatterers}-{max_scatterers} ä¸ªæ•£å°„ä¸­å¿ƒ")
        print(f"   é¢„ä¼°ä½ç½®é‡‡æ ·: {self.position_samples}Ã—{self.position_samples}")
        print(f"   æ–¹ä½è§’é‡‡æ ·: {self.azimuth_samples}")

    def _configure_precision_settings(self):
        """æ ¹æ®ç²¾åº¦æ¨¡å¼é…ç½®é‡‡æ ·å‚æ•°"""
        if self.precision_mode == "fast":
            self.position_samples = 16
            self.azimuth_samples = 4
            self.enable_refinement = False
            self.use_progressive_sampling = False
        elif self.precision_mode == "balanced":
            self.position_samples = 32
            self.azimuth_samples = 8
            self.enable_refinement = True
            self.use_progressive_sampling = True
            self.refinement_iterations = 2
        elif self.precision_mode == "high":
            self.position_samples = 48
            self.azimuth_samples = 12
            self.enable_refinement = True
            self.use_progressive_sampling = True
            self.refinement_iterations = 3
        elif self.precision_mode == "ultra":
            self.position_samples = 64
            self.azimuth_samples = 16
            self.enable_refinement = True
            self.use_progressive_sampling = True
            self.refinement_iterations = 5
        else:
            # é»˜è®¤è®¾ç½®
            self.position_samples = 32
            self.azimuth_samples = 8
            self.enable_refinement = True
            self.use_progressive_sampling = False

    def load_raw_data(self, raw_file_path: str) -> Tuple[np.ndarray, np.ndarray]:
        """åŠ è½½RAWæ ¼å¼SARæ•°æ®"""
        print(f"ğŸ“‚ åŠ è½½RAWæ•°æ®: {raw_file_path}")

        with open(raw_file_path, "rb") as f:
            data = f.read()

        # è§£æå¤å€¼æ•°æ® (å®éƒ¨+è™šéƒ¨ï¼Œfloat32ï¼Œå°ç«¯åº)
        num_values = len(data) // 4
        real_imag = struct.unpack(f"<{num_values}f", data)

        # é‡æ„å¤å€¼å›¾åƒ
        complex_values = []
        for i in range(0, len(real_imag), 2):
            complex_values.append(complex(real_imag[i], real_imag[i + 1]))

        complex_image = np.array(complex_values).reshape(self.image_size)
        magnitude = np.abs(complex_image)

        print(f"   å›¾åƒå°ºå¯¸: {complex_image.shape}")
        print(f"   æ•°æ®èŒƒå›´: [{np.min(magnitude):.3f}, {np.max(magnitude):.3f}]")

        return magnitude, complex_image

    def preprocess_data(self, complex_image: np.ndarray) -> np.ndarray:
        """æ•°æ®é¢„å¤„ç†å’Œå½’ä¸€åŒ–"""
        print("âš™ï¸ æ•°æ®é¢„å¤„ç†...")

        # è½¬æ¢ä¸ºå‘é‡å½¢å¼
        signal = complex_image.flatten()

        # å½’ä¸€åŒ– (ä¿æŒç›¸ä½ä¿¡æ¯)
        max_magnitude = np.max(np.abs(signal))
        signal_normalized = signal / max_magnitude

        print(f"   ä¿¡å·é•¿åº¦: {len(signal)}")
        print(f"   å½’ä¸€åŒ–å› å­: {max_magnitude:.3f}")

        return signal_normalized

    def _generate_asc_atom(
        self,
        x: float,
        y: float,
        alpha: float,
        length: float,
        phi_bar: float,
        fx_range: np.ndarray,
        fy_range: np.ndarray,
    ) -> np.ndarray:
        """
        ç”ŸæˆASCå­—å…¸åŸå­

        ASCæ¨¡å‹: AÂ·f^Î±Â·sinc(LÂ·fÂ·sin(Î¸))Â·exp(jÂ·Ï†_bar)

        Args:
            x, y: æ•£å°„ä¸­å¿ƒä½ç½® (å½’ä¸€åŒ–)
            alpha: é¢‘ç‡ä¾èµ–å› å­
            length: æ•£å°„é•¿åº¦å‚æ•°
            phi_bar: æ–¹ä½è§’
            fx_range, fy_range: é¢‘ç‡é‡‡æ ·èŒƒå›´

        Returns:
            å¤å€¼åŸå­ (ç©ºåŸŸ)
        """
        # åˆ›å»ºé¢‘ç‡ç½‘æ ¼
        FX, FY = np.meshgrid(fx_range, fy_range, indexing="ij")

        # è®¡ç®—é¢‘ç‡å¹…åº¦å’Œè§’åº¦
        f_magnitude = np.sqrt(FX**2 + FY**2)
        theta = np.arctan2(FY, FX)

        # ASCé¢‘åŸŸå“åº”
        # 1. ä½ç½®ç›¸ä½é¡¹
        position_phase = -2j * np.pi * (FX * x + FY * y)

        # 2. é¢‘ç‡ä¾èµ–é¡¹: f^Î±
        frequency_term = np.power(f_magnitude + 1e-10, alpha)

        # 3. é•¿åº¦ç›¸å…³é¡¹: sinc(LÂ·fÂ·sin(Î¸-Ï†_bar))
        angle_diff = theta - phi_bar
        sinc_arg = length * f_magnitude * np.sin(angle_diff)
        length_term = np.sinc(sinc_arg / np.pi)  # numpy sinc = sin(Ï€x)/(Ï€x)

        # 4. æ–¹ä½è§’ç›¸ä½é¡¹
        azimuth_phase = 1j * phi_bar

        # ç»„åˆASCé¢‘åŸŸå“åº”
        H_asc = frequency_term * length_term * np.exp(position_phase + azimuth_phase)

        # ç©ºåŸŸåŸå­ (IFFT)
        atom = np.fft.ifft2(np.fft.ifftshift(H_asc))

        return atom

    def build_asc_dictionary(
        self, position_samples: int = None, azimuth_samples: int = None
    ) -> Tuple[np.ndarray, List[Dict]]:
        """
        æ„å»ºå®Œæ•´çš„ASCå¤åˆå­—å…¸ (æ”¯æŒé«˜ç²¾åº¦æ¨¡å¼)

        ä½¿ç”¨æ¸è¿›å¼é‡‡æ ·ç­–ç•¥ï¼šå…ˆç²—ç½‘æ ¼å¿«é€Ÿå®šä½ï¼Œå†ç»†ç½‘æ ¼ç²¾ç¡®ä¼°è®¡
        """
        # ä½¿ç”¨é…ç½®çš„ç²¾åº¦å‚æ•°
        if position_samples is None:
            position_samples = self.position_samples
        if azimuth_samples is None:
            azimuth_samples = self.azimuth_samples

        print(f"ğŸ“š æ„å»ºASCå¤åˆå­—å…¸ (ç²¾åº¦æ¨¡å¼: {self.precision_mode})...")

        # é¢‘ç‡é‡‡æ ·èŒƒå›´
        fx_range = np.linspace(-self.B / 2, self.B / 2, self.image_size[0])
        fy_range = np.linspace(-self.fc * np.sin(self.omega / 2), self.fc * np.sin(self.omega / 2), self.image_size[1])

        # é«˜ç²¾åº¦å‚æ•°é‡‡æ ·
        x_positions = np.linspace(-0.9, 0.9, position_samples)  # é¿å…è¾¹ç•Œæ•ˆåº”
        y_positions = np.linspace(-0.9, 0.9, position_samples)
        phi_bar_values = np.linspace(0, 2 * np.pi, azimuth_samples, endpoint=False)

        # ä¼°ç®—å­—å…¸å¤§å°
        total_atoms = (
            len(x_positions) * len(y_positions) * len(self.alpha_values) * len(self.length_values) * len(phi_bar_values)
        )

        print(f"   ä½ç½®é‡‡æ ·: {position_samples}Ã—{position_samples}")
        print(f"   Î±é‡‡æ ·: {len(self.alpha_values)} ä¸ªå€¼")
        print(f"   Lé‡‡æ ·: {len(self.length_values)} ä¸ªå€¼")
        print(f"   Ï†_baré‡‡æ ·: {azimuth_samples} ä¸ªå€¼")
        print(f"   æ€»åŸå­æ•°: {total_atoms}")

        if total_atoms > 50000:
            print(f"âš ï¸ å­—å…¸è§„æ¨¡è¾ƒå¤§ï¼Œæ„å»ºå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")

        # æ„å»ºå­—å…¸
        dictionary_atoms = []
        param_grid = []

        atom_count = 0
        start_time = time.time()

        for i, x in enumerate(x_positions):
            for j, y in enumerate(y_positions):
                for alpha in self.alpha_values:
                    for length in self.length_values:
                        for phi_bar in phi_bar_values:
                            # ç”ŸæˆASCåŸå­
                            atom = self._generate_asc_atom(x, y, alpha, length, phi_bar, fx_range, fy_range)

                            # ç¨³å¥çš„å½’ä¸€åŒ–
                            atom_flat = atom.flatten()
                            atom_energy = np.linalg.norm(atom_flat)
                            if atom_energy > 1e-12:
                                atom_normalized = atom_flat / atom_energy
                            else:
                                # è·³è¿‡èƒ½é‡è¿‡ä½çš„åŸå­
                                continue

                            dictionary_atoms.append(atom_normalized)
                            param_grid.append(
                                {
                                    "x": x,
                                    "y": y,
                                    "alpha": alpha,
                                    "length": length,
                                    "phi_bar": phi_bar,
                                    "atom_energy": atom_energy,
                                    "grid_index": (i, j),  # è®°å½•ç½‘æ ¼ç´¢å¼•ç”¨äºåç»­ä¼˜åŒ–
                                }
                            )

                            atom_count += 1
                            if atom_count % 2000 == 0:
                                elapsed = time.time() - start_time
                                progress = atom_count / total_atoms * 100
                                print(f"   æ„å»ºè¿›åº¦: {atom_count}/{total_atoms} ({progress:.1f}%) - {elapsed:.1f}s")

        # è½¬æ¢ä¸ºçŸ©é˜µ
        dictionary = np.column_stack(dictionary_atoms)

        print(f"âœ… ASCå­—å…¸æ„å»ºå®Œæˆ")
        print(f"   å­—å…¸å°ºå¯¸: {dictionary.shape}")
        print(f"   å†…å­˜å ç”¨: ~{dictionary.nbytes / 1024**2:.1f} MB")
        print(f"   æ„å»ºæ—¶é—´: {time.time() - start_time:.1f}s")

        return dictionary, param_grid

    def adaptive_asc_extraction(self, signal: np.ndarray, dictionary: np.ndarray, param_grid: List[Dict]) -> List[Dict]:
        """
        è‡ªé€‚åº”ASCæå– (æ”¹è¿›ç‰ˆæœ¬ï¼Œæé«˜æ”¶æ•›æ€§)

        å…³é”®æ”¹è¿›ï¼š
        1. æ›´ä¸¥æ ¼çš„æ”¶æ•›åˆ¤æ–­
        2. æ”¹è¿›çš„æ®‹å·®æ›´æ–°æœºåˆ¶
        3. æ™ºèƒ½çš„åœæ­¢æ¡ä»¶
        """
        print(f"ğŸ¯ å¼€å§‹è‡ªé€‚åº”ASCæå– (ç²¾åº¦æ¨¡å¼: {self.precision_mode})...")

        residual_signal = signal.copy()
        extracted_scatterers = []

        # è®¡ç®—åˆå§‹ä¿¡å·ç‰¹å¾
        initial_energy = np.linalg.norm(residual_signal)
        initial_max_amplitude = np.max(np.abs(residual_signal))

        # æ™ºèƒ½é˜ˆå€¼è®¾ç½®
        energy_threshold = initial_energy * self.adaptive_threshold
        amplitude_threshold = initial_max_amplitude * 0.05  # 5%å¹…åº¦é˜ˆå€¼

        print(f"   åˆå§‹ä¿¡å·èƒ½é‡: {initial_energy:.6f}")
        print(f"   åˆå§‹æœ€å¤§å¹…åº¦: {initial_max_amplitude:.6f}")
        print(f"   èƒ½é‡åœæ­¢é˜ˆå€¼: {energy_threshold:.6f}")
        print(f"   å¹…åº¦åœæ­¢é˜ˆå€¼: {amplitude_threshold:.6f}")

        # æ”¶æ•›æ€§è·Ÿè¸ª
        convergence_history = []
        last_significant_improvement = 0

        for iteration in range(self.max_iterations):
            # å½“å‰æ®‹å·®ç‰¹å¾
            current_energy = np.linalg.norm(residual_signal)
            current_max_amplitude = np.max(np.abs(residual_signal))
            energy_reduction_ratio = (initial_energy - current_energy) / initial_energy

            convergence_history.append(
                {
                    "iteration": iteration,
                    "energy": current_energy,
                    "max_amplitude": current_max_amplitude,
                    "energy_reduction": energy_reduction_ratio,
                }
            )

            # å¤šé‡åœæ­¢æ¡ä»¶æ£€æŸ¥
            if current_energy < energy_threshold:
                print(f"   ğŸ’¡ è¾¾åˆ°èƒ½é‡é˜ˆå€¼ ({energy_reduction_ratio:.1%} å‡å°‘)ï¼Œåœæ­¢è¿­ä»£")
                break

            if current_max_amplitude < amplitude_threshold:
                print(f"   ğŸ’¡ è¾¾åˆ°å¹…åº¦é˜ˆå€¼ï¼Œåœæ­¢è¿­ä»£")
                break

            if len(extracted_scatterers) >= self.max_scatterers:
                print(f"   ğŸ’¡ è¾¾åˆ°æœ€å¤§æ•£å°„ä¸­å¿ƒæ•°ï¼Œåœæ­¢è¿­ä»£")
                break

            # æ£€æŸ¥æ”¶æ•›åœæ» (è¿ç»­5æ¬¡è¿­ä»£æ”¹è¿›å°äº0.1%)
            if len(convergence_history) >= 5:
                recent_improvements = []
                for i in range(-4, 0):
                    recent_improvements.append(
                        convergence_history[i]["energy_reduction"] - convergence_history[i - 1]["energy_reduction"]
                    )

                if max(recent_improvements) < 0.001:  # 0.1%æ”¹è¿›é˜ˆå€¼
                    print(f"   ğŸ’¡ æ”¶æ•›åœæ» (æ”¹è¿›<0.1%)ï¼Œåœæ­¢è¿­ä»£")
                    break

            # æ”¹è¿›çš„OMPåŒ¹é…
            residual_real = np.concatenate([residual_signal.real, residual_signal.imag])
            dictionary_real = np.concatenate([dictionary.real, dictionary.imag], axis=0)

            omp = OrthogonalMatchingPursuit(n_nonzero_coefs=1, fit_intercept=False)

            try:
                omp.fit(dictionary_real, residual_real)
                coefficients = omp.coef_
            except Exception as e:
                print(f"   âš ï¸ OMPæ‹Ÿåˆå¤±è´¥: {str(e)}")
                break

            # å¯»æ‰¾æœ€ä½³åŒ¹é…
            nonzero_indices = np.nonzero(coefficients)[0]
            if len(nonzero_indices) == 0:
                print(f"   ğŸ’¡ æœªæ‰¾åˆ°æ˜¾è‘—æ•£å°„ä¸­å¿ƒï¼Œåœæ­¢è¿­ä»£")
                break

            best_idx = nonzero_indices[0]
            best_params = param_grid[best_idx].copy()

            # æ”¹è¿›çš„å¤æ•°ç³»æ•°ä¼°è®¡
            selected_atom = dictionary[:, best_idx]

            # ä½¿ç”¨æœ€å°äºŒä¹˜æ³•è·å¾—æ›´å‡†ç¡®çš„å¤æ•°ç³»æ•°
            complex_coef = np.vdot(selected_atom, residual_signal) / np.vdot(selected_atom, selected_atom)

            # éªŒè¯ç³»æ•°è´¨é‡
            projected_energy = abs(complex_coef) ** 2 * np.linalg.norm(selected_atom) ** 2
            signal_energy = np.linalg.norm(residual_signal) ** 2
            energy_capture_ratio = projected_energy / signal_energy

            if energy_capture_ratio < 1e-6:
                print(f"   ğŸ’¡ èƒ½é‡æ•è·ç‡è¿‡ä½ ({energy_capture_ratio:.2e})ï¼Œåœæ­¢è¿­ä»£")
                break

            # æ›´ç¨³å¥çš„æ®‹å·®æ›´æ–°
            atom_contribution = complex_coef * selected_atom
            residual_signal = residual_signal - atom_contribution

            # è®°å½•æ•£å°„ä¸­å¿ƒ
            estimated_amplitude = np.abs(complex_coef) * best_params["atom_energy"]
            estimated_phase = np.angle(complex_coef)

            scatterer = {
                "iteration": iteration + 1,
                "x": best_params["x"],
                "y": best_params["y"],
                "alpha": best_params["alpha"],
                "length": best_params["length"],
                "phi_bar": best_params["phi_bar"],
                "estimated_amplitude": estimated_amplitude,
                "estimated_phase": estimated_phase,
                "coefficient": complex_coef,
                "energy_capture_ratio": energy_capture_ratio,
                "cumulative_energy_reduction": energy_reduction_ratio,
                "grid_index": best_params["grid_index"],
            }

            extracted_scatterers.append(scatterer)

            # æ™ºèƒ½è¿›åº¦æ˜¾ç¤º
            if iteration < 10 or (iteration + 1) % 5 == 0:
                print(
                    f"   è¿­ä»£ {iteration+1}: èƒ½é‡å‡å°‘ {energy_reduction_ratio:.1%}, "
                    f"æ•£å°„ä¸­å¿ƒæ•° {len(extracted_scatterers)}, "
                    f"æ•è·ç‡ {energy_capture_ratio:.2e}"
                )

        # æœ€ç»ˆç»Ÿè®¡
        final_energy = np.linalg.norm(residual_signal)
        total_energy_reduction = (initial_energy - final_energy) / initial_energy

        # æ£€æŸ¥æå–è´¨é‡
        if len(extracted_scatterers) < self.min_scatterers:
            print(f"   âš ï¸ æå–çš„æ•£å°„ä¸­å¿ƒæ•° ({len(extracted_scatterers)}) " f"å°‘äºæœ€å°‘è¦æ±‚ ({self.min_scatterers})")

        print(f"âœ… è‡ªé€‚åº”ASCæå–å®Œæˆ")
        print(f"   æ€»è¿­ä»£æ¬¡æ•°: {len(extracted_scatterers)}")
        print(f"   æ€»èƒ½é‡å‡å°‘: {total_energy_reduction:.1%}")
        print(f"   æœ€ç»ˆæ®‹å·®èƒ½é‡: {final_energy:.6f}")

        # è¯„ä¼°æå–è´¨é‡
        if total_energy_reduction > 0.5:  # 50%+
            print(f"   ğŸ¯ æå–è´¨é‡: ä¼˜ç§€")
        elif total_energy_reduction > 0.2:  # 20%+
            print(f"   ğŸ¯ æå–è´¨é‡: è‰¯å¥½")
        else:
            print(f"   âš ï¸ æå–è´¨é‡: éœ€è¦æ”¹è¿›")

        return extracted_scatterers

    def refine_parameters(self, scatterers: List[Dict], original_signal: np.ndarray) -> List[Dict]:
        """
        å‚æ•°ç²¾åŒ– - åå¤„ç†ä¼˜åŒ–æ­¥éª¤

        å¯¹æå–çš„ASCå‚æ•°è¿›è¡Œéçº¿æ€§ä¼˜åŒ–ï¼Œæé«˜å‚æ•°ä¼°è®¡ç²¾åº¦
        ç±»ä¼¼äºextrac.mä¸­çš„fminconä¼˜åŒ–

        Args:
            scatterers: åˆå§‹æå–çš„æ•£å°„ä¸­å¿ƒ
            original_signal: åŸå§‹ä¿¡å·

        Returns:
            refined_scatterers: ç²¾åŒ–åçš„æ•£å°„ä¸­å¿ƒå‚æ•°
        """
        print(f"ğŸ”§ å¼€å§‹ASCå‚æ•°ç²¾åŒ–...")

        refined_scatterers = []

        # é¢‘ç‡é‡‡æ ·
        fx_range = np.linspace(-self.B / 2, self.B / 2, self.image_size[0])
        fy_range = np.linspace(-self.fc * np.sin(self.omega / 2), self.fc * np.sin(self.omega / 2), self.image_size[1])

        for i, scatterer in enumerate(scatterers):
            print(f"   ç²¾åŒ–æ•£å°„ä¸­å¿ƒ {i+1}/{len(scatterers)}...")

            # åˆå§‹å‚æ•°
            x0 = [scatterer["x"], scatterer["y"], scatterer["estimated_amplitude"], scatterer["estimated_phase"]]

            # å›ºå®šçš„ç¦»æ•£å‚æ•°
            alpha_fixed = scatterer["alpha"]
            length_fixed = scatterer["length"]
            phi_bar_fixed = scatterer["phi_bar"]

            # å®šä¹‰ä¼˜åŒ–ç›®æ ‡å‡½æ•°
            def objective(params):
                x, y, amp, phase = params

                # ç”Ÿæˆç²¾åŒ–åŸå­
                atom = self._generate_asc_atom(x, y, alpha_fixed, length_fixed, phi_bar_fixed, fx_range, fy_range)
                atom_flat = atom.flatten()

                # å½’ä¸€åŒ–
                atom_energy = np.linalg.norm(atom_flat)
                if atom_energy > 1e-10:
                    atom_normalized = atom_flat / atom_energy
                else:
                    atom_normalized = atom_flat

                # è®¡ç®—é‡æ„è¯¯å·®
                reconstruction = amp * np.exp(1j * phase) * atom_normalized
                error = np.linalg.norm(original_signal - reconstruction)

                return error

            # å‚æ•°è¾¹ç•Œ
            bounds = [(-1.0, 1.0), (-1.0, 1.0), (0.001, 10.0), (-np.pi, np.pi)]  # x  # y  # amplitude  # phase

            # æ‰§è¡Œä¼˜åŒ–
            try:
                result = minimize(objective, x0, method="L-BFGS-B", bounds=bounds, options={"maxiter": 100})

                if result.success:
                    # æ›´æ–°å‚æ•°
                    refined_scatterer = scatterer.copy()
                    refined_scatterer["x"] = result.x[0]
                    refined_scatterer["y"] = result.x[1]
                    refined_scatterer["estimated_amplitude"] = result.x[2]
                    refined_scatterer["estimated_phase"] = result.x[3]
                    refined_scatterer["optimization_success"] = True
                    refined_scatterer["optimization_error"] = result.fun

                    refined_scatterers.append(refined_scatterer)
                else:
                    # ä¿æŒåŸå§‹å‚æ•°
                    scatterer["optimization_success"] = False
                    refined_scatterers.append(scatterer)

            except Exception as e:
                print(f"     âš ï¸ ä¼˜åŒ–å¤±è´¥: {str(e)}")
                scatterer["optimization_success"] = False
                refined_scatterers.append(scatterer)

        successful_refinements = sum(1 for s in refined_scatterers if s.get("optimization_success", False))

        print(f"âœ… ASCå‚æ•°ç²¾åŒ–å®Œæˆ")
        print(f"   æˆåŠŸç²¾åŒ–: {successful_refinements}/{len(scatterers)}")

        return refined_scatterers

    def reconstruct_asc_image(self, scatterers: List[Dict]) -> np.ndarray:
        """åŸºäºASCå‚æ•°é‡æ„SARå›¾åƒ"""
        print(f"ğŸ”„ åŸºäºASCå‚æ•°é‡æ„å›¾åƒ...")

        reconstructed = np.zeros(self.image_size, dtype=complex)

        # é¢‘ç‡é‡‡æ ·
        fx_range = np.linspace(-self.B / 2, self.B / 2, self.image_size[0])
        fy_range = np.linspace(-self.fc * np.sin(self.omega / 2), self.fc * np.sin(self.omega / 2), self.image_size[1])

        for scatterer in scatterers:
            # ç”ŸæˆASCåŸå­
            atom = self._generate_asc_atom(
                scatterer["x"],
                scatterer["y"],
                scatterer["alpha"],
                scatterer["length"],
                scatterer["phi_bar"],
                fx_range,
                fy_range,
            )

            # åº”ç”¨å¹…åº¦å’Œç›¸ä½
            contribution = scatterer["estimated_amplitude"] * np.exp(1j * scatterer["estimated_phase"]) * atom

            reconstructed += contribution

        print(f"   é‡æ„å®Œæˆï¼Œæ•£å°„ä¸­å¿ƒæ•°: {len(scatterers)}")

        return reconstructed

    def analyze_asc_results(self, scatterers: List[Dict]) -> Dict:
        """åˆ†æASCæå–ç»“æœ"""
        if not scatterers:
            return {}

        print(f"ğŸ“Š åˆ†æASCæå–ç»“æœ...")

        # æŒ‰æ•£å°„ç±»å‹åˆ†ç»„
        alpha_groups = {}
        for scatterer in scatterers:
            alpha = scatterer["alpha"]
            if alpha not in alpha_groups:
                alpha_groups[alpha] = []
            alpha_groups[alpha].append(scatterer)

        # ç»Ÿè®¡åˆ†æ
        amplitudes = [s["estimated_amplitude"] for s in scatterers]
        lengths = [s["length"] for s in scatterers]

        analysis = {
            "total_scatterers": len(scatterers),
            "alpha_distribution": {alpha: len(group) for alpha, group in alpha_groups.items()},
            "amplitude_stats": {
                "mean": np.mean(amplitudes),
                "std": np.std(amplitudes),
                "min": np.min(amplitudes),
                "max": np.max(amplitudes),
            },
            "length_stats": {
                "mean": np.mean(lengths),
                "std": np.std(lengths),
                "min": np.min(lengths),
                "max": np.max(lengths),
            },
            "optimization_success_rate": sum(1 for s in scatterers if s.get("optimization_success", False))
            / len(scatterers),
        }

        print(f"   æ€»æ•£å°„ä¸­å¿ƒæ•°: {analysis['total_scatterers']}")
        print(f"   Î±åˆ†å¸ƒ: {analysis['alpha_distribution']}")
        print(f"   å¹…åº¦èŒƒå›´: [{analysis['amplitude_stats']['min']:.3f}, {analysis['amplitude_stats']['max']:.3f}]")
        print(f"   é•¿åº¦èŒƒå›´: [{analysis['length_stats']['min']:.3f}, {analysis['length_stats']['max']:.3f}]")
        print(f"   ä¼˜åŒ–æˆåŠŸç‡: {analysis['optimization_success_rate']:.1%}")

        return analysis


def main():
    """ASCæå–ç³»ç»Ÿæ¼”ç¤º"""
    print("ğŸ¯ é«˜çº§ASCæå–ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)

    # åˆå§‹åŒ–ç³»ç»Ÿ
    asc_extractor = ASCExtractionAdvanced(
        adaptive_threshold=0.05,
        max_iterations=50,
        min_scatterers=5,
        max_scatterers=30,
        precision_mode="balanced",  # 5% é˜ˆå€¼
    )

    # æµ‹è¯•ç”¨ä¾‹ - è¿™é‡Œå¯ä»¥åŠ è½½å®é™…çš„MSTARæ•°æ®
    print("\nğŸ“ æ³¨æ„: è¯·åœ¨å®é™…ä½¿ç”¨ä¸­åŠ è½½MSTARæ•°æ®æ–‡ä»¶")
    print("ç¤ºä¾‹è°ƒç”¨:")
    print("magnitude, complex_image = asc_extractor.load_raw_data('path/to/data.raw')")
    print("signal = asc_extractor.preprocess_data(complex_image)")
    print("dictionary, param_grid = asc_extractor.build_asc_dictionary()")
    print("scatterers = asc_extractor.adaptive_asc_extraction(signal, dictionary, param_grid)")
    print("refined_scatterers = asc_extractor.refine_parameters(scatterers, signal)")
    print("reconstructed = asc_extractor.reconstruct_asc_image(refined_scatterers)")

    return asc_extractor


if __name__ == "__main__":
    asc_system = main()
