"""
Fixed Attribute Scattering Center (ASC) Extraction System
ä¿®å¤ç‰ˆå±æ€§æ•£å°„ä¸­å¿ƒæå–ç³»ç»Ÿ

è§£å†³ç°æœ‰ç®—æ³•çš„ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š
1. æ•°å€¼ç¨³å®šæ€§ï¼šä¿®å¤ASCåŸå­ç”Ÿæˆä¸­çš„é›¶é¢‘å’Œè´ŸÎ±å€¼é—®é¢˜
2. ä¼˜åŒ–é€»è¾‘ï¼šä¿®å¤å‚æ•°ç²¾åŒ–ä¸­ç”¨å•ä¸ªåŸå­åŒ¹é…å®Œæ•´ä¿¡å·çš„é”™è¯¯
3. è¿­ä»£æ”¶æ•›ï¼šå®ç°æ­£ç¡®çš„"åŒ¹é…-ä¼˜åŒ–-å‡å»"æµç¨‹

æŠ€æœ¯æ”¹è¿›ï¼š
- æ•°å€¼ç¨³å¥çš„ASCåŸå­ç”Ÿæˆå‡½æ•°
- æ­£ç¡®çš„æ®‹å·®åŒ¹é…ä¼˜åŒ–ç›®æ ‡
- æ¸è¿›å¼æå–ç­–ç•¥ï¼ˆç‚¹æ•£å°„â†’åˆ†å¸ƒå¼æ•£å°„ï¼‰
- æ™ºèƒ½æ”¶æ•›åˆ¤æ–­å’Œè‡ªé€‚åº”åœæ­¢
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize, differential_evolution
from sklearn.linear_model import OrthogonalMatchingPursuit
from scipy.io import loadmat
import struct
from typing import Tuple, List, Dict, Optional
import warnings
import time

warnings.filterwarnings("ignore")


class ASCExtractionFixed:
    """
    ä¿®å¤ç‰ˆASCæå–ç³»ç»Ÿ

    æ ¸å¿ƒä¿®å¤ï¼š
    1. æ•°å€¼ç¨³å¥çš„ASCåŸå­ç”Ÿæˆ
    2. æ­£ç¡®çš„æ®‹å·®åŒ¹é…ä¼˜åŒ–
    3. åˆ†å±‚æå–ç­–ç•¥
    """

    def __init__(
        self,
        image_size: Tuple[int, int] = (128, 128),
        extraction_mode: str = "progressive",  # "point_only", "progressive", "full_asc"
        adaptive_threshold: float = 0.01,
        max_iterations: int = 50,
        min_scatterers: int = 3,
        max_scatterers: int = 30,
    ):
        """
        åˆå§‹åŒ–ä¿®å¤ç‰ˆASCæå–ç³»ç»Ÿ

        Args:
            extraction_mode: æå–æ¨¡å¼
                - "point_only": ä»…ç‚¹æ•£å°„ï¼ˆL=0, phi_bar=0ï¼ŒéªŒè¯Î±è¯†åˆ«ï¼‰
                - "progressive": æ¸è¿›å¼ï¼ˆå…ˆç‚¹æ•£å°„ï¼Œå†æ‰©å±•ï¼‰
                - "full_asc": å®Œæ•´ASCï¼ˆ6å‚æ•°åŒæ—¶æå–ï¼‰
        """
        self.image_size = image_size
        self.extraction_mode = extraction_mode
        self.adaptive_threshold = adaptive_threshold
        self.max_iterations = max_iterations
        self.min_scatterers = min_scatterers
        self.max_scatterers = max_scatterers

        # SARç³»ç»Ÿå‚æ•°
        self.fc = 1e10  # ä¸­å¿ƒé¢‘ç‡ 10GHz
        self.B = 1e9  # å¸¦å®½ 1GHz
        self.omega = np.pi / 3  # åˆæˆå­”å¾„è§’
        self.scene_size = 30.0  # åœºæ™¯å°ºå¯¸ (ç±³)

        # æ ¹æ®æå–æ¨¡å¼é…ç½®å‚æ•°
        self._configure_extraction_mode()

        print(f"ğŸ”§ ä¿®å¤ç‰ˆASCæå–ç³»ç»Ÿåˆå§‹åŒ–")
        print(f"   æå–æ¨¡å¼: {extraction_mode}")
        print(f"   å›¾åƒå°ºå¯¸: {image_size}")
        print(f"   Î±å€¼èŒƒå›´: {self.alpha_values}")
        print(f"   Lå€¼èŒƒå›´: {self.length_values}")
        print(f"   è‡ªé€‚åº”é˜ˆå€¼: {adaptive_threshold}")

    def _configure_extraction_mode(self):
        """æ ¹æ®æå–æ¨¡å¼é…ç½®å‚æ•°"""
        if self.extraction_mode == "point_only":
            # ä»…ç‚¹æ•£å°„ï¼šå›ºå®šL=0, phi_bar=0ï¼Œä¸“æ³¨Î±è¯†åˆ«
            self.alpha_values = [-1.0, -0.5, 0.0, 0.5, 1.0]
            self.length_values = [0.0]  # å›ºå®šä¸º0
            self.phi_bar_values = [0.0]  # å›ºå®šä¸º0
            self.position_samples = 32
            print("   ğŸ¯ ç‚¹æ•£å°„æ¨¡å¼ï¼šä¸“æ³¨é¢‘ç‡ä¾èµ–å› å­Î±è¯†åˆ«")

        elif self.extraction_mode == "progressive":
            # æ¸è¿›å¼ï¼šå…ˆç‚¹æ•£å°„ï¼Œå†é€æ­¥æ‰©å±•
            self.alpha_values = [-1.0, -0.5, 0.0, 0.5, 1.0]
            self.length_values = [0.0, 0.1, 0.5]  # é€æ­¥æ‰©å±•
            self.phi_bar_values = [0.0, np.pi / 4, np.pi / 2]  # é€æ­¥æ‰©å±•
            self.position_samples = 32
            print("   ğŸ¯ æ¸è¿›æ¨¡å¼ï¼šä»ç‚¹æ•£å°„æ‰©å±•åˆ°åˆ†å¸ƒå¼æ•£å°„")

        else:  # full_asc
            # å®Œæ•´ASCï¼šæ‰€æœ‰å‚æ•°åŒæ—¶æå–
            self.alpha_values = [-1.0, -0.5, 0.0, 0.5, 1.0]
            self.length_values = np.logspace(-2, 0, 5)  # [0.01, 1.0]
            self.phi_bar_values = np.linspace(0, np.pi, 8)
            self.position_samples = 24  # é™ä½é‡‡æ ·å‡å°‘è®¡ç®—é‡
            print("   ğŸ¯ å®Œæ•´ASCæ¨¡å¼ï¼š6å‚æ•°åŒæ—¶æå–")

    def load_mstar_data(self, raw_file_path: str) -> Tuple[np.ndarray, np.ndarray]:
        """åŠ è½½MSTAR RAWæ•°æ®"""
        print(f"ğŸ“‚ åŠ è½½MSTARæ•°æ®: {raw_file_path}")

        with open(raw_file_path, "rb") as f:
            data = f.read()

        # è§£æå¤å€¼æ•°æ®
        num_values = len(data) // 4
        real_imag = struct.unpack(f"<{num_values}f", data)

        # é‡æ„å¤å€¼å›¾åƒ
        complex_values = []
        for i in range(0, len(real_imag), 2):
            complex_values.append(complex(real_imag[i], real_imag[i + 1]))

        complex_image = np.array(complex_values).reshape(self.image_size)
        magnitude = np.abs(complex_image)

        print(f"   å›¾åƒå°ºå¯¸: {complex_image.shape}")
        print(f"   å¹…åº¦èŒƒå›´: [{np.min(magnitude):.3f}, {np.max(magnitude):.3f}]")
        print(f"   ä¿¡å·èƒ½é‡: {np.linalg.norm(complex_image):.3f}")

        return magnitude, complex_image

    def preprocess_data(self, complex_image: np.ndarray) -> np.ndarray:
        """æ™ºèƒ½æ•°æ®é¢„å¤„ç†"""
        print("âš™ï¸ æ™ºèƒ½æ•°æ®é¢„å¤„ç†...")

        # ä¿¡å·å‘é‡åŒ–
        signal = complex_image.flatten()

        # èƒ½é‡å½’ä¸€åŒ–ï¼ˆä¿æŒç›¸å¯¹å¼ºåº¦å…³ç³»ï¼‰
        signal_energy = np.linalg.norm(signal)
        signal_normalized = signal / np.sqrt(signal_energy)

        print(f"   ä¿¡å·é•¿åº¦: {len(signal)}")
        print(f"   åŸå§‹èƒ½é‡: {signal_energy:.3f}")
        print(f"   å½’ä¸€åŒ–æ–¹å¼: èƒ½é‡å½’ä¸€åŒ–")

        return signal_normalized

    def _generate_robust_asc_atom(
        self,
        x: float,
        y: float,
        alpha: float,
        length: float,
        phi_bar: float,
        fx_range: np.ndarray,
        fy_range: np.ndarray,
    ) -> np.ndarray:
        """
        ç”Ÿæˆæ•°å€¼ç¨³å¥çš„ASCåŸå­

        å…³é”®ä¿®å¤ï¼š
        1. å¤„ç†é›¶é¢‘é—®é¢˜ï¼Œé¿å…0^(-alpha)æ•°å€¼çˆ†ç‚¸
        2. ä½¿ç”¨å½’ä¸€åŒ–é¢‘ç‡é¿å…æ•°å€¼è¿‡å¤§
        3. æ”¹è¿›çš„sincå‡½æ•°è®¡ç®—
        """
        # åˆ›å»ºé¢‘ç‡ç½‘æ ¼
        FX, FY = np.meshgrid(fx_range, fy_range, indexing="ij")

        # è®¡ç®—é¢‘ç‡ç‰¹å¾
        f_magnitude = np.sqrt(FX**2 + FY**2)
        theta = np.arctan2(FY, FX)

        # å…³é”®ä¿®å¤1ï¼šå¤„ç†é›¶é¢‘é—®é¢˜
        # ä½¿ç”¨æ›´å¤§çš„å®‰å…¨å€¼é¿å…æ•°å€¼é—®é¢˜
        f_magnitude_safe = np.where(f_magnitude < 1e-8, 1e-8, f_magnitude)

        # ASCé¢‘åŸŸå“åº”
        # 1. ä½ç½®ç›¸ä½é¡¹
        position_phase = -2j * np.pi * (FX * x + FY * y)

        # 2. é¢‘ç‡ä¾èµ–é¡¹: f^Î± (å…³é”®ä¿®å¤)
        if alpha == 0:
            # ç‰¹æ®Šå¤„ç†Î±=0çš„æƒ…å†µ
            frequency_term = np.ones_like(f_magnitude_safe)
        else:
            # ä½¿ç”¨å½’ä¸€åŒ–é¢‘ç‡ f/fc é¿å…æ•°å€¼è¿‡å¤§
            normalized_freq = f_magnitude_safe / self.fc
            frequency_term = np.power(normalized_freq, alpha)

        # 3. é•¿åº¦ç›¸å…³é¡¹: sinc(LÂ·fÂ·sin(Î¸-Ï†_bar))
        if length == 0:
            # ç‚¹æ•£å°„æƒ…å†µ
            length_term = np.ones_like(f_magnitude_safe)
        else:
            angle_diff = theta - phi_bar
            sinc_arg = length * f_magnitude_safe * np.sin(angle_diff)

            # æ”¹è¿›çš„sincå‡½æ•°è®¡ç®—ï¼Œé¿å…æ•°å€¼é—®é¢˜
            with np.errstate(divide="ignore", invalid="ignore"):
                length_term = np.where(np.abs(sinc_arg) < 1e-10, 1.0, np.sin(np.pi * sinc_arg) / (np.pi * sinc_arg))

        # 4. æ–¹ä½è§’ç›¸ä½é¡¹
        azimuth_phase = 1j * phi_bar

        # ç»„åˆå®Œæ•´ASCé¢‘åŸŸå“åº”
        H_asc = frequency_term * length_term * np.exp(position_phase + azimuth_phase)

        # ç©ºåŸŸåŸå­ (IFFT)
        atom = np.fft.ifft2(np.fft.ifftshift(H_asc))

        return atom

    def build_robust_dictionary(self) -> Tuple[np.ndarray, List[Dict]]:
        """æ„å»ºæ•°å€¼ç¨³å¥çš„ASCå­—å…¸"""
        print(f"ğŸ“š æ„å»ºç¨³å¥ASCå­—å…¸ (æ¨¡å¼: {self.extraction_mode})...")

        # é¢‘ç‡é‡‡æ ·èŒƒå›´
        fx_range = np.linspace(-self.B / 2, self.B / 2, self.image_size[0])
        fy_range = np.linspace(-self.fc * np.sin(self.omega / 2), self.fc * np.sin(self.omega / 2), self.image_size[1])

        # ä½ç½®é‡‡æ ·
        x_positions = np.linspace(-0.9, 0.9, self.position_samples)
        y_positions = np.linspace(-0.9, 0.9, self.position_samples)

        # ä¼°ç®—å­—å…¸å¤§å°
        total_atoms = (
            len(x_positions)
            * len(y_positions)
            * len(self.alpha_values)
            * len(self.length_values)
            * len(self.phi_bar_values)
        )

        print(f"   ä½ç½®é‡‡æ ·: {self.position_samples}Ã—{self.position_samples}")
        print(f"   Î±é‡‡æ ·: {len(self.alpha_values)} ä¸ªå€¼")
        print(f"   Lé‡‡æ ·: {len(self.length_values)} ä¸ªå€¼")
        print(f"   Ï†_baré‡‡æ ·: {len(self.phi_bar_values)} ä¸ªå€¼")
        print(f"   é¢„è®¡åŸå­æ•°: {total_atoms}")

        # æ„å»ºå­—å…¸
        dictionary_atoms = []
        param_grid = []

        atom_count = 0
        invalid_atoms = 0
        start_time = time.time()

        for i, x in enumerate(x_positions):
            for j, y in enumerate(y_positions):
                for alpha in self.alpha_values:
                    for length in self.length_values:
                        for phi_bar in self.phi_bar_values:
                            # ç”ŸæˆASCåŸå­
                            atom = self._generate_robust_asc_atom(x, y, alpha, length, phi_bar, fx_range, fy_range)

                            # æ£€æŸ¥åŸå­æœ‰æ•ˆæ€§
                            atom_flat = atom.flatten()
                            atom_energy = np.linalg.norm(atom_flat)

                            # æ£€æŸ¥æ•°å€¼å¼‚å¸¸
                            if (
                                atom_energy > 1e-12
                                and np.isfinite(atom_energy)
                                and not np.any(np.isnan(atom_flat))
                                and not np.any(np.isinf(atom_flat))
                            ):

                                # å½’ä¸€åŒ–
                                atom_normalized = atom_flat / atom_energy

                                dictionary_atoms.append(atom_normalized)
                                param_grid.append(
                                    {
                                        "x": x,
                                        "y": y,
                                        "alpha": alpha,
                                        "length": length,
                                        "phi_bar": phi_bar,
                                        "atom_energy": atom_energy,
                                        "grid_index": (i, j),
                                        "scattering_type": self._classify_scattering_type(alpha),
                                    }
                                )

                                atom_count += 1
                            else:
                                invalid_atoms += 1

                            if (atom_count + invalid_atoms) % 2000 == 0:
                                progress = (atom_count + invalid_atoms) / total_atoms * 100
                                elapsed = time.time() - start_time
                                print(
                                    f"   è¿›åº¦: {progress:.1f}% ({atom_count}æœ‰æ•ˆ, {invalid_atoms}æ— æ•ˆ) - {elapsed:.1f}s"
                                )

        # è½¬æ¢ä¸ºçŸ©é˜µ
        dictionary = np.column_stack(dictionary_atoms)

        print(f"âœ… ç¨³å¥å­—å…¸æ„å»ºå®Œæˆ")
        print(f"   æœ‰æ•ˆåŸå­æ•°: {atom_count}")
        print(f"   æ— æ•ˆåŸå­æ•°: {invalid_atoms}")
        print(f"   æœ‰æ•ˆç‡: {atom_count/(atom_count+invalid_atoms)*100:.1f}%")
        print(f"   å­—å…¸å°ºå¯¸: {dictionary.shape}")
        print(f"   å†…å­˜å ç”¨: ~{dictionary.nbytes / 1024**2:.1f} MB")

        return dictionary, param_grid

    def _classify_scattering_type(self, alpha: float) -> str:
        """æ ¹æ®Î±å€¼åˆ†ç±»æ•£å°„ç±»å‹"""
        scattering_types = {-1.0: "å°–é¡¶ç»•å°„", -0.5: "è¾¹ç¼˜ç»•å°„", 0.0: "æ ‡å‡†æ•£å°„", 0.5: "è¡¨é¢æ•£å°„", 1.0: "é•œé¢åå°„"}
        return scattering_types.get(alpha, f"Î±={alpha}")

    def fixed_adaptive_extraction(
        self, signal: np.ndarray, dictionary: np.ndarray, param_grid: List[Dict]
    ) -> List[Dict]:
        """
        ä¿®å¤ç‰ˆè‡ªé€‚åº”æå–ç®—æ³•

        æ ¸å¿ƒä¿®å¤ï¼š
        1. æ­£ç¡®çš„"åŒ¹é…-ä¼˜åŒ–-å‡å»"è¿­ä»£æµç¨‹
        2. ç¨³å¥çš„æ®‹å·®æ›´æ–°æœºåˆ¶
        3. æ™ºèƒ½çš„æ”¶æ•›åˆ¤æ–­
        """
        print(f"ğŸ¯ å¼€å§‹ä¿®å¤ç‰ˆè‡ªé€‚åº”ASCæå–...")

        residual_signal = signal.copy()
        extracted_scatterers = []

        # åˆå§‹ä¿¡å·ç‰¹å¾
        initial_energy = np.linalg.norm(residual_signal)
        energy_threshold = initial_energy * self.adaptive_threshold

        print(f"   åˆå§‹ä¿¡å·èƒ½é‡: {initial_energy:.6f}")
        print(f"   èƒ½é‡åœæ­¢é˜ˆå€¼: {energy_threshold:.6f}")

        for iteration in range(self.max_iterations):
            current_energy = np.linalg.norm(residual_signal)
            energy_reduction_ratio = (initial_energy - current_energy) / initial_energy

            # å¤šé‡åœæ­¢æ¡ä»¶
            if current_energy < energy_threshold:
                print(f"   ğŸ’¡ è¾¾åˆ°èƒ½é‡é˜ˆå€¼ï¼Œåœæ­¢è¿­ä»£ (å‡å°‘{energy_reduction_ratio:.1%})")
                break

            if len(extracted_scatterers) >= self.max_scatterers:
                print(f"   ğŸ’¡ è¾¾åˆ°æœ€å¤§æ•£å°„ä¸­å¿ƒæ•°ï¼Œåœæ­¢è¿­ä»£")
                break

            # é˜¶æ®µ1ï¼šç²—åŒ¹é… - åœ¨å­—å…¸ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…åŸå­
            best_atom_idx, best_coefficient = self._find_best_match(residual_signal, dictionary)

            if best_atom_idx is None:
                print(f"   ğŸ’¡ æœªæ‰¾åˆ°æ˜¾è‘—æ•£å°„ä¸­å¿ƒï¼Œåœæ­¢è¿­ä»£")
                break

            # è·å–åˆå§‹å‚æ•°
            initial_params = param_grid[best_atom_idx].copy()

            # é˜¶æ®µ2ï¼šå‚æ•°ç²¾åŒ– - ä½¿ç”¨å½“å‰æ®‹å·®ä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼ˆå…³é”®ä¿®å¤ï¼‰
            refined_params = self._refine_parameters_correctly(
                initial_params, residual_signal, best_coefficient  # å…³é”®ï¼šä½¿ç”¨æ®‹å·®è€ŒéåŸå§‹ä¿¡å·
            )

            # é˜¶æ®µ3ï¼šæ®‹å·®æ›´æ–° - ä»ä¿¡å·ä¸­å‡å»å½“å‰æ•£å°„ä¸­å¿ƒçš„è´¡çŒ®
            updated_residual = self._update_residual_robust(residual_signal, refined_params)

            # éªŒè¯æ›´æ–°æœ‰æ•ˆæ€§
            new_energy = np.linalg.norm(updated_residual)
            energy_reduction = current_energy - new_energy

            if energy_reduction < current_energy * 0.001:  # 0.1%æ”¹è¿›é˜ˆå€¼
                print(f"   ğŸ’¡ èƒ½é‡å‡å°‘ä¸æ˜¾è‘— ({energy_reduction/current_energy:.3%})ï¼Œåœæ­¢è¿­ä»£")
                break

            # æ›´æ–°æ®‹å·®å’Œè®°å½•æ•£å°„ä¸­å¿ƒ
            residual_signal = updated_residual
            extracted_scatterers.append(refined_params)

            # è¿›åº¦æ˜¾ç¤º
            if iteration < 10 or (iteration + 1) % 5 == 0:
                print(
                    f"   è¿­ä»£ {iteration+1}: èƒ½é‡ {current_energy:.6f} â†’ {new_energy:.6f} "
                    f"(å‡å°‘ {energy_reduction/current_energy:.2%})"
                )

        # æœ€ç»ˆç»Ÿè®¡
        final_energy = np.linalg.norm(residual_signal)
        total_reduction = (initial_energy - final_energy) / initial_energy

        print(f"âœ… ä¿®å¤ç‰ˆASCæå–å®Œæˆ")
        print(f"   æå–æ•£å°„ä¸­å¿ƒæ•°: {len(extracted_scatterers)}")
        print(f"   æ€»èƒ½é‡å‡å°‘: {total_reduction:.1%}")
        print(f"   æœ€ç»ˆæ®‹å·®èƒ½é‡: {final_energy:.6f}")

        return extracted_scatterers

    def _find_best_match(self, signal: np.ndarray, dictionary: np.ndarray) -> Tuple[Optional[int], Optional[complex]]:
        """åœ¨å­—å…¸ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…åŸå­"""
        # è½¬æ¢ä¸ºå®å€¼OMP
        signal_real = np.concatenate([signal.real, signal.imag])
        dictionary_real = np.concatenate([dictionary.real, dictionary.imag], axis=0)

        try:
            omp = OrthogonalMatchingPursuit(n_nonzero_coefs=1, fit_intercept=False)
            omp.fit(dictionary_real, signal_real)

            nonzero_indices = np.nonzero(omp.coef_)[0]
            if len(nonzero_indices) == 0:
                return None, None

            best_idx = nonzero_indices[0]

            # è®¡ç®—å‡†ç¡®çš„å¤æ•°ç³»æ•°
            selected_atom = dictionary[:, best_idx]
            complex_coef = np.vdot(selected_atom, signal) / np.vdot(selected_atom, selected_atom)

            return best_idx, complex_coef

        except Exception as e:
            print(f"   âš ï¸ OMPåŒ¹é…å¤±è´¥: {str(e)}")
            return None, None

    def _refine_parameters_correctly(
        self,
        initial_params: Dict,
        target_signal: np.ndarray,  # å…³é”®ï¼šä½¿ç”¨æ®‹å·®ä¿¡å·è€ŒéåŸå§‹ä¿¡å·
        initial_coefficient: complex,
    ) -> Dict:
        """
        æ­£ç¡®çš„å‚æ•°ç²¾åŒ–

        å…³é”®ä¿®å¤ï¼šä¼˜åŒ–ç›®æ ‡æ˜¯åŒ¹é…å½“å‰æ®‹å·®ä¿¡å·ï¼Œè€ŒéåŸå§‹ä¿¡å·
        """
        if self.extraction_mode == "point_only":
            # ç‚¹æ•£å°„æ¨¡å¼ï¼šåªä¼˜åŒ–ä½ç½®å’Œå¹…åº¦/ç›¸ä½
            return self._refine_point_scatterer(initial_params, target_signal, initial_coefficient)
        else:
            # å®Œæ•´ASCæ¨¡å¼ï¼šä¼˜åŒ–æ‰€æœ‰è¿ç»­å‚æ•°
            return self._refine_full_asc(initial_params, target_signal, initial_coefficient)

    def _refine_point_scatterer(
        self, initial_params: Dict, target_signal: np.ndarray, initial_coefficient: complex
    ) -> Dict:
        """ç²¾åŒ–ç‚¹æ•£å°„ä¸­å¿ƒå‚æ•°"""
        # å›ºå®šç¦»æ•£å‚æ•°
        alpha_fixed = initial_params["alpha"]
        length_fixed = 0.0  # ç‚¹æ•£å°„
        phi_bar_fixed = 0.0  # ç‚¹æ•£å°„

        # ä¼˜åŒ–å˜é‡ï¼š[x, y, amplitude, phase]
        x0 = [initial_params["x"], initial_params["y"], np.abs(initial_coefficient), np.angle(initial_coefficient)]

        # é¢‘ç‡èŒƒå›´
        fx_range = np.linspace(-self.B / 2, self.B / 2, self.image_size[0])
        fy_range = np.linspace(-self.fc * np.sin(self.omega / 2), self.fc * np.sin(self.omega / 2), self.image_size[1])

        def objective(params):
            x, y, amp, phase = params

            # ç”Ÿæˆå½“å‰å‚æ•°çš„åŸå­
            atom = self._generate_robust_asc_atom(x, y, alpha_fixed, length_fixed, phi_bar_fixed, fx_range, fy_range)

            atom_flat = atom.flatten()
            atom_energy = np.linalg.norm(atom_flat)

            if atom_energy > 1e-12:
                atom_normalized = atom_flat / atom_energy
            else:
                return 1e6  # æƒ©ç½šæ— æ•ˆåŸå­

            # å½“å‰å‚æ•°ä¸‹çš„é‡æ„
            reconstruction = amp * np.exp(1j * phase) * atom_normalized

            # å…³é”®ä¿®å¤ï¼šä¸æ®‹å·®ä¿¡å·æ¯”è¾ƒï¼Œè€ŒéåŸå§‹ä¿¡å·
            error = np.linalg.norm(target_signal - reconstruction)

            return error

        # å‚æ•°è¾¹ç•Œ
        bounds = [(-1.0, 1.0), (-1.0, 1.0), (0.001, 10.0), (-np.pi, np.pi)]  # x  # y  # amplitude  # phase

        try:
            result = minimize(objective, x0, method="L-BFGS-B", bounds=bounds, options={"maxiter": 50})

            if result.success:
                refined_params = initial_params.copy()
                refined_params.update(
                    {
                        "x": result.x[0],
                        "y": result.x[1],
                        "estimated_amplitude": result.x[2],
                        "estimated_phase": result.x[3],
                        "optimization_success": True,
                        "optimization_error": result.fun,
                    }
                )
                return refined_params
            else:
                # ä¿æŒåˆå§‹å‚æ•°
                initial_params["estimated_amplitude"] = np.abs(initial_coefficient)
                initial_params["estimated_phase"] = np.angle(initial_coefficient)
                initial_params["optimization_success"] = False
                return initial_params

        except Exception:
            # ä¿æŒåˆå§‹å‚æ•°
            initial_params["estimated_amplitude"] = np.abs(initial_coefficient)
            initial_params["estimated_phase"] = np.angle(initial_coefficient)
            initial_params["optimization_success"] = False
            return initial_params

    def _refine_full_asc(self, initial_params: Dict, target_signal: np.ndarray, initial_coefficient: complex) -> Dict:
        """ç²¾åŒ–å®Œæ•´ASCå‚æ•°"""
        # å¯¹äºå®Œæ•´ASCï¼Œæš‚æ—¶ä¿æŒç®€åŒ–å¤„ç†
        # å¯ä»¥åç»­æ‰©å±•ä¸ºä¼˜åŒ–æ‰€æœ‰6ä¸ªå‚æ•°
        return self._refine_point_scatterer(initial_params, target_signal, initial_coefficient)

    def _update_residual_robust(self, current_signal: np.ndarray, scatterer_params: Dict) -> np.ndarray:
        """ç¨³å¥çš„æ®‹å·®æ›´æ–°"""
        # é¢‘ç‡èŒƒå›´
        fx_range = np.linspace(-self.B / 2, self.B / 2, self.image_size[0])
        fy_range = np.linspace(-self.fc * np.sin(self.omega / 2), self.fc * np.sin(self.omega / 2), self.image_size[1])

        # é‡æ–°ç”Ÿæˆç²¾åŒ–åçš„åŸå­
        atom = self._generate_robust_asc_atom(
            scatterer_params["x"],
            scatterer_params["y"],
            scatterer_params["alpha"],
            scatterer_params.get("length", 0.0),
            scatterer_params.get("phi_bar", 0.0),
            fx_range,
            fy_range,
        )

        atom_flat = atom.flatten()
        atom_energy = np.linalg.norm(atom_flat)

        if atom_energy > 1e-12:
            atom_normalized = atom_flat / atom_energy

            # è®¡ç®—æ•£å°„ä¸­å¿ƒçš„è´¡çŒ®
            contribution = (
                scatterer_params["estimated_amplitude"]
                * np.exp(1j * scatterer_params["estimated_phase"])
                * atom_normalized
            )

            # ä»ä¿¡å·ä¸­å‡å»è´¡çŒ®
            updated_signal = current_signal - contribution

            return updated_signal
        else:
            # åŸå­æ— æ•ˆï¼Œè¿”å›åŸä¿¡å·
            return current_signal

    def extract_asc_scatterers(self, complex_image: np.ndarray) -> List[Dict]:
        """å®Œæ•´çš„ASCæå–æµç¨‹"""
        print(f"ğŸš€ å¼€å§‹å®Œæ•´ASCæå–æµç¨‹ (æ¨¡å¼: {self.extraction_mode})")
        print("=" * 60)

        # æ­¥éª¤1ï¼šæ•°æ®é¢„å¤„ç†
        signal = self.preprocess_data(complex_image)

        # æ­¥éª¤2ï¼šæ„å»ºç¨³å¥å­—å…¸
        dictionary, param_grid = self.build_robust_dictionary()

        # æ­¥éª¤3ï¼šä¿®å¤ç‰ˆè‡ªé€‚åº”æå–
        scatterers = self.fixed_adaptive_extraction(signal, dictionary, param_grid)

        # æ­¥éª¤4ï¼šç»“æœåˆ†æ
        if scatterers:
            analysis = self._analyze_extraction_results(scatterers)
            print(f"\nğŸ“Š æå–ç»“æœåˆ†æ:")
            print(f"   æ•£å°„ä¸­å¿ƒæ€»æ•°: {analysis['total_count']}")
            print(f"   Î±åˆ†å¸ƒ: {analysis['alpha_distribution']}")
            print(f"   ä¼˜åŒ–æˆåŠŸç‡: {analysis['optimization_success_rate']:.1%}")

        return scatterers

    def _analyze_extraction_results(self, scatterers: List[Dict]) -> Dict:
        """åˆ†ææå–ç»“æœ"""
        if not scatterers:
            return {}

        # æŒ‰Î±å€¼åˆ†ç»„
        alpha_distribution = {}
        for scatterer in scatterers:
            alpha = scatterer["alpha"]
            scattering_type = self._classify_scattering_type(alpha)
            if scattering_type not in alpha_distribution:
                alpha_distribution[scattering_type] = 0
            alpha_distribution[scattering_type] += 1

        # ç»Ÿè®¡åˆ†æ
        optimization_success_count = sum(1 for s in scatterers if s.get("optimization_success", False))

        return {
            "total_count": len(scatterers),
            "alpha_distribution": alpha_distribution,
            "optimization_success_rate": optimization_success_count / len(scatterers),
            "amplitudes": [s["estimated_amplitude"] for s in scatterers],
            "positions": [(s["x"], s["y"]) for s in scatterers],
        }


def main():
    """ä¿®å¤ç‰ˆASCç³»ç»Ÿæ¼”ç¤º"""
    print("ğŸ”§ ä¿®å¤ç‰ˆASCæå–ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)

    # åˆå§‹åŒ–ä¿®å¤ç‰ˆç³»ç»Ÿ
    asc_fixed = ASCExtractionFixed(
        extraction_mode="point_only", adaptive_threshold=0.05, max_iterations=30, max_scatterers=20  # ä»ç‚¹æ•£å°„å¼€å§‹éªŒè¯
    )

    print("\nğŸ“ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œå‡†å¤‡åŠ è½½MSTARæ•°æ®è¿›è¡Œæµ‹è¯•")
    print("\nä½¿ç”¨ç¤ºä¾‹:")
    print("magnitude, complex_image = asc_fixed.load_mstar_data('data.raw')")
    print("scatterers = asc_fixed.extract_asc_scatterers(complex_image)")

    return asc_fixed


if __name__ == "__main__":
    asc_system = main()
