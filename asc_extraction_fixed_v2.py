"""
Fixed ASC Extraction System v2
ä¿®å¤ç‰ˆASCæå–ç³»ç»Ÿ v2

åœ¨v1åŸºç¡€ä¸Šè¿›ä¸€æ­¥ä¿®å¤ï¼š
1. MSTARæ•°æ®åŠ è½½NaNé—®é¢˜
2. é‡æ„è¯¯å·®è®¡ç®—é€»è¾‘
3. è¿­ä»£æ”¶æ•›æ€§èƒ½ä¼˜åŒ–
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize, differential_evolution
from sklearn.linear_model import OrthogonalMatchingPursuit
import struct
from typing import Tuple, List, Dict, Optional
import warnings
import time

warnings.filterwarnings("ignore")


class ASCExtractionFixedV2:
    """ä¿®å¤ç‰ˆASCæå–ç³»ç»Ÿ v2"""

    def __init__(
        self,
        image_size: Tuple[int, int] = (128, 128),
        extraction_mode: str = "progressive",
        adaptive_threshold: float = 0.01,
        max_iterations: int = 30,
        max_scatterers: int = 20,
        # New flexible parameters for dictionary building
        alpha_values: Optional[List[float]] = None,
        length_values: Optional[List[float]] = None,
        phi_bar_values: Optional[List[float]] = None,
        position_samples: Optional[int] = None,
    ):
        self.image_size = image_size
        self.extraction_mode = extraction_mode
        self.adaptive_threshold = adaptive_threshold
        self.max_iterations = max_iterations
        self.max_scatterers = max_scatterers

        # SARç³»ç»Ÿå‚æ•°
        self.fc = 1e10  # ä¸­å¿ƒé¢‘ç‡
        self.B = 1e9  # å¸¦å®½
        self.omega = np.pi / 3  # åˆæˆå­”å¾„è§’
        self.scene_size = 30.0  # åœºæ™¯å°ºå¯¸ (ç±³)

        # é…ç½®å‚æ•°
        if alpha_values is not None:
            print("   ğŸ”§ ä½¿ç”¨è‡ªå®šä¹‰å­—å…¸å‚æ•°è¿›è¡Œåˆå§‹åŒ–")
            self.alpha_values = alpha_values
            self.length_values = length_values if length_values is not None else [0.0]
            self.phi_bar_values = phi_bar_values if phi_bar_values is not None else [0.0]
            self.position_samples = position_samples if position_samples is not None else 64
        else:
            self._configure_extraction_mode()

        print(f"ğŸ”§ ä¿®å¤ç‰ˆASCæå–ç³»ç»Ÿv2åˆå§‹åŒ–")
        print(f"   æå–æ¨¡å¼: {extraction_mode}")
        print(f"   è‡ªé€‚åº”é˜ˆå€¼: {adaptive_threshold}")
        print(f"   åœºæ™¯å°ºå¯¸: {self.scene_size}m")

    def _configure_extraction_mode(self):
        """é…ç½®æå–æ¨¡å¼å‚æ•°"""
        if self.extraction_mode == "point_only":
            self.alpha_values = [-1.0, -0.5, 0.0, 0.5, 1.0]
            self.length_values = [0.0]
            self.phi_bar_values = [0.0]
            self.position_samples = 24  # é™ä½é‡‡æ ·æé«˜é€Ÿåº¦
            print("   ğŸ¯ ç‚¹æ•£å°„æ¨¡å¼ï¼šä¸“æ³¨Î±è¯†åˆ«")
        else:
            self.alpha_values = [-1.0, -0.5, 0.0, 0.5, 1.0]
            self.length_values = [0.0, 0.1, 0.5]
            self.phi_bar_values = [0.0, np.pi / 4, np.pi / 2]
            self.position_samples = 20

    def load_mstar_data_robust(self, raw_file_path: str) -> Tuple[np.ndarray, np.ndarray]:
        """
        ç¨³å¥çš„MSTARæ•°æ®åŠ è½½ - ä¿®å¤ç‰ˆv3
        æ­£ç¡®è§£æ[å¹…åº¦..., ç›¸ä½...]æ ¼å¼çš„big-endianæ•°æ®
        """
        print(f"ğŸ“‚ ç¨³å¥åŠ è½½MSTARæ•°æ® (v3): {raw_file_path}")

        try:
            with open(raw_file_path, "rb") as f:
                data = f.read()

            # æ ¹æ®MATLABè„šæœ¬ï¼Œæ•°æ®ä¸ºfloat32, big-endian
            num_floats = len(data) // 4
            # ä½¿ç”¨ '>' æŒ‡å®š big-endian
            all_values = struct.unpack(f">{num_floats}f", data)
            all_values = np.array(all_values)

            # --- å…³é”®ä¿®å¤ï¼šæ­£ç¡®åˆ†ç¦»å¹…åº¦å’Œç›¸ä½ ---
            num_pixels = self.image_size[0] * self.image_size[1]
            if len(all_values) != 2 * num_pixels:
                raise ValueError(f"æ•°æ®å°ºå¯¸ä¸åŒ¹é…ï¼ŒæœŸæœ› {2*num_pixels} ä¸ªå€¼ï¼Œå®é™…å¾—åˆ° {len(all_values)}")

            magnitude_flat = all_values[:num_pixels]
            phase_flat = all_values[num_pixels:]

            # --- é‡æ„å¤æ•°å›¾åƒ ---
            complex_image_flat = magnitude_flat * np.exp(1j * phase_flat)
            complex_image = complex_image_flat.reshape(self.image_size)

            # æ•°æ®æœ‰æ•ˆæ€§æ£€æŸ¥
            if np.any(np.isnan(complex_image)):
                print("   âš ï¸ æ£€æµ‹åˆ°NaNå€¼ï¼Œè¿›è¡Œæ¸…ç†...")
                complex_image = np.nan_to_num(complex_image)

            magnitude = np.abs(complex_image)

            print(f"   âœ… æ•°æ®åŠ è½½æˆåŠŸ")
            print(f"      å›¾åƒå°ºå¯¸: {complex_image.shape}")
            print(f"      ä¿¡å·èƒ½é‡: {np.linalg.norm(complex_image):.3f}")

            return magnitude, complex_image

        except Exception as e:
            print(f"   âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
            # è¿”å›é›¶æ•°æ®
            return np.zeros(self.image_size), np.zeros(self.image_size, dtype=complex)

    def preprocess_data_robust(self, complex_image: np.ndarray) -> np.ndarray:
        """ç¨³å¥çš„æ•°æ®é¢„å¤„ç†"""
        print("âš™ï¸ ç¨³å¥æ•°æ®é¢„å¤„ç†...")

        # ä¿¡å·å‘é‡åŒ–
        signal = complex_image.flatten()

        # æ£€æŸ¥å’Œæ¸…ç†æ•°æ®
        if np.any(np.isnan(signal)) or np.any(np.isinf(signal)):
            print("   âš ï¸ æ£€æµ‹åˆ°å¼‚å¸¸å€¼ï¼Œè¿›è¡Œæ¸…ç†...")
            signal = np.where(np.isnan(signal) | np.isinf(signal), 0.0 + 0.0j, signal)

        # è®¡ç®—ä¿¡å·ç‰¹å¾
        signal_energy = np.linalg.norm(signal)
        signal_max = np.max(np.abs(signal))

        if signal_energy < 1e-12:
            print("   âš ï¸ ä¿¡å·èƒ½é‡è¿‡ä½ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®...")
            # åˆ›å»ºç®€å•çš„æµ‹è¯•ä¿¡å·
            signal = 0.1 * (np.random.randn(len(signal)) + 1j * np.random.randn(len(signal)))
            signal_energy = np.linalg.norm(signal)

        # ç¨³å¥å½’ä¸€åŒ–
        signal_normalized = signal / np.sqrt(signal_energy)

        print(f"   ä¿¡å·é•¿åº¦: {len(signal)}")
        print(f"   å¤„ç†åèƒ½é‡: {np.linalg.norm(signal_normalized):.3f}")
        print(f"   æœ€å¤§å¹…åº¦: {np.max(np.abs(signal_normalized)):.3f}")

        return signal_normalized

    def _generate_robust_asc_atom(
        self,
        x: float,
        y: float,
        alpha: float,
        length: float = 0.0,  # é»˜è®¤ä¸ºç‚¹æ•£å°„ä½“
        phi_bar: float = 0.0,
        fx_range: np.ndarray = None,
        fy_range: np.ndarray = None,
    ) -> np.ndarray:
        """v3ç‰ˆæœ¬: ä¿®å¤äº†sincå‡½æ•°å‚æ•°çš„ç‰©ç†æ¨¡å‹"""
        if fx_range is None:
            fx_range = np.linspace(-self.B / 2, self.B / 2, self.image_size[0])
        if fy_range is None:
            fy_range = np.linspace(
                -self.fc * np.sin(self.omega / 2), self.fc * np.sin(self.omega / 2), self.image_size[1]
            )

        FX, FY = np.meshgrid(fx_range, fy_range, indexing="ij")

        # --- å…³é”®ä¿®å¤ï¼šç»Ÿä¸€ç‰©ç†å°ºåº¦ ---
        C = 299792458.0  # å…‰é€Ÿ
        x_meters = x * (self.scene_size / 2.0)  # å°†å½’ä¸€åŒ–åæ ‡[-1,1]è½¬ä¸ºç±³
        y_meters = y * (self.scene_size / 2.0)

        f_magnitude = np.sqrt(FX**2 + FY**2)

        theta = np.arctan2(FY, FX)

        # 1. é¢‘ç‡ä¾èµ–é¡¹ (f/fc)^Î± - æ•°å€¼ç¨³å®šç‰ˆæœ¬
        f_magnitude_safe = np.where(f_magnitude < 1e-9, 1e-9, f_magnitude)
        if alpha == 0:
            frequency_term = np.ones_like(f_magnitude_safe)
        else:
            normalized_freq = f_magnitude_safe / self.fc
            frequency_term = np.power(normalized_freq, alpha)

        # 2. ä½ç½®ç›¸ä½é¡¹ - ä¿®å¤ç‰©ç†å°ºåº¦
        # æ­£ç¡®å…¬å¼: exp(-j*2*pi/c * (FX*x_m + FY*y_m))
        position_phase = -2j * np.pi / C * (FX * x_meters + FY * y_meters)

        # 3. é•¿åº¦/æ–¹ä½è§’é¡¹ - ä¿®å¤ç‰©ç†å…¬å¼
        length_term = np.ones_like(f_magnitude_safe, dtype=float)
        if length > 1e-6:
            k = 2 * np.pi * f_magnitude_safe / C
            angle_diff = theta - phi_bar

            # --- å…³é”®ä¿®å¤ï¼šä¿®æ­£sincå‡½æ•°çš„å‚æ•° ---
            # ç‰©ç†é¡¹ Y = k * length * np.sin(angle_diff) / 2
            # æˆ‘ä»¬éœ€è¦è®¡ç®— sinc(Y/pi)
            Y = k * length * np.sin(angle_diff) / 2  # æ³¨æ„è¿™é‡Œçš„é™¤2æ˜¯é’ˆå¯¹çº¿çŠ¶æ•£å°„ä½“æ¨¡å‹
            sinc_arg = Y / np.pi
            length_term = np.sinc(sinc_arg)

        # ç»„åˆé¢‘åŸŸå“åº”
        H_asc = frequency_term * length_term * np.exp(position_phase)

        # IFFT åˆ°ç©ºåŸŸ
        atom = np.fft.ifftshift(np.fft.ifft2(np.fft.ifftshift(H_asc)))

        return atom

    def estimate_params_in_roi(
        self, complex_image: np.ndarray, center_x: float, center_y: float, roi_size: int = 24
    ) -> Optional[Dict]:
        """
        ç¬¬äºŒé˜¶æ®µV2ç‰ˆæœ¬ï¼šåœ¨ROIå†…è¿›è¡Œ"æ¨¡å‹åŒ¹é…+å±€éƒ¨å¾®è°ƒ"
        """
        img_h, img_w = self.image_size
        px = int((center_x + 1) / 2 * img_w)
        py = int((center_y + 1) / 2 * img_h)
        half_size = roi_size // 2

        y_start, y_end = py - half_size, py + half_size
        x_start, x_end = px - half_size, px + half_size
        if not (0 <= y_start < y_end <= img_h and 0 <= x_start < x_end <= img_w):
            return None

        roi_signal = complex_image[y_start:y_end, x_start:x_end]

        # --- æ­¥éª¤A: æ¨¡å‹åŒ¹é… ---
        # åœ¨ç¦»æ•£çš„å‚æ•°ç©ºé—´ï¼ˆalpha, length, phi_barï¼‰ä¸­æ‰¾åˆ°æœ€ä½³æ¨¡å‹
        best_match = {"error": float("inf")}

        for alpha in self.alpha_values:
            for length in self.length_values:
                for phi_bar in self.phi_bar_values:
                    # ç”Ÿæˆç†è®ºåŸå­
                    atom_full = self._generate_robust_asc_atom(center_x, center_y, alpha, length, phi_bar)
                    atom_roi = atom_full[y_start:y_end, x_start:x_end]

                    # è®¡ç®—è¯¥æ¨¡å‹ä¸‹çš„æœ€ä½³å¤å¹…åº¦ (é€šè¿‡æŠ•å½±)
                    atom_energy = np.linalg.norm(atom_roi)
                    if atom_energy < 1e-9:
                        continue

                    complex_amp = np.vdot(atom_roi, roi_signal) / atom_energy**2

                    # è®¡ç®—è¯¥æ¨¡å‹ä¸‹çš„æ‹Ÿåˆè¯¯å·®
                    error = np.linalg.norm(roi_signal - complex_amp * atom_roi)

                    if error < best_match["error"]:
                        best_match = {
                            "error": error,
                            "alpha": alpha,
                            "length": length,
                            "phi_bar": phi_bar,
                            "amp": np.abs(complex_amp),
                            "phase": np.angle(complex_amp),
                        }

        # --- æ­¥éª¤B: å±€éƒ¨å¾®è°ƒ ---
        # ä½¿ç”¨ä¸Šä¸€æ­¥æ‰¾åˆ°çš„æœ€ä½³å‚æ•°ä½œä¸ºåˆå§‹å€¼ï¼Œå¯¹è¿ç»­å‚æ•°(x, y, A, Ï†)è¿›è¡Œå¾®è°ƒ

        # å›ºå®šçš„ç¦»æ•£å‚æ•°
        alpha_fixed = best_match["alpha"]
        length_fixed = best_match["length"]
        phi_bar_fixed = best_match["phi_bar"]

        def objective(params):  # x, y, amp, phase
            x, y, amp, phase = params
            atom_full = self._generate_robust_asc_atom(x, y, alpha_fixed, length_fixed, phi_bar_fixed)
            atom_roi = atom_full[y_start:y_end, x_start:x_end]
            reconstruction = amp * np.exp(1j * phase) * atom_roi
            return np.linalg.norm(roi_signal - reconstruction)

        x0 = [center_x, center_y, best_match["amp"], best_match["phase"]]
        # é™åˆ¶å¾®è°ƒèŒƒå›´ï¼Œé˜²æ­¢ä¼˜åŒ–è·‘é£
        bounds = [
            (center_x - 0.1, center_x + 0.1),
            (center_y - 0.1, center_y + 0.1),
            (0, 2 * best_match["amp"]),
            (-np.pi, np.pi),
        ]

        result = minimize(objective, x0, method="L-BFGS-B", bounds=bounds, options={"maxiter": 50})

        if result.success:
            return {
                "alpha": alpha_fixed,
                "length": length_fixed,
                "phi_bar": phi_bar_fixed,
                "x": result.x[0],
                "y": result.x[1],
                "estimated_amplitude": result.x[2],
                "estimated_phase": result.x[3],
                "scattering_type": self._classify_scattering_type(alpha_fixed),
                "optimization_success": True,
            }
        else:  # ä¼˜åŒ–å¤±è´¥ï¼Œè¿”å›ç²—åŒ¹é…ç»“æœ
            return {
                "alpha": best_match["alpha"],
                "length": best_match["length"],
                "phi_bar": best_match["phi_bar"],
                "x": center_x,
                "y": center_y,
                "estimated_amplitude": best_match["amp"],
                "estimated_phase": best_match["phase"],
                "scattering_type": self._classify_scattering_type(best_match["alpha"]),
                "optimization_success": False,
            }

    def build_compact_dictionary(self) -> Tuple[np.ndarray, List[Dict]]:
        """æ„å»ºç´§å‡‘é«˜æ•ˆçš„å­—å…¸"""
        print(f"ğŸ“š æ„å»ºç´§å‡‘ASCå­—å…¸...")

        # é¢‘ç‡é‡‡æ ·
        fx_range = np.linspace(-self.B / 2, self.B / 2, self.image_size[0])
        fy_range = np.linspace(-self.fc * np.sin(self.omega / 2), self.fc * np.sin(self.omega / 2), self.image_size[1])

        # ä½ç½®é‡‡æ ·
        x_positions = np.linspace(-0.8, 0.8, self.position_samples)
        y_positions = np.linspace(-0.8, 0.8, self.position_samples)

        dictionary_atoms = []
        param_grid = []

        valid_count = 0
        total_count = 0

        for x in x_positions:
            for y in y_positions:
                for alpha in self.alpha_values:
                    for length in self.length_values:
                        for phi_bar in self.phi_bar_values:
                            total_count += 1

                            atom = self._generate_robust_asc_atom(x, y, alpha, length, phi_bar, fx_range, fy_range)

                            atom_flat = atom.flatten()
                            atom_energy = np.linalg.norm(atom_flat)

                            # æ£€æŸ¥åŸå­æœ‰æ•ˆæ€§
                            if (
                                atom_energy > 1e-12
                                and np.isfinite(atom_energy)
                                and not np.any(np.isnan(atom_flat))
                                and not np.any(np.isinf(atom_flat))
                            ):

                                atom_normalized = atom_flat / atom_energy
                                dictionary_atoms.append(atom_normalized)
                                param_grid.append(
                                    {
                                        "x": x,
                                        "y": y,
                                        "alpha": alpha,
                                        "length": length,
                                        "phi_bar": phi_bar,
                                        "atom_energy": atom_energy,
                                        "scattering_type": self._classify_scattering_type(alpha),
                                    }
                                )
                                valid_count += 1

        dictionary = np.column_stack(dictionary_atoms)

        print(f"   æœ‰æ•ˆåŸå­: {valid_count}/{total_count} ({valid_count/total_count*100:.1f}%)")
        print(f"   å­—å…¸å°ºå¯¸: {dictionary.shape}")
        print(f"   å†…å­˜å ç”¨: ~{dictionary.nbytes / 1024**2:.1f} MB")

        return dictionary, param_grid

    def _classify_scattering_type(self, alpha: float) -> str:
        """æ•£å°„ç±»å‹åˆ†ç±»"""
        types = {-1.0: "å°–é¡¶ç»•å°„", -0.5: "è¾¹ç¼˜ç»•å°„", 0.0: "æ ‡å‡†æ•£å°„", 0.5: "è¡¨é¢æ•£å°„", 1.0: "é•œé¢åå°„"}
        return types.get(alpha, f"Î±={alpha}")

    def improved_adaptive_extraction(
        self, signal: np.ndarray, dictionary: np.ndarray, param_grid: List[Dict]
    ) -> List[Dict]:
        """æ”¹è¿›çš„è‡ªé€‚åº”æå–ç®—æ³•"""
        print(f"ğŸ¯ å¼€å§‹æ”¹è¿›ç‰ˆè‡ªé€‚åº”æå–...")

        residual_signal = signal.copy()
        extracted_scatterers = []

        initial_energy = np.linalg.norm(residual_signal)
        energy_threshold = initial_energy * self.adaptive_threshold

        print(f"   åˆå§‹èƒ½é‡: {initial_energy:.6f}")
        print(f"   åœæ­¢é˜ˆå€¼: {energy_threshold:.6f}")

        for iteration in range(self.max_iterations):
            current_energy = np.linalg.norm(residual_signal)

            # å¤šé‡åœæ­¢æ¡ä»¶
            if current_energy < energy_threshold:
                print(f"   ğŸ’¡ è¾¾åˆ°èƒ½é‡é˜ˆå€¼ï¼Œåœæ­¢è¿­ä»£")
                break

            if len(extracted_scatterers) >= self.max_scatterers:
                print(f"   ğŸ’¡ è¾¾åˆ°æœ€å¤§æ•£å°„ä¸­å¿ƒæ•°ï¼Œåœæ­¢è¿­ä»£")
                break

            # æ£€æŸ¥åœæ»
            if len(extracted_scatterers) >= 3:
                recent_energies = [s.get("residual_energy", current_energy) for s in extracted_scatterers[-3:]]
                if max(recent_energies) - min(recent_energies) < current_energy * 0.001:
                    print(f"   ğŸ’¡ èƒ½é‡å‡å°‘åœæ»ï¼Œåœæ­¢è¿­ä»£")
                    break

            # æ‰¾åˆ°æœ€ä½³åŒ¹é…
            best_idx, best_coef = self._find_best_match_robust(residual_signal, dictionary)
            if best_idx is None:
                print(f"   ğŸ’¡ æœªæ‰¾åˆ°æœ‰æ•ˆåŒ¹é…ï¼Œåœæ­¢è¿­ä»£")
                break

            initial_params = param_grid[best_idx].copy()

            # å‚æ•°ç²¾åŒ–
            refined_params = self._refine_point_scatterer_v2(initial_params, residual_signal, best_coef)

            # è®¡ç®—è´¡çŒ®å¹¶æ›´æ–°æ®‹å·®
            contribution = self._calculate_scatterer_contribution(refined_params)

            if np.linalg.norm(contribution) < current_energy * 0.001:
                print(f"   ğŸ’¡ æ•£å°„ä¸­å¿ƒè´¡çŒ®è¿‡å°ï¼Œåœæ­¢è¿­ä»£")
                break

            # æ›´æ–°æ®‹å·®
            new_residual = residual_signal - contribution
            new_energy = np.linalg.norm(new_residual)

            # éªŒè¯èƒ½é‡å‡å°‘
            if new_energy >= current_energy * 0.999:  # å‡ ä¹æ²¡æœ‰æ”¹å–„
                print(f"   ğŸ’¡ èƒ½é‡å‡å°‘ä¸è¶³ï¼Œåœæ­¢è¿­ä»£")
                break

            residual_signal = new_residual
            refined_params["residual_energy"] = new_energy
            extracted_scatterers.append(refined_params)

            if iteration < 5 or (iteration + 1) % 5 == 0:
                reduction = (current_energy - new_energy) / current_energy
                print(f"   è¿­ä»£ {iteration+1}: {current_energy:.6f} â†’ {new_energy:.6f} (å‡å°‘{reduction:.2%})")

        final_energy = np.linalg.norm(residual_signal)
        total_reduction = (initial_energy - final_energy) / initial_energy

        print(f"âœ… æ”¹è¿›ç‰ˆæå–å®Œæˆ")
        print(f"   æ•£å°„ä¸­å¿ƒæ•°: {len(extracted_scatterers)}")
        print(f"   æ€»èƒ½é‡å‡å°‘: {total_reduction:.1%}")

        return extracted_scatterers

    def _find_best_match_robust(
        self, signal: np.ndarray, dictionary: np.ndarray
    ) -> Tuple[Optional[int], Optional[complex]]:
        """ç¨³å¥çš„æœ€ä½³åŒ¹é…æŸ¥æ‰¾"""
        # æ£€æŸ¥è¾“å…¥æœ‰æ•ˆæ€§
        if np.any(np.isnan(signal)) or np.any(np.isinf(signal)):
            return None, None

        signal_real = np.concatenate([signal.real, signal.imag])
        dictionary_real = np.concatenate([dictionary.real, dictionary.imag], axis=0)

        # æ£€æŸ¥å­—å…¸æœ‰æ•ˆæ€§
        if np.any(np.isnan(dictionary_real)) or np.any(np.isinf(dictionary_real)):
            return None, None

        try:
            omp = OrthogonalMatchingPursuit(n_nonzero_coefs=1, fit_intercept=False)
            omp.fit(dictionary_real, signal_real)

            nonzero_indices = np.nonzero(omp.coef_)[0]
            if len(nonzero_indices) == 0:
                return None, None

            best_idx = nonzero_indices[0]
            selected_atom = dictionary[:, best_idx]

            # è®¡ç®—å¤æ•°ç³»æ•°
            numerator = np.vdot(selected_atom, signal)
            denominator = np.vdot(selected_atom, selected_atom)

            if abs(denominator) < 1e-12:
                return None, None

            complex_coef = numerator / denominator

            return best_idx, complex_coef

        except Exception as e:
            print(f"   âš ï¸ OMPåŒ¹é…å¼‚å¸¸: {str(e)}")
            return None, None

    def _refine_point_scatterer_v2(
        self, initial_params: Dict, target_signal: np.ndarray, initial_coef: complex
    ) -> Dict:
        """
        çœŸæ­£çš„å‚æ•°ç²¾åŒ–å‡½æ•° - ä¿®å¤ä¼˜åŒ–é€»è¾‘
        å…³é”®ï¼šå¯¹å½“å‰æ®‹å·®è¿›è¡Œä¼˜åŒ–ï¼Œè€ŒéåŸå§‹ä¿¡å·
        """
        alpha_fixed = initial_params["alpha"]

        # ä¼˜åŒ–ç›®æ ‡å‡½æ•°
        def objective(params):
            x, y, amp, phase = params
            # ç”ŸæˆåŸå­
            atom = self._generate_robust_asc_atom(x=x, y=y, alpha=alpha_fixed)
            atom_flat = atom.flatten()
            atom_energy = np.linalg.norm(atom_flat)

            if atom_energy < 1e-12:
                return 1e6  # æƒ©ç½šæ— æ•ˆåŸå­

            atom_normalized = atom_flat / atom_energy
            # é‡æ„
            reconstruction = amp * np.exp(1j * phase) * atom_normalized
            # å…³é”®ï¼šè®¡ç®—ä¸å½“å‰æ®‹å·®(target_signal)çš„è¯¯å·®
            return np.linalg.norm(target_signal - reconstruction)

        # åˆå§‹å€¼å’Œè¾¹ç•Œ
        x0 = [initial_params["x"], initial_params["y"], np.abs(initial_coef), np.angle(initial_coef)]
        bounds = [(-1, 1), (-1, 1), (0, 10 * np.abs(initial_coef)), (-np.pi, np.pi)]

        # æ‰§è¡Œä¼˜åŒ–
        try:
            from scipy.optimize import minimize

            result = minimize(objective, x0, method="L-BFGS-B", bounds=bounds, options={"maxiter": 50})

            refined_params = initial_params.copy()
            if result.success and result.fun < np.linalg.norm(target_signal):
                refined_params.update(
                    {
                        "x": result.x[0],
                        "y": result.x[1],
                        "estimated_amplitude": result.x[2],
                        "estimated_phase": result.x[3],
                        "optimization_success": True,
                        "optimization_error": result.fun,
                    }
                )
            else:  # ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨ç²—åŒ¹é…ç»“æœ
                refined_params.update(
                    {
                        "estimated_amplitude": np.abs(initial_coef),
                        "estimated_phase": np.angle(initial_coef),
                        "optimization_success": False,
                    }
                )

        except Exception as e:
            print(f"   âš ï¸ å‚æ•°ä¼˜åŒ–å¼‚å¸¸: {str(e)}")
            refined_params = initial_params.copy()
            refined_params.update(
                {
                    "estimated_amplitude": np.abs(initial_coef),
                    "estimated_phase": np.angle(initial_coef),
                    "optimization_success": False,
                }
            )

        return refined_params

    def _calculate_scatterer_contribution(self, scatterer_params: Dict) -> np.ndarray:
        """è®¡ç®—æ•£å°„ä¸­å¿ƒå¯¹ä¿¡å·çš„è´¡çŒ®"""
        fx_range = np.linspace(-self.B / 2, self.B / 2, self.image_size[0])
        fy_range = np.linspace(-self.fc * np.sin(self.omega / 2), self.fc * np.sin(self.omega / 2), self.image_size[1])

        atom = self._generate_robust_asc_atom(
            scatterer_params["x"],
            scatterer_params["y"],
            scatterer_params["alpha"],
            scatterer_params.get("length", 0.0),
            scatterer_params.get("phi_bar", 0.0),
            fx_range,
            fy_range,
        )

        atom_flat = atom.flatten()
        atom_energy = np.linalg.norm(atom_flat)

        if atom_energy > 1e-12:
            atom_normalized = atom_flat / atom_energy
            contribution = (
                scatterer_params["estimated_amplitude"]
                * np.exp(1j * scatterer_params["estimated_phase"])
                * atom_normalized
            )
            return contribution
        else:
            return np.zeros_like(atom_flat)

    def extract_asc_scatterers_v2(self, complex_image: np.ndarray) -> List[Dict]:
        """
        å®Œæ•´çš„v3ç‰ˆæœ¬ASCæå–æµç¨‹ - å¸¦çœŸæ­£çš„ä¼˜åŒ–
        å®ç°æ­£ç¡®çš„"åŒ¹é…-ä¼˜åŒ–-å‡å»"å¾ªç¯
        """
        print(f"ğŸš€ å¼€å§‹v3ç‰ˆæœ¬ASCæå–æµç¨‹ (å¸¦ä¼˜åŒ–)")
        print("=" * 60)

        # æ•°æ®é¢„å¤„ç†
        signal = self.preprocess_data_robust(complex_image)

        # æ„å»ºå­—å…¸
        dictionary, param_grid = self.build_compact_dictionary()

        # åˆå§‹åŒ–
        residual_signal = signal.copy()
        extracted_scatterers = []

        initial_energy = np.linalg.norm(residual_signal)
        energy_threshold = initial_energy * self.adaptive_threshold

        print(f"   åˆå§‹èƒ½é‡: {initial_energy:.6f}")
        print(f"   åœæ­¢é˜ˆå€¼: {energy_threshold:.6f}")

        for iteration in range(self.max_iterations):
            current_energy = np.linalg.norm(residual_signal)

            # åœæ­¢æ¡ä»¶æ£€æŸ¥
            if current_energy < energy_threshold:
                print(f"   ğŸ’¡ è¾¾åˆ°èƒ½é‡é˜ˆå€¼ï¼Œåœæ­¢è¿­ä»£")
                break

            if len(extracted_scatterers) >= self.max_scatterers:
                print(f"   ğŸ’¡ è¾¾åˆ°æœ€å¤§æ•£å°„ä¸­å¿ƒæ•°ï¼Œåœæ­¢è¿­ä»£")
                break

            # --- 1. åŒ¹é… (Matching) ---
            best_idx, initial_coef = self._find_best_match_robust(residual_signal, dictionary)
            if best_idx is None:
                print(f"   ğŸ’¡ æœªæ‰¾åˆ°æœ‰æ•ˆåŒ¹é…ï¼Œåœæ­¢è¿­ä»£")
                break

            initial_params = param_grid[best_idx].copy()

            # --- 2. ä¼˜åŒ– (Optimization) ---
            # å…³é”®ï¼šå¯¹å½“å‰æ®‹å·®è¿›è¡Œä¼˜åŒ–
            refined_params = self._refine_point_scatterer_v2(initial_params, residual_signal, initial_coef)

            # --- 3. å‡å» (Subtraction) ---
            contribution = self._calculate_scatterer_contribution(refined_params)

            # æ£€æŸ¥è´¡çŒ®æœ‰æ•ˆæ€§
            contribution_energy = np.linalg.norm(contribution)
            if contribution_energy < current_energy * 0.001:
                print(f"   ğŸ’¡ æ•£å°„ä¸­å¿ƒè´¡çŒ®è¿‡å°({contribution_energy:.2e})ï¼Œåœæ­¢è¿­ä»£")
                break

            new_residual_signal = residual_signal - contribution
            new_energy = np.linalg.norm(new_residual_signal)

            # å…³é”®ï¼šæ£€æŸ¥èƒ½é‡æ˜¯å¦æœ‰æ•ˆå‡å°‘
            if new_energy >= current_energy:
                print(f"   âš ï¸ èƒ½é‡å¢åŠ ({current_energy:.6f} â†’ {new_energy:.6f})ï¼Œä¼˜åŒ–å¤±è´¥ï¼Œåœæ­¢è¿­ä»£")
                break

            # æ›´æ–°æ®‹å·®å’Œç»“æœ
            residual_signal = new_residual_signal
            refined_params["residual_energy"] = new_energy
            extracted_scatterers.append(refined_params)

            # è¿›åº¦æŠ¥å‘Š
            reduction = (current_energy - new_energy) / current_energy
            opt_status = "âœ…" if refined_params.get("optimization_success", False) else "âš ï¸"
            print(
                f"   è¿­ä»£ {iteration+1}: {opt_status} æå– {refined_params['scattering_type']}, "
                f"å¹…åº¦ {refined_params['estimated_amplitude']:.3f}, "
                f"èƒ½é‡å‡å°‘ {reduction:.2%}"
            )

        # æœ€ç»ˆç»“æœåˆ†æ
        final_energy = np.linalg.norm(residual_signal)
        total_reduction = (initial_energy - final_energy) / initial_energy

        print(f"\nâœ… v3ç‰ˆæœ¬æå–å®Œæˆ")
        print(f"   æ•£å°„ä¸­å¿ƒæ•°: {len(extracted_scatterers)}")
        print(f"   æ€»èƒ½é‡å‡å°‘: {total_reduction:.1%}")

        if extracted_scatterers:
            print(f"\nğŸ“Š æå–ç»“æœåˆ†æ:")
            alpha_dist = {}
            opt_success_count = 0
            for s in extracted_scatterers:
                stype = s["scattering_type"]
                alpha_dist[stype] = alpha_dist.get(stype, 0) + 1
                if s.get("optimization_success", False):
                    opt_success_count += 1

            print(f"   æ•£å°„ç±»å‹åˆ†å¸ƒ: {alpha_dist}")
            print(
                f"   ä¼˜åŒ–æˆåŠŸç‡: {opt_success_count}/{len(extracted_scatterers)} ({opt_success_count/len(extracted_scatterers)*100:.1f}%)"
            )

        return extracted_scatterers


def visualize_extraction_results(complex_image, scatterers, save_path=None):
    """
    å¯è§†åŒ–æ•£å°„ä¸­å¿ƒæå–ç»“æœ
    å°†æ•£å°„ä¸­å¿ƒå åŠ åœ¨åŸå§‹SARå›¾åƒä¸Šæ˜¾ç¤º
    """
    if not scatterers:
        print("âš ï¸ No scatterers extracted, cannot visualize.")
        return

    magnitude = np.abs(complex_image)

    fig, ax = plt.subplots(1, 1, figsize=(10, 10))

    # 1. æ˜¾ç¤ºåŸå§‹SARå›¾åƒä½œä¸ºèƒŒæ™¯
    ax.imshow(magnitude, cmap="gray", origin="lower", extent=(-1, 1, -1, 1), alpha=0.8)

    # 2. ç»˜åˆ¶æå–çš„æ•£å°„ä¸­å¿ƒ
    alpha_colors = {
        -1.0: "blue",  # å°–é¡¶ç»•å°„
        -0.5: "cyan",  # è¾¹ç¼˜ç»•å°„
        0.0: "green",  # æ ‡å‡†æ•£å°„
        0.5: "orange",  # è¡¨é¢æ•£å°„
        1.0: "red",  # é•œé¢åå°„
    }

    alpha_names = {
        -1.0: "Dihedral (Î±=-1.0)",
        -0.5: "Edge Diffraction (Î±=-0.5)",
        0.0: "Isotropic (Î±=0.0)",
        0.5: "Surface (Î±=0.5)",
        1.0: "Specular (Î±=1.0)",
    }

    # ç»Ÿè®¡æ•£å°„ä¸­å¿ƒ
    plotted_types = set()

    for i, sc in enumerate(scatterers):
        x, y = sc["x"], sc["y"]
        alpha = sc["alpha"]
        amplitude = sc["estimated_amplitude"]
        opt_success = sc.get("optimization_success", False)

        # é¢œè‰²ä»£è¡¨æ•£å°„ç±»å‹(alpha)
        color = alpha_colors.get(alpha, "purple")
        # å¤§å°ä»£è¡¨å¹…åº¦
        size = 100 + amplitude * 1000  # è°ƒæ•´ç³»æ•°ä»¥è·å¾—å¥½çš„è§†è§‰æ•ˆæœ

        # è¾¹æ¡†è¡¨ç¤ºä¼˜åŒ–æˆåŠŸä¸å¦
        edge_color = "white" if opt_success else "black"
        edge_width = 2 if opt_success else 1

        scatter = ax.scatter(x, y, s=size, c=color, alpha=0.7, edgecolors=edge_color, linewidth=edge_width)

        # æ ‡æ³¨æ•£å°„ä¸­å¿ƒç¼–å·
        ax.annotate(
            f"{i+1}", (x, y), xytext=(5, 5), textcoords="offset points", fontsize=8, color="white", weight="bold"
        )

        plotted_types.add(alpha)

    # è®¾ç½®å›¾åƒå±æ€§
    ax.set_title(f"ASC Scattering Centers - {len(scatterers)} Extracted", fontsize=14, weight="bold")
    ax.set_xlabel("X Position (Normalized)", fontsize=12)
    ax.set_ylabel("Y Position (Normalized)", fontsize=12)
    ax.set_xlim(-1, 1)
    ax.set_ylim(-1, 1)
    ax.grid(True, linestyle="--", alpha=0.3)

    # åˆ›å»ºå›¾ä¾‹
    legend_elements = []
    for alpha in sorted(plotted_types):
        color = alpha_colors.get(alpha, "purple")
        name = alpha_names.get(alpha, f"Î±={alpha}")
        legend_elements.append(
            plt.scatter([], [], c=color, s=100, alpha=0.7, edgecolors="white", linewidth=2, label=name)
        )

    # æ·»åŠ ä¼˜åŒ–æˆåŠŸè¯´æ˜
    legend_elements.append(
        plt.scatter([], [], c="gray", s=100, alpha=0.7, edgecolors="white", linewidth=2, label="ä¼˜åŒ–æˆåŠŸ")
    )
    legend_elements.append(
        plt.scatter([], [], c="gray", s=100, alpha=0.7, edgecolors="black", linewidth=1, label="ç²—åŒ¹é…")
    )

    ax.legend(handles=legend_elements, title="æ•£å°„ç±»å‹ & ä¼˜åŒ–çŠ¶æ€", loc="upper left", bbox_to_anchor=(1.02, 1))

    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    stats_text = f"Statistics:\n"
    stats_text += f"Total Scatterers: {len(scatterers)}\n"
    opt_count = sum(1 for s in scatterers if s.get("optimization_success", False))
    stats_text += f"Optimized: {opt_count}/{len(scatterers)}\n"

    ax.text(
        0.02,
        0.98,
        stats_text,
        transform=ax.transAxes,
        fontsize=10,
        verticalalignment="top",
        bbox=dict(boxstyle="round", facecolor="white", alpha=0.8),
    )

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=200, bbox_inches="tight")
        print(f"ğŸ–¼ï¸ å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {save_path}")

    plt.show()


def main():
    """v3ç‰ˆæœ¬æ¼”ç¤º - å¸¦çœŸæ­£çš„ä¼˜åŒ–å’Œå¯è§†åŒ–"""
    print("ğŸ”§ ä¿®å¤ç‰ˆASCæå–ç³»ç»Ÿv3")
    print("è§£å†³ç‰©ç†å°ºåº¦ã€å‚æ•°ç²¾åŒ–å’Œæ”¶æ•›æ€§é—®é¢˜")

    asc_v3 = ASCExtractionFixedV2(
        extraction_mode="point_only", adaptive_threshold=0.05, max_iterations=15, max_scatterers=10
    )

    print("\nğŸš€ å®Œæ•´ä½¿ç”¨æµç¨‹:")
    print("1. magnitude, complex_image = asc_v3.load_mstar_data_robust('data.raw')")
    print("2. scatterers = asc_v3.extract_asc_scatterers_v2(complex_image)")
    print("3. visualize_extraction_results(complex_image, scatterers, 'result.png')")

    return asc_v3


if __name__ == "__main__":
    asc_system = main()
