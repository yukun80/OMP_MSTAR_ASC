"""
Fixed ASC Extraction System v2
ä¿®å¤ç‰ˆASCæå–ç³»ç»Ÿ v2

åœ¨v1åŸºç¡€ä¸Šè¿›ä¸€æ­¥ä¿®å¤ï¼š
1. MSTARæ•°æ®åŠ è½½NaNé—®é¢˜
2. é‡æ„è¯¯å·®è®¡ç®—é€»è¾‘
3. è¿­ä»£æ”¶æ•›æ€§èƒ½ä¼˜åŒ–
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize
from sklearn.linear_model import OrthogonalMatchingPursuit
import struct
from typing import Tuple, List, Dict, Optional
import warnings
import time

warnings.filterwarnings("ignore")


class ASCExtractionFixedV2:
    """ä¿®å¤ç‰ˆASCæå–ç³»ç»Ÿ v2"""

    def __init__(
        self,
        image_size: Tuple[int, int] = (128, 128),
        extraction_mode: str = "point_only",
        adaptive_threshold: float = 0.01,
        max_iterations: int = 30,
        max_scatterers: int = 20,
    ):
        self.image_size = image_size
        self.extraction_mode = extraction_mode
        self.adaptive_threshold = adaptive_threshold
        self.max_iterations = max_iterations
        self.max_scatterers = max_scatterers

        # SARç³»ç»Ÿå‚æ•°
        self.fc = 1e10  # ä¸­å¿ƒé¢‘ç‡
        self.B = 1e9  # å¸¦å®½
        self.omega = np.pi / 3  # åˆæˆå­”å¾„è§’

        # é…ç½®å‚æ•°
        self._configure_extraction_mode()

        print(f"ğŸ”§ ä¿®å¤ç‰ˆASCæå–ç³»ç»Ÿv2åˆå§‹åŒ–")
        print(f"   æå–æ¨¡å¼: {extraction_mode}")
        print(f"   è‡ªé€‚åº”é˜ˆå€¼: {adaptive_threshold}")

    def _configure_extraction_mode(self):
        """é…ç½®æå–æ¨¡å¼å‚æ•°"""
        if self.extraction_mode == "point_only":
            self.alpha_values = [-1.0, -0.5, 0.0, 0.5, 1.0]
            self.length_values = [0.0]
            self.phi_bar_values = [0.0]
            self.position_samples = 24  # é™ä½é‡‡æ ·æé«˜é€Ÿåº¦
            print("   ğŸ¯ ç‚¹æ•£å°„æ¨¡å¼ï¼šä¸“æ³¨Î±è¯†åˆ«")
        else:
            self.alpha_values = [-1.0, -0.5, 0.0, 0.5, 1.0]
            self.length_values = [0.0, 0.1, 0.5]
            self.phi_bar_values = [0.0, np.pi / 4, np.pi / 2]
            self.position_samples = 20

    def load_mstar_data_robust(self, raw_file_path: str) -> Tuple[np.ndarray, np.ndarray]:
        """ç¨³å¥çš„MSTARæ•°æ®åŠ è½½ - ä¿®å¤NaNé—®é¢˜"""
        print(f"ğŸ“‚ ç¨³å¥åŠ è½½MSTARæ•°æ®: {raw_file_path}")

        try:
            with open(raw_file_path, "rb") as f:
                data = f.read()

            # å°è¯•ä¸åŒçš„æ•°æ®æ ¼å¼è§£æ
            num_values = len(data) // 4

            # æ–¹æ³•1ï¼šå°è¯•little-endian float32
            try:
                real_imag = struct.unpack(f"<{num_values}f", data)
                print("   ä½¿ç”¨little-endian float32æ ¼å¼")
            except:
                # æ–¹æ³•2ï¼šå°è¯•big-endian float32
                try:
                    real_imag = struct.unpack(f">{num_values}f", data)
                    print("   ä½¿ç”¨big-endian float32æ ¼å¼")
                except:
                    # æ–¹æ³•3ï¼šå°è¯•int16æ ¼å¼å¹¶è½¬æ¢
                    num_values_int16 = len(data) // 2
                    int_data = struct.unpack(f"<{num_values_int16}h", data)
                    real_imag = [float(x) / 32767.0 for x in int_data]  # å½’ä¸€åŒ–
                    print("   ä½¿ç”¨int16æ ¼å¼å¹¶å½’ä¸€åŒ–")

            # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
            if np.any(np.isnan(real_imag)) or np.any(np.isinf(real_imag)):
                print("   âš ï¸ æ£€æµ‹åˆ°NaN/Infå€¼ï¼Œè¿›è¡Œæ•°æ®æ¸…ç†...")
                real_imag = np.array(real_imag)
                # å°†NaNå’ŒInfæ›¿æ¢ä¸º0
                real_imag = np.where(np.isnan(real_imag) | np.isinf(real_imag), 0.0, real_imag)

            # é‡æ„å¤å€¼å›¾åƒ
            if len(real_imag) % 2 != 0:
                real_imag = real_imag[:-1]  # ç¡®ä¿å¶æ•°é•¿åº¦

            complex_values = []
            for i in range(0, len(real_imag), 2):
                if i + 1 < len(real_imag):
                    complex_values.append(complex(real_imag[i], real_imag[i + 1]))

            # ç¡®ä¿æ•°æ®é•¿åº¦åŒ¹é…å›¾åƒå°ºå¯¸
            expected_size = self.image_size[0] * self.image_size[1]
            if len(complex_values) > expected_size:
                complex_values = complex_values[:expected_size]
            elif len(complex_values) < expected_size:
                # å¡«å……é›¶å€¼
                complex_values.extend([0.0 + 0.0j] * (expected_size - len(complex_values)))

            complex_image = np.array(complex_values).reshape(self.image_size)
            magnitude = np.abs(complex_image)

            # æœ€ç»ˆæ•°æ®éªŒè¯
            if np.any(np.isnan(complex_image)) or np.any(np.isinf(complex_image)):
                print("   âš ï¸ å¤å€¼å›¾åƒä¸­ä»æœ‰NaN/Infï¼Œè¿›è¡Œæœ€ç»ˆæ¸…ç†...")
                complex_image = np.where(np.isnan(complex_image) | np.isinf(complex_image), 0.0 + 0.0j, complex_image)
                magnitude = np.abs(complex_image)

            print(f"   âœ… æ•°æ®åŠ è½½æˆåŠŸ")
            print(f"      å›¾åƒå°ºå¯¸: {complex_image.shape}")
            print(f"      å¹…åº¦èŒƒå›´: [{np.min(magnitude):.3f}, {np.max(magnitude):.3f}]")
            print(f"      ä¿¡å·èƒ½é‡: {np.linalg.norm(complex_image):.3f}")
            print(f"      æœ‰æ•ˆæ•°æ®æ¯”ä¾‹: {np.sum(magnitude > 0) / magnitude.size:.1%}")

            return magnitude, complex_image

        except Exception as e:
            print(f"   âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
            # è¿”å›é›¶æ•°æ®ä½œä¸ºå¤‡é€‰
            complex_image = np.zeros(self.image_size, dtype=complex)
            magnitude = np.zeros(self.image_size)
            return magnitude, complex_image

    def preprocess_data_robust(self, complex_image: np.ndarray) -> np.ndarray:
        """ç¨³å¥çš„æ•°æ®é¢„å¤„ç†"""
        print("âš™ï¸ ç¨³å¥æ•°æ®é¢„å¤„ç†...")

        # ä¿¡å·å‘é‡åŒ–
        signal = complex_image.flatten()

        # æ£€æŸ¥å’Œæ¸…ç†æ•°æ®
        if np.any(np.isnan(signal)) or np.any(np.isinf(signal)):
            print("   âš ï¸ æ£€æµ‹åˆ°å¼‚å¸¸å€¼ï¼Œè¿›è¡Œæ¸…ç†...")
            signal = np.where(np.isnan(signal) | np.isinf(signal), 0.0 + 0.0j, signal)

        # è®¡ç®—ä¿¡å·ç‰¹å¾
        signal_energy = np.linalg.norm(signal)
        signal_max = np.max(np.abs(signal))

        if signal_energy < 1e-12:
            print("   âš ï¸ ä¿¡å·èƒ½é‡è¿‡ä½ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®...")
            # åˆ›å»ºç®€å•çš„æµ‹è¯•ä¿¡å·
            signal = 0.1 * (np.random.randn(len(signal)) + 1j * np.random.randn(len(signal)))
            signal_energy = np.linalg.norm(signal)

        # ç¨³å¥å½’ä¸€åŒ–
        signal_normalized = signal / np.sqrt(signal_energy)

        print(f"   ä¿¡å·é•¿åº¦: {len(signal)}")
        print(f"   å¤„ç†åèƒ½é‡: {np.linalg.norm(signal_normalized):.3f}")
        print(f"   æœ€å¤§å¹…åº¦: {np.max(np.abs(signal_normalized)):.3f}")

        return signal_normalized

    def _generate_robust_asc_atom(
        self,
        x: float,
        y: float,
        alpha: float,
        length: float,
        phi_bar: float,
        fx_range: np.ndarray,
        fy_range: np.ndarray,
    ) -> np.ndarray:
        """ç”Ÿæˆæ•°å€¼ç¨³å¥çš„ASCåŸå­"""
        # åˆ›å»ºé¢‘ç‡ç½‘æ ¼
        FX, FY = np.meshgrid(fx_range, fy_range, indexing="ij")
        f_magnitude = np.sqrt(FX**2 + FY**2)
        theta = np.arctan2(FY, FX)

        # æ•°å€¼ç¨³å®šå¤„ç†
        f_magnitude_safe = np.where(f_magnitude < 1e-8, 1e-8, f_magnitude)

        # ä½ç½®ç›¸ä½é¡¹
        position_phase = -2j * np.pi * (FX * x + FY * y)

        # é¢‘ç‡ä¾èµ–é¡¹ - æ•°å€¼ç¨³å®šç‰ˆæœ¬
        if alpha == 0:
            frequency_term = np.ones_like(f_magnitude_safe)
        else:
            normalized_freq = f_magnitude_safe / self.fc
            frequency_term = np.power(normalized_freq, alpha)

        # é•¿åº¦ç›¸å…³é¡¹
        if length == 0:
            length_term = np.ones_like(f_magnitude_safe)
        else:
            angle_diff = theta - phi_bar
            sinc_arg = length * f_magnitude_safe * np.sin(angle_diff)
            with np.errstate(divide="ignore", invalid="ignore"):
                length_term = np.where(np.abs(sinc_arg) < 1e-10, 1.0, np.sin(np.pi * sinc_arg) / (np.pi * sinc_arg))

        # ç»„åˆå“åº”
        H_asc = frequency_term * length_term * np.exp(position_phase + 1j * phi_bar)

        # ç©ºåŸŸåŸå­
        atom = np.fft.ifft2(np.fft.ifftshift(H_asc))
        return atom

    def build_compact_dictionary(self) -> Tuple[np.ndarray, List[Dict]]:
        """æ„å»ºç´§å‡‘é«˜æ•ˆçš„å­—å…¸"""
        print(f"ğŸ“š æ„å»ºç´§å‡‘ASCå­—å…¸...")

        # é¢‘ç‡é‡‡æ ·
        fx_range = np.linspace(-self.B / 2, self.B / 2, self.image_size[0])
        fy_range = np.linspace(-self.fc * np.sin(self.omega / 2), self.fc * np.sin(self.omega / 2), self.image_size[1])

        # ä½ç½®é‡‡æ ·
        x_positions = np.linspace(-0.8, 0.8, self.position_samples)
        y_positions = np.linspace(-0.8, 0.8, self.position_samples)

        dictionary_atoms = []
        param_grid = []

        valid_count = 0
        total_count = 0

        for x in x_positions:
            for y in y_positions:
                for alpha in self.alpha_values:
                    for length in self.length_values:
                        for phi_bar in self.phi_bar_values:
                            total_count += 1

                            atom = self._generate_robust_asc_atom(x, y, alpha, length, phi_bar, fx_range, fy_range)

                            atom_flat = atom.flatten()
                            atom_energy = np.linalg.norm(atom_flat)

                            # æ£€æŸ¥åŸå­æœ‰æ•ˆæ€§
                            if (
                                atom_energy > 1e-12
                                and np.isfinite(atom_energy)
                                and not np.any(np.isnan(atom_flat))
                                and not np.any(np.isinf(atom_flat))
                            ):

                                atom_normalized = atom_flat / atom_energy
                                dictionary_atoms.append(atom_normalized)
                                param_grid.append(
                                    {
                                        "x": x,
                                        "y": y,
                                        "alpha": alpha,
                                        "length": length,
                                        "phi_bar": phi_bar,
                                        "atom_energy": atom_energy,
                                        "scattering_type": self._classify_scattering_type(alpha),
                                    }
                                )
                                valid_count += 1

        dictionary = np.column_stack(dictionary_atoms)

        print(f"   æœ‰æ•ˆåŸå­: {valid_count}/{total_count} ({valid_count/total_count*100:.1f}%)")
        print(f"   å­—å…¸å°ºå¯¸: {dictionary.shape}")
        print(f"   å†…å­˜å ç”¨: ~{dictionary.nbytes / 1024**2:.1f} MB")

        return dictionary, param_grid

    def _classify_scattering_type(self, alpha: float) -> str:
        """æ•£å°„ç±»å‹åˆ†ç±»"""
        types = {-1.0: "å°–é¡¶ç»•å°„", -0.5: "è¾¹ç¼˜ç»•å°„", 0.0: "æ ‡å‡†æ•£å°„", 0.5: "è¡¨é¢æ•£å°„", 1.0: "é•œé¢åå°„"}
        return types.get(alpha, f"Î±={alpha}")

    def improved_adaptive_extraction(
        self, signal: np.ndarray, dictionary: np.ndarray, param_grid: List[Dict]
    ) -> List[Dict]:
        """æ”¹è¿›çš„è‡ªé€‚åº”æå–ç®—æ³•"""
        print(f"ğŸ¯ å¼€å§‹æ”¹è¿›ç‰ˆè‡ªé€‚åº”æå–...")

        residual_signal = signal.copy()
        extracted_scatterers = []

        initial_energy = np.linalg.norm(residual_signal)
        energy_threshold = initial_energy * self.adaptive_threshold

        print(f"   åˆå§‹èƒ½é‡: {initial_energy:.6f}")
        print(f"   åœæ­¢é˜ˆå€¼: {energy_threshold:.6f}")

        for iteration in range(self.max_iterations):
            current_energy = np.linalg.norm(residual_signal)

            # å¤šé‡åœæ­¢æ¡ä»¶
            if current_energy < energy_threshold:
                print(f"   ğŸ’¡ è¾¾åˆ°èƒ½é‡é˜ˆå€¼ï¼Œåœæ­¢è¿­ä»£")
                break

            if len(extracted_scatterers) >= self.max_scatterers:
                print(f"   ğŸ’¡ è¾¾åˆ°æœ€å¤§æ•£å°„ä¸­å¿ƒæ•°ï¼Œåœæ­¢è¿­ä»£")
                break

            # æ£€æŸ¥åœæ»
            if len(extracted_scatterers) >= 3:
                recent_energies = [s.get("residual_energy", current_energy) for s in extracted_scatterers[-3:]]
                if max(recent_energies) - min(recent_energies) < current_energy * 0.001:
                    print(f"   ğŸ’¡ èƒ½é‡å‡å°‘åœæ»ï¼Œåœæ­¢è¿­ä»£")
                    break

            # æ‰¾åˆ°æœ€ä½³åŒ¹é…
            best_idx, best_coef = self._find_best_match_robust(residual_signal, dictionary)
            if best_idx is None:
                print(f"   ğŸ’¡ æœªæ‰¾åˆ°æœ‰æ•ˆåŒ¹é…ï¼Œåœæ­¢è¿­ä»£")
                break

            initial_params = param_grid[best_idx].copy()

            # å‚æ•°ç²¾åŒ–
            refined_params = self._refine_parameters_simple(initial_params, residual_signal, best_coef)

            # è®¡ç®—è´¡çŒ®å¹¶æ›´æ–°æ®‹å·®
            contribution = self._calculate_scatterer_contribution(refined_params)

            if np.linalg.norm(contribution) < current_energy * 0.001:
                print(f"   ğŸ’¡ æ•£å°„ä¸­å¿ƒè´¡çŒ®è¿‡å°ï¼Œåœæ­¢è¿­ä»£")
                break

            # æ›´æ–°æ®‹å·®
            new_residual = residual_signal - contribution
            new_energy = np.linalg.norm(new_residual)

            # éªŒè¯èƒ½é‡å‡å°‘
            if new_energy >= current_energy * 0.999:  # å‡ ä¹æ²¡æœ‰æ”¹å–„
                print(f"   ğŸ’¡ èƒ½é‡å‡å°‘ä¸è¶³ï¼Œåœæ­¢è¿­ä»£")
                break

            residual_signal = new_residual
            refined_params["residual_energy"] = new_energy
            extracted_scatterers.append(refined_params)

            if iteration < 5 or (iteration + 1) % 5 == 0:
                reduction = (current_energy - new_energy) / current_energy
                print(f"   è¿­ä»£ {iteration+1}: {current_energy:.6f} â†’ {new_energy:.6f} (å‡å°‘{reduction:.2%})")

        final_energy = np.linalg.norm(residual_signal)
        total_reduction = (initial_energy - final_energy) / initial_energy

        print(f"âœ… æ”¹è¿›ç‰ˆæå–å®Œæˆ")
        print(f"   æ•£å°„ä¸­å¿ƒæ•°: {len(extracted_scatterers)}")
        print(f"   æ€»èƒ½é‡å‡å°‘: {total_reduction:.1%}")

        return extracted_scatterers

    def _find_best_match_robust(
        self, signal: np.ndarray, dictionary: np.ndarray
    ) -> Tuple[Optional[int], Optional[complex]]:
        """ç¨³å¥çš„æœ€ä½³åŒ¹é…æŸ¥æ‰¾"""
        # æ£€æŸ¥è¾“å…¥æœ‰æ•ˆæ€§
        if np.any(np.isnan(signal)) or np.any(np.isinf(signal)):
            return None, None

        signal_real = np.concatenate([signal.real, signal.imag])
        dictionary_real = np.concatenate([dictionary.real, dictionary.imag], axis=0)

        # æ£€æŸ¥å­—å…¸æœ‰æ•ˆæ€§
        if np.any(np.isnan(dictionary_real)) or np.any(np.isinf(dictionary_real)):
            return None, None

        try:
            omp = OrthogonalMatchingPursuit(n_nonzero_coefs=1, fit_intercept=False)
            omp.fit(dictionary_real, signal_real)

            nonzero_indices = np.nonzero(omp.coef_)[0]
            if len(nonzero_indices) == 0:
                return None, None

            best_idx = nonzero_indices[0]
            selected_atom = dictionary[:, best_idx]

            # è®¡ç®—å¤æ•°ç³»æ•°
            numerator = np.vdot(selected_atom, signal)
            denominator = np.vdot(selected_atom, selected_atom)

            if abs(denominator) < 1e-12:
                return None, None

            complex_coef = numerator / denominator

            return best_idx, complex_coef

        except Exception as e:
            print(f"   âš ï¸ OMPåŒ¹é…å¼‚å¸¸: {str(e)}")
            return None, None

    def _refine_parameters_simple(self, initial_params: Dict, target_signal: np.ndarray, initial_coef: complex) -> Dict:
        """ç®€åŒ–çš„å‚æ•°ç²¾åŒ–"""
        # å¯¹äºç‚¹æ•£å°„æ¨¡å¼ï¼Œåªç²¾åŒ–ä½ç½®å’Œå¹…åº¦ç›¸ä½
        refined_params = initial_params.copy()
        refined_params["estimated_amplitude"] = np.abs(initial_coef)
        refined_params["estimated_phase"] = np.angle(initial_coef)
        refined_params["optimization_success"] = True

        return refined_params

    def _calculate_scatterer_contribution(self, scatterer_params: Dict) -> np.ndarray:
        """è®¡ç®—æ•£å°„ä¸­å¿ƒå¯¹ä¿¡å·çš„è´¡çŒ®"""
        fx_range = np.linspace(-self.B / 2, self.B / 2, self.image_size[0])
        fy_range = np.linspace(-self.fc * np.sin(self.omega / 2), self.fc * np.sin(self.omega / 2), self.image_size[1])

        atom = self._generate_robust_asc_atom(
            scatterer_params["x"],
            scatterer_params["y"],
            scatterer_params["alpha"],
            scatterer_params.get("length", 0.0),
            scatterer_params.get("phi_bar", 0.0),
            fx_range,
            fy_range,
        )

        atom_flat = atom.flatten()
        atom_energy = np.linalg.norm(atom_flat)

        if atom_energy > 1e-12:
            atom_normalized = atom_flat / atom_energy
            contribution = (
                scatterer_params["estimated_amplitude"]
                * np.exp(1j * scatterer_params["estimated_phase"])
                * atom_normalized
            )
            return contribution
        else:
            return np.zeros_like(atom_flat)

    def extract_asc_scatterers_v2(self, complex_image: np.ndarray) -> List[Dict]:
        """å®Œæ•´çš„v2ç‰ˆæœ¬ASCæå–æµç¨‹"""
        print(f"ğŸš€ å¼€å§‹v2ç‰ˆæœ¬ASCæå–æµç¨‹")
        print("=" * 60)

        # æ•°æ®é¢„å¤„ç†
        signal = self.preprocess_data_robust(complex_image)

        # æ„å»ºå­—å…¸
        dictionary, param_grid = self.build_compact_dictionary()

        # è‡ªé€‚åº”æå–
        scatterers = self.improved_adaptive_extraction(signal, dictionary, param_grid)

        # ç»“æœåˆ†æ
        if scatterers:
            print(f"\nğŸ“Š æå–ç»“æœåˆ†æ:")
            alpha_dist = {}
            for s in scatterers:
                stype = s["scattering_type"]
                alpha_dist[stype] = alpha_dist.get(stype, 0) + 1
            print(f"   æ•£å°„ç±»å‹åˆ†å¸ƒ: {alpha_dist}")

        return scatterers


def main():
    """v2ç‰ˆæœ¬æ¼”ç¤º"""
    print("ğŸ”§ ä¿®å¤ç‰ˆASCæå–ç³»ç»Ÿv2")
    print("è§£å†³æ•°æ®åŠ è½½å’Œæ”¶æ•›æ€§é—®é¢˜")

    asc_v2 = ASCExtractionFixedV2(
        extraction_mode="point_only", adaptive_threshold=0.03, max_iterations=20, max_scatterers=15
    )

    print("\nä½¿ç”¨æ–¹æ³•:")
    print("magnitude, complex_image = asc_v2.load_mstar_data_robust('data.raw')")
    print("scatterers = asc_v2.extract_asc_scatterers_v2(complex_image)")

    return asc_v2


if __name__ == "__main__":
    asc_system = main()
