"""
ASCæ•£å°„ä¸­å¿ƒæå–æ¼”ç¤º - v3ä¿®å¤ç‰ˆæœ¬
å±•ç¤ºå®Œæ•´çš„MSTARæ•°æ®å¤„ç†å’Œå¯è§†åŒ–æµç¨‹

ä½¿ç”¨ä¿®å¤åçš„ç®—æ³•è§£å†³ï¼š
1. ç‰©ç†å°ºåº¦ä¸åŒ¹é…é—®é¢˜
2. å‚æ•°ç²¾åŒ–é€»è¾‘ç¼ºå¤±é—®é¢˜
3. è¿­ä»£æ”¶æ•›æ€§é—®é¢˜

è¿è¡Œæ–¹å¼ï¼š
python demo_asc_fixed_v3.py
"""

import numpy as np
import matplotlib.pyplot as plt
import os
import time
from asc_extraction_fixed_v2 import ASCExtractionFixedV2, visualize_extraction_results


def find_mstar_files():
    """æŸ¥æ‰¾MSTARæ•°æ®æ–‡ä»¶"""
    print("ğŸ” æœç´¢MSTARæ•°æ®æ–‡ä»¶...")

    search_paths = [
        "datasets/SAR_ASC_Project/02_Data_Processed_raw/SN_S7/",
        "datasets/SAR_ASC_Project/02_Data_Processed_raw/",
        "datasets/",
    ]

    mstar_files = []
    for search_path in search_paths:
        if os.path.exists(search_path):
            for root, dirs, files in os.walk(search_path):
                for file in files:
                    if file.endswith(".raw") and "HB" in file:
                        mstar_files.append(os.path.join(root, file))

    if mstar_files:
        print(f"   æ‰¾åˆ° {len(mstar_files)} ä¸ªMSTARæ–‡ä»¶")
        for i, file in enumerate(mstar_files[:3]):  # æ˜¾ç¤ºå‰3ä¸ª
            print(f"   {i+1}. {file}")
        if len(mstar_files) > 3:
            print(f"   ... è¿˜æœ‰ {len(mstar_files)-3} ä¸ªæ–‡ä»¶")
    else:
        print("   âš ï¸ æœªæ‰¾åˆ°MSTARæ•°æ®æ–‡ä»¶")

    return mstar_files


def demo_real_data():
    """çœŸå®MSTARæ•°æ®æ¼”ç¤º"""
    print("ğŸš€ çœŸå®MSTARæ•°æ®ASCæå–æ¼”ç¤º")
    print("=" * 50)

    # æŸ¥æ‰¾æ•°æ®æ–‡ä»¶
    mstar_files = find_mstar_files()

    if not mstar_files:
        print("è·³è½¬åˆ°åˆæˆæ•°æ®æ¼”ç¤º...")
        return demo_synthetic_data()

    # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œæ¼”ç¤º
    test_file = mstar_files[0]
    print(f"\nğŸ“‚ ä½¿ç”¨æ•°æ®æ–‡ä»¶: {os.path.basename(test_file)}")

    # åˆ›å»ºASCæå–å™¨
    print("\nğŸ”§ åˆå§‹åŒ–ASCæå–å™¨...")
    asc_extractor = ASCExtractionFixedV2(
        extraction_mode="point_only",  # ä¸“æ³¨ç‚¹æ•£å°„Î±å€¼è¯†åˆ«
        adaptive_threshold=0.03,  # é€‚ä¸­çš„é˜ˆå€¼
        max_iterations=20,  # å……åˆ†çš„è¿­ä»£æ¬¡æ•°
        max_scatterers=15,  # åˆç†çš„æ•£å°„ä¸­å¿ƒæ•°
    )

    try:
        # æ­¥éª¤1: æ•°æ®åŠ è½½
        print("\nğŸ“¥ æ­¥éª¤1: åŠ è½½MSTARæ•°æ®...")
        start_time = time.time()

        magnitude, complex_image = asc_extractor.load_mstar_data_robust(test_file)

        load_time = time.time() - start_time
        print(f"   âœ… æ•°æ®åŠ è½½æˆåŠŸ ({load_time:.2f}s)")
        print(f"      å›¾åƒå°ºå¯¸: {complex_image.shape}")
        print(f"      ä¿¡å·èƒ½é‡: {np.linalg.norm(complex_image):.3f}")

        # æ­¥éª¤2: ASCæ•£å°„ä¸­å¿ƒæå–
        print("\nğŸ¯ æ­¥éª¤2: ASCæ•£å°„ä¸­å¿ƒæå–...")
        extraction_start = time.time()

        scatterers = asc_extractor.extract_asc_scatterers_v2(complex_image)

        extraction_time = time.time() - extraction_start

        # æ­¥éª¤3: ç»“æœåˆ†æ
        print(f"\nğŸ“Š æ­¥éª¤3: ç»“æœåˆ†æ...")
        print(f"   æå–æ—¶é—´: {extraction_time:.2f}s")
        print(f"   æ•£å°„ä¸­å¿ƒæ•°: {len(scatterers)}")

        if scatterers:
            print(f"\nâœ… æˆåŠŸæå–æ•£å°„ä¸­å¿ƒ!")

            # è¯¦ç»†ä¿¡æ¯
            print(f"\nğŸ” æ•£å°„ä¸­å¿ƒè¯¦ç»†ä¿¡æ¯:")
            for i, sc in enumerate(scatterers):
                opt_symbol = "âœ…" if sc.get("optimization_success", False) else "âš ï¸"
                print(
                    f"   #{i+1}: {opt_symbol} ä½ç½®({sc['x']:.3f}, {sc['y']:.3f}), "
                    f"{sc['scattering_type']}, "
                    f"å¹…åº¦: {sc['estimated_amplitude']:.3f}"
                )

            # ç»Ÿè®¡åˆ†æ
            alpha_dist = {}
            opt_success_count = 0
            for sc in scatterers:
                stype = sc["scattering_type"]
                alpha_dist[stype] = alpha_dist.get(stype, 0) + 1
                if sc.get("optimization_success", False):
                    opt_success_count += 1

            print(f"\nğŸ“ˆ ç»Ÿè®¡åˆ†æ:")
            print(f"   æ•£å°„ç±»å‹åˆ†å¸ƒ: {alpha_dist}")
            print(
                f"   ä¼˜åŒ–æˆåŠŸç‡: {opt_success_count}/{len(scatterers)} ({opt_success_count/len(scatterers)*100:.1f}%)"
            )

            # æ­¥éª¤4: å¯è§†åŒ–
            print(f"\nğŸ–¼ï¸ æ­¥éª¤4: ç”Ÿæˆå¯è§†åŒ–...")

            # ç¡®ä¿resultsç›®å½•å­˜åœ¨
            os.makedirs("results", exist_ok=True)
            save_path = f"results/asc_demo_real_data.png"

            visualize_extraction_results(complex_image, scatterers, save_path)

            print(f"   âœ… å¯è§†åŒ–å®Œæˆ!")
            print(f"   ç»“æœä¿å­˜è‡³: {save_path}")

            # ç®—æ³•æ•ˆæœè¯„ä¼°
            print(f"\nğŸ¯ ç®—æ³•æ•ˆæœè¯„ä¼°:")

            quality_score = 0
            if len(scatterers) >= 5:
                quality_score += 30
                print("   âœ… æ•£å°„ä¸­å¿ƒæ•°é‡å……è¶³ (+30åˆ†)")
            else:
                print(f"   âš ï¸ æ•£å°„ä¸­å¿ƒæ•°é‡è¾ƒå°‘: {len(scatterers)}")

            if opt_success_count / len(scatterers) > 0.6:
                quality_score += 35
                print("   âœ… å‚æ•°ä¼˜åŒ–æ•ˆæœè‰¯å¥½ (+35åˆ†)")
            else:
                print(f"   âš ï¸ å‚æ•°ä¼˜åŒ–æˆåŠŸç‡è¾ƒä½: {opt_success_count/len(scatterers)*100:.1f}%")

            if len(alpha_dist) >= 3:
                quality_score += 35
                print("   âœ… æ•£å°„æœºç†è¯†åˆ«å¤šæ · (+35åˆ†)")
            else:
                print(f"   âš ï¸ æ•£å°„æœºç†è¯†åˆ«ç§ç±»è¾ƒå°‘: {len(alpha_dist)}")

            print(f"\nğŸ† æ€»ä½“è´¨é‡è¯„åˆ†: {quality_score}/100")

            if quality_score >= 80:
                print("   ğŸ‰ ä¼˜ç§€! ç®—æ³•ä¿®å¤éå¸¸æˆåŠŸ!")
            elif quality_score >= 60:
                print("   âœ… è‰¯å¥½! ç®—æ³•ä¿®å¤åŸºæœ¬æˆåŠŸ!")
            else:
                print("   âš ï¸ éœ€è¦æ”¹è¿›! å»ºè®®è°ƒæ•´å‚æ•°æˆ–æ£€æŸ¥æ•°æ®è´¨é‡")

        else:
            print("   âŒ æœªèƒ½æå–åˆ°æ•£å°„ä¸­å¿ƒ")
            print("   ğŸ“‹ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
            print("      1. é™ä½adaptive_threshold (å½“å‰: 0.03)")
            print("      2. å¢åŠ max_iterations (å½“å‰: 20)")
            print("      3. æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ")

            # å°è¯•åˆæˆæ•°æ®
            print("\n   ğŸ”„ å°è¯•åˆæˆæ•°æ®æµ‹è¯•...")
            return demo_synthetic_data()

    except Exception as e:
        print(f"   âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {str(e)}")
        import traceback

        traceback.print_exc()

        print("\n   ğŸ”„ å°è¯•åˆæˆæ•°æ®æµ‹è¯•...")
        return demo_synthetic_data()


def demo_synthetic_data():
    """åˆæˆæ•°æ®æ¼”ç¤º"""
    print("\nğŸ§ª åˆæˆæ•°æ®ASCæå–æ¼”ç¤º")
    print("=" * 50)

    # åˆ›å»ºASCæå–å™¨
    asc_extractor = ASCExtractionFixedV2(
        extraction_mode="point_only", adaptive_threshold=0.05, max_iterations=15, max_scatterers=10
    )

    print("ğŸ”§ åˆ›å»ºåˆæˆæµ‹è¯•æ•°æ®...")

    # åˆ›å»ºåŒ…å«å¤šä¸ªæ•£å°„ä¸­å¿ƒçš„åˆæˆå›¾åƒ
    image_size = (128, 128)
    complex_image = np.zeros(image_size, dtype=complex)

    # å®šä¹‰ç†è®ºæ•£å°„ä¸­å¿ƒ
    theoretical_scatterers = [
        {"pos": (0.4, 0.3), "amp": 1.2, "phase": 0.0, "type": "å¼ºåå°„é¢"},
        {"pos": (-0.3, 0.5), "amp": 0.8, "phase": np.pi / 4, "type": "è¾¹ç¼˜ç»“æ„"},
        {"pos": (0.1, -0.4), "amp": 0.6, "phase": np.pi / 2, "type": "æ ‡å‡†æ•£å°„"},
        {"pos": (-0.5, -0.2), "amp": 0.9, "phase": 0.0, "type": "è¡¨é¢æ•£å°„"},
    ]

    for sc in theoretical_scatterers:
        x, y = sc["pos"]
        amplitude = sc["amp"]
        phase = sc["phase"]

        # è½¬æ¢åˆ°åƒç´ åæ ‡
        px = int((x + 1) * image_size[0] / 2)
        py = int((y + 1) * image_size[1] / 2)

        # åˆ›å»ºé«˜æ–¯å½¢çŠ¶çš„æ•£å°„ä¸­å¿ƒ
        sigma = 3.0
        for i in range(max(0, px - 10), min(image_size[0], px + 11)):
            for j in range(max(0, py - 10), min(image_size[1], py + 11)):
                distance = np.sqrt((i - px) ** 2 + (j - py) ** 2)
                weight = np.exp(-(distance**2) / (2 * sigma**2))
                complex_image[i, j] += amplitude * weight * np.exp(1j * phase)

    # æ·»åŠ é€‚é‡å™ªå£°
    noise_level = 0.02
    noise = noise_level * (np.random.randn(*image_size) + 1j * np.random.randn(*image_size))
    complex_image += noise

    print(f"   åˆæˆæ•°æ®ç‰¹å¾:")
    print(f"     å›¾åƒå°ºå¯¸: {complex_image.shape}")
    print(f"     ç†è®ºæ•£å°„ä¸­å¿ƒ: {len(theoretical_scatterers)}ä¸ª")
    print(f"     ä¿¡å·èƒ½é‡: {np.linalg.norm(complex_image):.3f}")
    print(f"     ä¿¡å™ªæ¯”: ~{1/noise_level:.1f}")

    # ASCæå–
    print(f"\nğŸ¯ å¼€å§‹ASCæ•£å°„ä¸­å¿ƒæå–...")
    start_time = time.time()

    scatterers = asc_extractor.extract_asc_scatterers_v2(complex_image)

    extraction_time = time.time() - start_time

    print(f"\nğŸ“Š æå–ç»“æœ:")
    print(f"   æå–æ—¶é—´: {extraction_time:.2f}s")
    print(f"   æå–æ•£å°„ä¸­å¿ƒ: {len(scatterers)}ä¸ª")
    print(f"   ç†è®ºæ•£å°„ä¸­å¿ƒ: {len(theoretical_scatterers)}ä¸ª")

    if scatterers:
        print(f"\nâœ… æˆåŠŸä»åˆæˆæ•°æ®ä¸­æå–æ•£å°„ä¸­å¿ƒ!")

        # å¯è§†åŒ–
        print(f"\nğŸ–¼ï¸ ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
        os.makedirs("results", exist_ok=True)
        save_path = "results/asc_demo_synthetic_data.png"

        visualize_extraction_results(complex_image, scatterers, save_path)

        print(f"   âœ… åˆæˆæ•°æ®å¯è§†åŒ–ä¿å­˜è‡³: {save_path}")

        # ä¸ç†è®ºå€¼æ¯”è¾ƒ
        print(f"\nğŸ” ä¸ç†è®ºå€¼æ¯”è¾ƒ:")
        for i, sc in enumerate(scatterers):
            print(
                f"   #{i+1}: ä½ç½®({sc['x']:.3f}, {sc['y']:.3f}), "
                f"{sc['scattering_type']}, "
                f"å¹…åº¦: {sc['estimated_amplitude']:.3f}"
            )

        detection_rate = len(scatterers) / len(theoretical_scatterers)
        print(f"\nğŸ“ˆ æ£€æµ‹ç‡: {detection_rate:.1%} ({len(scatterers)}/{len(theoretical_scatterers)})")

        if detection_rate >= 0.75:
            print("   ğŸ‰ æ£€æµ‹æ•ˆæœä¼˜ç§€!")
        elif detection_rate >= 0.5:
            print("   âœ… æ£€æµ‹æ•ˆæœè‰¯å¥½!")
        else:
            print("   âš ï¸ æ£€æµ‹æ•ˆæœéœ€è¦æ”¹è¿›!")
    else:
        print("   âŒ åˆæˆæ•°æ®æµ‹è¯•ä¹Ÿå¤±è´¥äº†")
        print("   è¿™å¯èƒ½è¡¨æ˜ç®—æ³•å®ç°ä»å­˜åœ¨é—®é¢˜")


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ¯ ASCæ•£å°„ä¸­å¿ƒæå–æ¼”ç¤º - v3ä¿®å¤ç‰ˆæœ¬")
    print("=" * 60)
    print("æœ¬æ¼”ç¤ºå±•ç¤ºä¿®å¤åçš„ç®—æ³•å¦‚ä½•:")
    print("  âœ… è§£å†³ç‰©ç†å°ºåº¦ä¸åŒ¹é…é—®é¢˜")
    print("  âœ… å®ç°çœŸæ­£çš„å‚æ•°ç²¾åŒ–ä¼˜åŒ–")
    print("  âœ… æ­£ç¡®çš„åŒ¹é…-ä¼˜åŒ–-å‡å»è¿­ä»£")
    print("  âœ… å®Œæ•´çš„æ•£å°„ä¸­å¿ƒå¯è§†åŒ–")
    print("=" * 60)

    try:
        # é¦–å…ˆå°è¯•çœŸå®æ•°æ®
        demo_real_data()

    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ¼”ç¤º")
    except Exception as e:
        print(f"\n\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {str(e)}")
        import traceback

        traceback.print_exc()

    print(f"\nğŸŠ æ¼”ç¤ºå®Œæˆ!")
    print(f"   è¯·æŸ¥çœ‹results/ç›®å½•ä¸­çš„å¯è§†åŒ–ç»“æœ")
    print(f"   å¦‚æœæ•ˆæœè‰¯å¥½ï¼Œå¯ä»¥å°è¯•:")
    print(f"     - è°ƒæ•´extraction_modeä¸º'progressive'")
    print(f"     - å¤„ç†æ›´å¤šçš„MSTARæ•°æ®æ–‡ä»¶")
    print(f"     - ä¼˜åŒ–ç®—æ³•å‚æ•°ä»¥è·å¾—æ›´å¥½æ•ˆæœ")


if __name__ == "__main__":
    main()
