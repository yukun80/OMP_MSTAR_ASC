#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MSTARæ•°æ®OMPæ•£å°„ä¸­å¿ƒæå–å¤„ç†è„šæœ¬
MSTAR Data OMP Scattering Center Extraction Processing Script

å°†OMP ASCç®—æ³•åº”ç”¨äºå®é™…çš„MSTAR SARæ•°æ®
"""

import numpy as np
import matplotlib.pyplot as plt
from omp_asc_final import OMPASCFinal
import os
import glob
import time
from typing import List, Dict
import pickle


class MSTARProcessor:
    """MSTARæ•°æ®å¤„ç†å™¨"""

    def __init__(self, data_root: str = "datasets/SAR_ASC_Project"):
        self.data_root = data_root
        self.raw_data_dir = os.path.join(data_root, "02_Data_Processed_raw")
        self.results_dir = os.path.join(data_root, "03_OMP_Results")

        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs(self.results_dir, exist_ok=True)

        # åˆå§‹åŒ–OMPç®—æ³• - ä½¿ç”¨æ¨èçš„å¹³è¡¡é…ç½®
        self.omp_asc = OMPASCFinal(n_scatterers=40, image_size=(128, 128), use_cv=False)  # æ–‡æ¡£è¦æ±‚çš„40ä¸ªæ•£å°„ä¸­å¿ƒ

        print(f"MSTARå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"æ•°æ®æ ¹ç›®å½•: {self.data_root}")
        print(f"ç»“æœä¿å­˜ç›®å½•: {self.results_dir}")

    def find_raw_files(self) -> List[str]:
        """æŸ¥æ‰¾æ‰€æœ‰.rawæ–‡ä»¶"""
        pattern = os.path.join(self.raw_data_dir, "**", "*.raw")
        raw_files = glob.glob(pattern, recursive=True)
        raw_files.sort()

        print(f"æ‰¾åˆ° {len(raw_files)} ä¸ªRAWæ–‡ä»¶:")
        for file in raw_files:
            rel_path = os.path.relpath(file, self.data_root)
            print(f"  - {rel_path}")

        return raw_files

    def process_single_file(self, raw_file_path: str) -> Dict:
        """å¤„ç†å•ä¸ªRAWæ–‡ä»¶"""
        print(f"\n{'='*60}")
        file_name = os.path.basename(raw_file_path)
        print(f"å¤„ç†æ–‡ä»¶: {file_name}")
        print(f"{'='*60}")

        start_time = time.time()

        try:
            # 1. åŠ è½½æ•°æ®
            print("æ­¥éª¤1: åŠ è½½SARæ•°æ®...")
            magnitude, complex_image = self.omp_asc.load_raw_data(raw_file_path)

            # 2. é¢„å¤„ç†
            print("æ­¥éª¤2: æ•°æ®é¢„å¤„ç†...")
            signal = self.omp_asc.preprocess_data(complex_image)

            # 3. æ„å»ºå­—å…¸ (ä½¿ç”¨å¹³è¡¡é…ç½®)
            print("æ­¥éª¤3: æ„å»ºSARå­—å…¸...")
            dictionary, param_grid = self.omp_asc.build_dictionary(position_grid_size=12, phase_levels=6)  # å¹³è¡¡é…ç½®

            # 4. æå–æ•£å°„ä¸­å¿ƒ
            print("æ­¥éª¤4: OMPæ•£å°„ä¸­å¿ƒæå–...")
            results = self.omp_asc.extract_scatterers(signal)

            # 5. é‡æ„å›¾åƒ
            print("æ­¥éª¤5: å›¾åƒé‡æ„...")
            reconstructed = self.omp_asc.reconstruct_image(results["scatterers"])

            # 6. è®¡ç®—è´¨é‡æŒ‡æ ‡
            mse = np.mean((magnitude - np.abs(reconstructed)) ** 2)
            max_val = np.max(magnitude)
            psnr = 20 * np.log10(max_val / np.sqrt(mse)) if mse > 0 else float("inf")

            processing_time = time.time() - start_time

            # æ•´ç†ç»“æœ
            result = {
                "file_name": file_name,
                "file_path": raw_file_path,
                "processing_time": processing_time,
                "scatterers": results["scatterers"],
                "coefficients": results["coefficients"],
                "reconstruction_error": results["reconstruction_error"],
                "psnr": psnr,
                "original_magnitude": magnitude,
                "reconstructed_image": reconstructed,
                "dictionary_size": dictionary.shape[1],
                "extracted_count": len(results["scatterers"]),
            }

            print(f"\nâœ… å¤„ç†å®Œæˆï¼")
            print(f"   å¤„ç†æ—¶é—´: {processing_time:.2f}s")
            print(f"   æå–æ•£å°„ä¸­å¿ƒ: {len(results['scatterers'])}")
            print(f"   é‡æ„PSNR: {psnr:.2f} dB")
            print(f"   å­—å…¸å¤§å°: {dictionary.shape[1]}")

            return result

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
            return {
                "file_name": file_name,
                "file_path": raw_file_path,
                "error": str(e),
                "processing_time": time.time() - start_time,
            }

    def process_all_files(self) -> List[Dict]:
        """æ‰¹é‡å¤„ç†æ‰€æœ‰æ–‡ä»¶"""
        print("ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†MSTARæ•°æ®")
        print("=" * 60)

        raw_files = self.find_raw_files()
        all_results = []

        for i, raw_file in enumerate(raw_files, 1):
            print(f"\nğŸ“ [{i}/{len(raw_files)}] å¤„ç†è¿›åº¦")
            result = self.process_single_file(raw_file)
            all_results.append(result)

            # ä¿å­˜å•ä¸ªç»“æœ
            self.save_single_result(result)

        # ä¿å­˜æ±‡æ€»ç»“æœ
        self.save_summary_results(all_results)

        print(f"\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print(f"   æ€»æ–‡ä»¶æ•°: {len(raw_files)}")
        print(f"   æˆåŠŸå¤„ç†: {sum(1 for r in all_results if 'error' not in r)}")
        print(f"   å¤„ç†å¤±è´¥: {sum(1 for r in all_results if 'error' in r)}")

        return all_results

    def save_single_result(self, result: Dict):
        """ä¿å­˜å•ä¸ªæ–‡ä»¶çš„å¤„ç†ç»“æœ"""
        if "error" in result:
            return

        file_name = result["file_name"]
        base_name = file_name.replace(".raw", "")

        # ä¿å­˜æ•£å°„ä¸­å¿ƒæ•°æ®
        scatterers_file = os.path.join(self.results_dir, f"{base_name}_scatterers.pkl")
        with open(scatterers_file, "wb") as f:
            pickle.dump(result["scatterers"], f)

        # ä¿å­˜å¯è§†åŒ–å›¾åƒ
        self.visualize_result(result, save_path=os.path.join(self.results_dir, f"{base_name}_visualization.png"))

        # ä¿å­˜æ•£å°„ä¸­å¿ƒåˆ—è¡¨
        self.save_scatterer_summary(result, os.path.join(self.results_dir, f"{base_name}_summary.txt"))

    def visualize_result(self, result: Dict, save_path: str):
        """å¯è§†åŒ–å•ä¸ªæ–‡ä»¶çš„å¤„ç†ç»“æœ"""
        if "error" in result:
            return

        magnitude = result["original_magnitude"]
        reconstructed = result["reconstructed_image"]
        scatterers = result["scatterers"]

        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle(f"OMPæ•£å°„ä¸­å¿ƒæå–ç»“æœ - {result['file_name']}", fontsize=14)

        # åŸå§‹å¹…åº¦å›¾åƒ
        im1 = axes[0, 0].imshow(magnitude, cmap="gray")
        axes[0, 0].set_title(f"åŸå§‹SARå¹…åº¦å›¾")
        axes[0, 0].axis("off")
        plt.colorbar(im1, ax=axes[0, 0])

        # é‡æ„å¹…åº¦å›¾åƒ
        im2 = axes[0, 1].imshow(np.abs(reconstructed), cmap="gray")
        axes[0, 1].set_title(f'OMPé‡æ„å›¾åƒ (PSNR: {result["psnr"]:.1f}dB)')
        axes[0, 1].axis("off")
        plt.colorbar(im2, ax=axes[0, 1])

        # å·®å€¼å›¾åƒ
        diff = magnitude - np.abs(reconstructed)
        im3 = axes[0, 2].imshow(diff, cmap="seismic")
        axes[0, 2].set_title("é‡æ„è¯¯å·®")
        axes[0, 2].axis("off")
        plt.colorbar(im3, ax=axes[0, 2])

        # æ•£å°„ä¸­å¿ƒä½ç½®å›¾
        x_pos = [s["x"] for s in scatterers]
        y_pos = [s["y"] for s in scatterers]
        amplitudes = [s["estimated_amplitude"] for s in scatterers]

        scatter = axes[1, 0].scatter(x_pos, y_pos, c=amplitudes, s=100, cmap="viridis")
        axes[1, 0].set_title(f"æ•£å°„ä¸­å¿ƒä½ç½® ({len(scatterers)}ä¸ª)")
        axes[1, 0].set_xlabel("Xä½ç½® (å½’ä¸€åŒ–)")
        axes[1, 0].set_ylabel("Yä½ç½® (å½’ä¸€åŒ–)")
        axes[1, 0].grid(True, alpha=0.3)
        axes[1, 0].set_xlim(-1.1, 1.1)
        axes[1, 0].set_ylim(-1.1, 1.1)
        plt.colorbar(scatter, ax=axes[1, 0], label="å¹…åº¦")

        # å¹…åº¦åˆ†å¸ƒç›´æ–¹å›¾
        axes[1, 1].hist(amplitudes, bins=20, alpha=0.7, edgecolor="black")
        axes[1, 1].set_title("æ•£å°„ä¸­å¿ƒå¹…åº¦åˆ†å¸ƒ")
        axes[1, 1].set_xlabel("å¹…åº¦")
        axes[1, 1].set_ylabel("æ•°é‡")
        axes[1, 1].grid(True, alpha=0.3)

        # å¤„ç†ä¿¡æ¯æ–‡æœ¬
        info_text = f"""å¤„ç†ä¿¡æ¯:
æ–‡ä»¶: {result['file_name']}
å¤„ç†æ—¶é—´: {result['processing_time']:.2f}s
æ•£å°„ä¸­å¿ƒæ•°: {result['extracted_count']}
å­—å…¸å¤§å°: {result['dictionary_size']}
é‡æ„PSNR: {result['psnr']:.2f} dB
é‡æ„è¯¯å·®: {result['reconstruction_error']:.3f}

å‰5å¼ºæ•£å°„ä¸­å¿ƒ:"""

        # æ·»åŠ å‰5å¼ºæ•£å°„ä¸­å¿ƒä¿¡æ¯
        for i, scatterer in enumerate(scatterers[:5]):
            info_text += f"\n{i+1}. ä½ç½®:({scatterer['x']:.2f},{scatterer['y']:.2f})"
            info_text += f" å¹…åº¦:{scatterer['estimated_amplitude']:.3f}"

        axes[1, 2].text(
            0.05,
            0.95,
            info_text,
            transform=axes[1, 2].transAxes,
            fontsize=10,
            verticalalignment="top",
            fontfamily="monospace",
        )
        axes[1, 2].axis("off")

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches="tight")
        plt.close()

        print(f"   å¯è§†åŒ–ç»“æœä¿å­˜: {os.path.basename(save_path)}")

    def save_scatterer_summary(self, result: Dict, save_path: str):
        """ä¿å­˜æ•£å°„ä¸­å¿ƒæ±‡æ€»ä¿¡æ¯"""
        if "error" in result:
            return

        with open(save_path, "w", encoding="utf-8") as f:
            f.write(f"MSTARæ–‡ä»¶OMPæ•£å°„ä¸­å¿ƒæå–ç»“æœ\n")
            f.write(f"=" * 50 + "\n")
            f.write(f"æ–‡ä»¶å: {result['file_name']}\n")
            f.write(f"å¤„ç†æ—¶é—´: {result['processing_time']:.2f}ç§’\n")
            f.write(f"æ•£å°„ä¸­å¿ƒæ€»æ•°: {result['extracted_count']}\n")
            f.write(f"å­—å…¸å¤§å°: {result['dictionary_size']}\n")
            f.write(f"é‡æ„PSNR: {result['psnr']:.2f} dB\n")
            f.write(f"é‡æ„è¯¯å·®: {result['reconstruction_error']:.3f}\n\n")

            f.write(f"æ•£å°„ä¸­å¿ƒè¯¦ç»†ä¿¡æ¯:\n")
            f.write(f"{'-'*80}\n")
            f.write(f"{'åºå·':<4} {'Xä½ç½®':<8} {'Yä½ç½®':<8} {'å¹…åº¦':<12} {'ç›¸ä½':<12}\n")
            f.write(f"{'-'*80}\n")

            for i, scatterer in enumerate(result["scatterers"], 1):
                f.write(
                    f"{i:<4} {scatterer['x']:<8.3f} {scatterer['y']:<8.3f} "
                    f"{scatterer['estimated_amplitude']:<12.6f} {scatterer['estimated_phase']:<12.3f}\n"
                )

        print(f"   æ•£å°„ä¸­å¿ƒæ•°æ®ä¿å­˜: {os.path.basename(save_path)}")

    def save_summary_results(self, all_results: List[Dict]):
        """ä¿å­˜æ‰€æœ‰æ–‡ä»¶çš„æ±‡æ€»ç»“æœ"""
        summary_file = os.path.join(self.results_dir, "processing_summary.txt")

        successful_results = [r for r in all_results if "error" not in r]
        failed_results = [r for r in all_results if "error" in r]

        with open(summary_file, "w", encoding="utf-8") as f:
            f.write("MSTARæ•°æ®æ‰¹é‡å¤„ç†æ±‡æ€»æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")

            f.write(f"å¤„ç†ç»Ÿè®¡:\n")
            f.write(f"  æ€»æ–‡ä»¶æ•°: {len(all_results)}\n")
            f.write(f"  æˆåŠŸå¤„ç†: {len(successful_results)}\n")
            f.write(f"  å¤„ç†å¤±è´¥: {len(failed_results)}\n\n")

            if successful_results:
                avg_time = np.mean([r["processing_time"] for r in successful_results])
                avg_psnr = np.mean([r["psnr"] for r in successful_results])
                avg_scatterers = np.mean([r["extracted_count"] for r in successful_results])

                f.write(f"æˆåŠŸå¤„ç†æ–‡ä»¶ç»Ÿè®¡:\n")
                f.write(f"  å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.2f}ç§’\n")
                f.write(f"  å¹³å‡PSNR: {avg_psnr:.2f} dB\n")
                f.write(f"  å¹³å‡æ•£å°„ä¸­å¿ƒæ•°: {avg_scatterers:.1f}\n\n")

                f.write(f"è¯¦ç»†ç»“æœ:\n")
                f.write(f"{'-'*80}\n")
                f.write(f"{'æ–‡ä»¶å':<25} {'æ—¶é—´(s)':<8} {'PSNR(dB)':<8} {'æ•£å°„ä¸­å¿ƒ':<8}\n")
                f.write(f"{'-'*80}\n")

                for result in successful_results:
                    f.write(
                        f"{result['file_name']:<25} {result['processing_time']:<8.2f} "
                        f"{result['psnr']:<8.2f} {result['extracted_count']:<8}\n"
                    )

            if failed_results:
                f.write(f"\nå¤±è´¥æ–‡ä»¶åˆ—è¡¨:\n")
                f.write(f"{'-'*50}\n")
                for result in failed_results:
                    f.write(f"æ–‡ä»¶: {result['file_name']}\n")
                    f.write(f"é”™è¯¯: {result['error']}\n\n")

        print(f"æ±‡æ€»æŠ¥å‘Šä¿å­˜: processing_summary.txt")


def main():
    """ä¸»å¤„ç†å‡½æ•°"""
    print("ğŸ¯ MSTARæ•°æ®OMPæ•£å°„ä¸­å¿ƒæå–å¤„ç†")
    print("=" * 60)

    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = MSTARProcessor()

    # æ‰¹é‡å¤„ç†æ‰€æœ‰æ–‡ä»¶
    results = processor.process_all_files()

    print(f"\nğŸ“Š å¤„ç†å®Œæˆï¼æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {processor.results_dir}")

    return results


if __name__ == "__main__":
    results = main()
