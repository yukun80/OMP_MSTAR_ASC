#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ASCç®—æ³•ä¿®å¤æ•ˆæœéªŒè¯æµ‹è¯•
Algorithm Fix Validation Test

éªŒè¯ä¿®å¤ç‰ˆASCç®—æ³•è§£å†³çš„ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š
1. æ•°å€¼ç¨³å®šæ€§ï¼šéªŒè¯è´ŸÎ±å€¼ä¸å†é€ æˆæ•°å€¼çˆ†ç‚¸
2. å‚æ•°ç²¾åŒ–é€»è¾‘ï¼šéªŒè¯ä½¿ç”¨æ®‹å·®è€ŒéåŸå§‹ä¿¡å·è¿›è¡Œä¼˜åŒ–
3. è¿­ä»£æ”¶æ•›ï¼šéªŒè¯"åŒ¹é…-ä¼˜åŒ–-å‡å»"æµç¨‹çš„æœ‰æ•ˆæ€§

å¯¹æ¯”æµ‹è¯•ï¼š
- åŸå§‹æœ‰é—®é¢˜çš„ç‰ˆæœ¬ vs ä¿®å¤ç‰ˆæœ¬
- æ•°å€¼ç¨³å®šæ€§æµ‹è¯•
- æ”¶æ•›æ€§èƒ½æµ‹è¯•
- å®é™…MSTARæ•°æ®æµ‹è¯•
"""

import numpy as np
import matplotlib.pyplot as plt
import time
import os
from typing import Dict, List, Tuple

# å¯¼å…¥ç³»ç»Ÿ
from asc_extraction_fixed import ASCExtractionFixed
from asc_extraction_advanced import ASCExtractionAdvanced


class AlgorithmFixValidator:
    """ç®—æ³•ä¿®å¤æ•ˆæœéªŒè¯å™¨"""

    def __init__(self):
        self.results = {}
        print("ğŸ”¬ ASCç®—æ³•ä¿®å¤æ•ˆæœéªŒè¯å™¨åˆå§‹åŒ–")
        print("=" * 60)

    def test_numerical_stability(self):
        """æµ‹è¯•1ï¼šæ•°å€¼ç¨³å®šæ€§éªŒè¯"""
        print("\nğŸ§ª æµ‹è¯•1ï¼šæ•°å€¼ç¨³å®šæ€§éªŒè¯")
        print("-" * 40)

        # æµ‹è¯•å‚æ•°
        test_params = {
            "x": 0.5,
            "y": 0.3,
            "alpha_values": [-1.0, -0.5, 0.0, 0.5, 1.0],
            "fx_range": np.linspace(-5e8, 5e8, 128),
            "fy_range": np.linspace(-5e8, 5e8, 128),
        }

        print(f"   æµ‹è¯•å‚æ•°: x={test_params['x']}, y={test_params['y']}")
        print(f"   Î±å€¼èŒƒå›´: {test_params['alpha_values']}")

        # åˆå§‹åŒ–ç³»ç»Ÿ
        fixed_system = ASCExtractionFixed(extraction_mode="point_only")

        stability_results = {}

        for alpha in test_params["alpha_values"]:
            print(f"\n   ğŸ”¬ æµ‹è¯•Î±={alpha} (æ•£å°„ç±»å‹: {fixed_system._classify_scattering_type(alpha)})...")

            try:
                # ç”Ÿæˆä¿®å¤ç‰ˆåŸå­
                start_time = time.time()
                atom_fixed = fixed_system._generate_robust_asc_atom(
                    test_params["x"],
                    test_params["y"],
                    alpha,
                    0.0,
                    0.0,
                    test_params["fx_range"],
                    test_params["fy_range"],
                )
                generation_time = time.time() - start_time

                # æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§
                atom_flat = atom_fixed.flatten()
                atom_energy = np.linalg.norm(atom_flat)
                has_nan = np.any(np.isnan(atom_flat))
                has_inf = np.any(np.isinf(atom_flat))
                is_finite = np.all(np.isfinite(atom_flat))

                stability_results[alpha] = {
                    "generation_time": generation_time,
                    "atom_energy": atom_energy,
                    "has_nan": has_nan,
                    "has_inf": has_inf,
                    "is_finite": is_finite,
                    "max_value": np.max(np.abs(atom_flat)),
                    "success": is_finite and not has_nan and not has_inf and atom_energy > 1e-12,
                }

                status = "âœ… æˆåŠŸ" if stability_results[alpha]["success"] else "âŒ å¤±è´¥"
                print(f"      çŠ¶æ€: {status}")
                print(f"      åŸå­èƒ½é‡: {atom_energy:.3e}")
                print(f"      æœ€å¤§å€¼: {stability_results[alpha]['max_value']:.3e}")
                print(f"      ç”Ÿæˆæ—¶é—´: {generation_time:.3f}s")

            except Exception as e:
                stability_results[alpha] = {"success": False, "error": str(e)}
                print(f"      âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")

        # æ±‡æ€»ç»“æœ
        successful_alphas = sum(1 for result in stability_results.values() if result.get("success", False))
        print(f"\n   ğŸ“Š æ•°å€¼ç¨³å®šæ€§æµ‹è¯•ç»“æœ:")
        print(
            f"      æˆåŠŸç‡: {successful_alphas}/{len(test_params['alpha_values'])} ({successful_alphas/len(test_params['alpha_values'])*100:.1f}%)"
        )

        if successful_alphas == len(test_params["alpha_values"]):
            print(f"      ğŸ‰ æ‰€æœ‰Î±å€¼å‡é€šè¿‡æ•°å€¼ç¨³å®šæ€§æµ‹è¯•ï¼")

        self.results["numerical_stability"] = stability_results
        return stability_results

    def test_parameter_refinement_logic(self):
        """æµ‹è¯•2ï¼šå‚æ•°ç²¾åŒ–é€»è¾‘éªŒè¯"""
        print("\nğŸ§ª æµ‹è¯•2ï¼šå‚æ•°ç²¾åŒ–é€»è¾‘éªŒè¯")
        print("-" * 40)

        # åˆ›å»ºæ¨¡æ‹Ÿæ®‹å·®ä¿¡å·å’Œæ•£å°„ä¸­å¿ƒå‚æ•°
        signal_size = 128 * 128

        # æ¨¡æ‹Ÿä¸€ä¸ªç®€å•çš„æ®‹å·®ä¿¡å·
        np.random.seed(42)
        residual_signal = 0.1 * (np.random.randn(signal_size) + 1j * np.random.randn(signal_size))

        # åœ¨ä¿¡å·ä¸­å¿ƒä½ç½®æ·»åŠ ä¸€ä¸ªå¼ºæ•£å°„ä¸­å¿ƒ
        center_idx = signal_size // 2
        residual_signal[center_idx : center_idx + 100] += 1.0 * np.exp(1j * np.pi / 4)

        print(f"   æ¨¡æ‹Ÿæ®‹å·®ä¿¡å·ç‰¹å¾:")
        print(f"      ä¿¡å·é•¿åº¦: {len(residual_signal)}")
        print(f"      ä¿¡å·èƒ½é‡: {np.linalg.norm(residual_signal):.3f}")
        print(f"      æœ€å¤§å¹…åº¦: {np.max(np.abs(residual_signal)):.3f}")

        # åˆå§‹åŒ–ä¿®å¤ç‰ˆç³»ç»Ÿ
        fixed_system = ASCExtractionFixed(extraction_mode="point_only")

        # æµ‹è¯•å‚æ•°ç²¾åŒ–
        initial_params = {"x": 0.1, "y": 0.1, "alpha": 0.0, "length": 0.0, "phi_bar": 0.0}

        initial_coefficient = 0.8 + 0.6j

        print(f"\n   ğŸ”¬ æµ‹è¯•å‚æ•°ç²¾åŒ–...")
        print(f"      åˆå§‹ä½ç½®: ({initial_params['x']}, {initial_params['y']})")
        print(f"      åˆå§‹ç³»æ•°: {initial_coefficient}")

        try:
            start_time = time.time()
            refined_params = fixed_system._refine_parameters_correctly(
                initial_params, residual_signal, initial_coefficient  # å…³é”®ï¼šä½¿ç”¨æ®‹å·®ä¿¡å·
            )
            refinement_time = time.time() - start_time

            # éªŒè¯ç²¾åŒ–ç»“æœ
            refinement_success = refined_params.get("optimization_success", False)
            position_change = np.sqrt(
                (refined_params["x"] - initial_params["x"]) ** 2 + (refined_params["y"] - initial_params["y"]) ** 2
            )

            print(f"      ğŸ¯ ç²¾åŒ–ç»“æœ:")
            print(f"         ä¼˜åŒ–æˆåŠŸ: {'âœ…' if refinement_success else 'âŒ'}")
            print(f"         ç²¾åŒ–ä½ç½®: ({refined_params['x']:.3f}, {refined_params['y']:.3f})")
            print(f"         ä½ç½®å˜åŒ–: {position_change:.3f}")
            print(f"         ç²¾åŒ–å¹…åº¦: {refined_params['estimated_amplitude']:.3f}")
            print(f"         ç²¾åŒ–ç›¸ä½: {refined_params['estimated_phase']:.3f}")
            print(f"         ç²¾åŒ–æ—¶é—´: {refinement_time:.3f}s")

            if refinement_success:
                print(f"         ä¼˜åŒ–è¯¯å·®: {refined_params.get('optimization_error', 'N/A'):.6f}")

            refinement_result = {
                "success": refinement_success,
                "position_change": position_change,
                "refinement_time": refinement_time,
                "initial_params": initial_params.copy(),
                "refined_params": refined_params.copy(),
            }

        except Exception as e:
            print(f"      âŒ å‚æ•°ç²¾åŒ–å¤±è´¥: {str(e)}")
            refinement_result = {"success": False, "error": str(e)}

        self.results["parameter_refinement"] = refinement_result
        return refinement_result

    def test_iterative_convergence(self):
        """æµ‹è¯•3ï¼šè¿­ä»£æ”¶æ•›æ€§éªŒè¯"""
        print("\nğŸ§ª æµ‹è¯•3ï¼šè¿­ä»£æ”¶æ•›æ€§éªŒè¯")
        print("-" * 40)

        # åˆ›å»ºåˆæˆæµ‹è¯•å›¾åƒ
        print("   ğŸ”§ åˆ›å»ºåˆæˆæµ‹è¯•ç›®æ ‡...")

        test_image = self._create_synthetic_test_image()
        signal = test_image.flatten()
        signal_normalized = signal / np.sqrt(np.linalg.norm(signal))

        print(f"      å›¾åƒå°ºå¯¸: {test_image.shape}")
        print(f"      ä¿¡å·èƒ½é‡: {np.linalg.norm(signal_normalized):.3f}")

        # åˆå§‹åŒ–ä¿®å¤ç‰ˆç³»ç»Ÿ
        fixed_system = ASCExtractionFixed(
            extraction_mode="point_only", adaptive_threshold=0.05, max_iterations=20, max_scatterers=15
        )

        print(f"\n   ğŸ¯ æµ‹è¯•è¿­ä»£æ”¶æ•›æ€§...")

        try:
            # æ„å»ºå­—å…¸
            start_time = time.time()
            dictionary, param_grid = fixed_system.build_robust_dictionary()
            dict_time = time.time() - start_time

            print(f"      å­—å…¸æ„å»ºæ—¶é—´: {dict_time:.1f}s")
            print(f"      å­—å…¸è§„æ¨¡: {dictionary.shape}")

            # æ‰§è¡Œè‡ªé€‚åº”æå–
            start_time = time.time()
            extracted_scatterers = fixed_system.fixed_adaptive_extraction(signal_normalized, dictionary, param_grid)
            extraction_time = time.time() - start_time

            # åˆ†ææ”¶æ•›æ€§èƒ½
            num_extracted = len(extracted_scatterers)
            optimization_success_rate = sum(
                1 for s in extracted_scatterers if s.get("optimization_success", False)
            ) / max(num_extracted, 1)

            # è®¡ç®—é‡æ„æ€§èƒ½
            if extracted_scatterers:
                reconstructed_signal = self._reconstruct_signal_from_scatterers(
                    extracted_scatterers, fixed_system, test_image.shape
                )

                reconstruction_error = np.linalg.norm(signal_normalized - reconstructed_signal.flatten())
                energy_reduction = (np.linalg.norm(signal_normalized) - reconstruction_error) / np.linalg.norm(
                    signal_normalized
                )

                # åˆ†æÎ±åˆ†å¸ƒ
                alpha_distribution = {}
                for scatterer in extracted_scatterers:
                    alpha = scatterer["alpha"]
                    scattering_type = fixed_system._classify_scattering_type(alpha)
                    alpha_distribution[scattering_type] = alpha_distribution.get(scattering_type, 0) + 1

                print(f"\n      ğŸ“Š æ”¶æ•›æ€§èƒ½åˆ†æ:")
                print(f"         æå–æ•£å°„ä¸­å¿ƒæ•°: {num_extracted}")
                print(f"         ä¼˜åŒ–æˆåŠŸç‡: {optimization_success_rate:.1%}")
                print(f"         èƒ½é‡å‡å°‘: {energy_reduction:.1%}")
                print(f"         é‡æ„è¯¯å·®: {reconstruction_error:.6f}")
                print(f"         æ€»æå–æ—¶é—´: {extraction_time:.1f}s")
                print(f"         Î±åˆ†å¸ƒ: {alpha_distribution}")

                convergence_result = {
                    "success": True,
                    "num_extracted": num_extracted,
                    "optimization_success_rate": optimization_success_rate,
                    "energy_reduction": energy_reduction,
                    "reconstruction_error": reconstruction_error,
                    "extraction_time": extraction_time,
                    "alpha_distribution": alpha_distribution,
                    "extracted_scatterers": extracted_scatterers,
                }

                if energy_reduction > 0.3:  # 30%+
                    print(f"         ğŸ‰ æ”¶æ•›æ€§èƒ½ä¼˜ç§€ï¼")
                elif energy_reduction > 0.1:  # 10%+
                    print(f"         âœ… æ”¶æ•›æ€§èƒ½è‰¯å¥½")
                else:
                    print(f"         âš ï¸ æ”¶æ•›æ€§èƒ½éœ€è¦æ”¹è¿›")
            else:
                print(f"         âŒ æœªæå–åˆ°æ•£å°„ä¸­å¿ƒ")
                convergence_result = {"success": False, "message": "æœªæå–åˆ°æ•£å°„ä¸­å¿ƒ"}

        except Exception as e:
            print(f"      âŒ è¿­ä»£æå–å¤±è´¥: {str(e)}")
            convergence_result = {"success": False, "error": str(e)}

        self.results["iterative_convergence"] = convergence_result
        return convergence_result

    def _create_synthetic_test_image(self) -> np.ndarray:
        """åˆ›å»ºåˆæˆæµ‹è¯•å›¾åƒ"""
        image_size = (128, 128)
        complex_image = np.zeros(image_size, dtype=complex)

        # æ·»åŠ å‡ ä¸ªä¸åŒå¼ºåº¦çš„æ•£å°„ä¸­å¿ƒ
        scatterer_positions = [
            (64, 64, 1.0, 0.0),  # ä¸­å¿ƒå¼ºæ•£å°„
            (48, 80, 0.6, np.pi / 4),  # ä¸­ç­‰å¼ºåº¦
            (80, 48, 0.4, np.pi / 2),  # è¾ƒå¼±
            (96, 96, 0.3, -np.pi / 3),  # æœ€å¼±
        ]

        for x, y, amplitude, phase in scatterer_positions:
            # æ·»åŠ é«˜æ–¯å½¢çŠ¶çš„æ•£å°„ä¸­å¿ƒ
            for i in range(max(0, x - 5), min(image_size[0], x + 6)):
                for j in range(max(0, y - 5), min(image_size[1], y + 6)):
                    distance = np.sqrt((i - x) ** 2 + (j - y) ** 2)
                    weight = np.exp(-(distance**2) / 8)
                    complex_image[i, j] += amplitude * weight * np.exp(1j * phase)

        # æ·»åŠ å°‘é‡å™ªå£°
        noise_level = 0.05
        noise = noise_level * (np.random.randn(*image_size) + 1j * np.random.randn(*image_size))
        complex_image += noise

        return complex_image

    def _reconstruct_signal_from_scatterers(
        self, scatterers: List[Dict], asc_system, image_shape: Tuple[int, int]
    ) -> np.ndarray:
        """ä»æ•£å°„ä¸­å¿ƒé‡æ„ä¿¡å·"""
        reconstructed = np.zeros(image_shape, dtype=complex)

        fx_range = np.linspace(-asc_system.B / 2, asc_system.B / 2, image_shape[0])
        fy_range = np.linspace(
            -asc_system.fc * np.sin(asc_system.omega / 2), asc_system.fc * np.sin(asc_system.omega / 2), image_shape[1]
        )

        for scatterer in scatterers:
            # ç”ŸæˆåŸå­
            atom = asc_system._generate_robust_asc_atom(
                scatterer["x"],
                scatterer["y"],
                scatterer["alpha"],
                scatterer.get("length", 0.0),
                scatterer.get("phi_bar", 0.0),
                fx_range,
                fy_range,
            )

            # åº”ç”¨å¹…åº¦å’Œç›¸ä½
            contribution = scatterer["estimated_amplitude"] * np.exp(1j * scatterer["estimated_phase"]) * atom

            reconstructed += contribution

        return reconstructed

    def test_mstar_data_compatibility(self):
        """æµ‹è¯•4ï¼šMSTARæ•°æ®å…¼å®¹æ€§éªŒè¯"""
        print("\nğŸ§ª æµ‹è¯•4ï¼šMSTARæ•°æ®å…¼å®¹æ€§éªŒè¯")
        print("-" * 40)

        # æŸ¥æ‰¾å¯ç”¨çš„MSTARæ•°æ®æ–‡ä»¶
        mstar_files = self._find_mstar_files()

        if not mstar_files:
            print("   âš ï¸ æœªæ‰¾åˆ°MSTARæ•°æ®æ–‡ä»¶ï¼Œè·³è¿‡æ­¤æµ‹è¯•")
            self.results["mstar_compatibility"] = {"success": False, "message": "æ— MSTARæ•°æ®"}
            return

        # é€‰æ‹©ç¬¬ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œæµ‹è¯•
        test_file = mstar_files[0]
        print(f"   ğŸ“‚ æµ‹è¯•æ–‡ä»¶: {test_file}")

        try:
            # åˆå§‹åŒ–ä¿®å¤ç‰ˆç³»ç»Ÿ
            fixed_system = ASCExtractionFixed(
                extraction_mode="point_only", adaptive_threshold=0.03, max_iterations=15, max_scatterers=10
            )

            # åŠ è½½æ•°æ®
            start_time = time.time()
            magnitude, complex_image = fixed_system.load_mstar_data(test_file)
            load_time = time.time() - start_time

            print(f"   âœ… æ•°æ®åŠ è½½æˆåŠŸ ({load_time:.2f}s)")
            print(f"      å›¾åƒå°ºå¯¸: {complex_image.shape}")
            print(f"      å¹…åº¦èŒƒå›´: [{np.min(magnitude):.3f}, {np.max(magnitude):.3f}]")

            # æ‰§è¡Œæå–
            start_time = time.time()
            scatterers = fixed_system.extract_asc_scatterers(complex_image)
            extraction_time = time.time() - start_time

            print(f"   âœ… ASCæå–å®Œæˆ ({extraction_time:.1f}s)")
            print(f"      æå–æ•£å°„ä¸­å¿ƒæ•°: {len(scatterers)}")

            if scatterers:
                # åˆ†æç»“æœ
                optimization_success_rate = sum(1 for s in scatterers if s.get("optimization_success", False)) / len(
                    scatterers
                )
                alpha_distribution = {}
                for scatterer in scatterers:
                    alpha = scatterer["alpha"]
                    scattering_type = fixed_system._classify_scattering_type(alpha)
                    alpha_distribution[scattering_type] = alpha_distribution.get(scattering_type, 0) + 1

                print(f"      ä¼˜åŒ–æˆåŠŸç‡: {optimization_success_rate:.1%}")
                print(f"      Î±åˆ†å¸ƒ: {alpha_distribution}")

                mstar_result = {
                    "success": True,
                    "test_file": test_file,
                    "load_time": load_time,
                    "extraction_time": extraction_time,
                    "num_scatterers": len(scatterers),
                    "optimization_success_rate": optimization_success_rate,
                    "alpha_distribution": alpha_distribution,
                }
            else:
                mstar_result = {"success": False, "message": "æœªæå–åˆ°æ•£å°„ä¸­å¿ƒ"}

        except Exception as e:
            print(f"   âŒ MSTARæ•°æ®æµ‹è¯•å¤±è´¥: {str(e)}")
            mstar_result = {"success": False, "error": str(e)}

        self.results["mstar_compatibility"] = mstar_result
        return mstar_result

    def _find_mstar_files(self) -> List[str]:
        """æŸ¥æ‰¾å¯ç”¨çš„MSTARæ•°æ®æ–‡ä»¶"""
        search_paths = ["datasets/SAR_ASC_Project/02_Data_Processed_raw/SN_S7/", "datasets/", "."]

        mstar_files = []

        for search_path in search_paths:
            if os.path.exists(search_path):
                for root, dirs, files in os.walk(search_path):
                    for file in files:
                        if file.endswith(".raw") and "HB" in file:
                            mstar_files.append(os.path.join(root, file))

        return mstar_files[:3]  # æœ€å¤šè¿”å›3ä¸ªæ–‡ä»¶

    def run_comprehensive_validation(self):
        """è¿è¡Œå®Œæ•´éªŒè¯æµ‹è¯•å¥—ä»¶"""
        print("ğŸš€ å¼€å§‹ASCç®—æ³•ä¿®å¤æ•ˆæœç»¼åˆéªŒè¯")
        print("=" * 80)

        start_time = time.time()

        # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
        test_results = {
            "numerical_stability": self.test_numerical_stability(),
            "parameter_refinement": self.test_parameter_refinement_logic(),
            "iterative_convergence": self.test_iterative_convergence(),
            "mstar_compatibility": self.test_mstar_data_compatibility(),
        }

        total_time = time.time() - start_time

        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self._generate_validation_report(test_results, total_time)

        return test_results

    def _generate_validation_report(self, test_results: Dict, total_time: float):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        print("\n" + "=" * 80)
        print("ğŸ“Š ASCç®—æ³•ä¿®å¤æ•ˆæœéªŒè¯æŠ¥å‘Š")
        print("=" * 80)

        # æ±‡æ€»æˆåŠŸç‡
        test_scores = {}

        # 1. æ•°å€¼ç¨³å®šæ€§
        stability = test_results["numerical_stability"]
        stability_success = sum(1 for result in stability.values() if result.get("success", False))
        stability_score = stability_success / len(stability) if stability else 0
        test_scores["æ•°å€¼ç¨³å®šæ€§"] = stability_score

        # 2. å‚æ•°ç²¾åŒ–
        refinement = test_results["parameter_refinement"]
        refinement_score = 1.0 if refinement.get("success", False) else 0.0
        test_scores["å‚æ•°ç²¾åŒ–"] = refinement_score

        # 3. è¿­ä»£æ”¶æ•›
        convergence = test_results["iterative_convergence"]
        if convergence.get("success", False):
            energy_reduction = convergence.get("energy_reduction", 0)
            convergence_score = min(1.0, energy_reduction / 0.3)  # 30%ä¸ºæ»¡åˆ†
        else:
            convergence_score = 0.0
        test_scores["è¿­ä»£æ”¶æ•›"] = convergence_score

        # 4. MSTARå…¼å®¹æ€§
        mstar = test_results["mstar_compatibility"]
        mstar_score = 1.0 if mstar.get("success", False) else 0.0
        test_scores["MSTARå…¼å®¹æ€§"] = mstar_score

        # è®¡ç®—æ€»ä½“è¯„åˆ†
        overall_score = np.mean(list(test_scores.values()))

        print(f"\nğŸ“ˆ æµ‹è¯•ç»“æœæ±‡æ€»:")
        for test_name, score in test_scores.items():
            status = "âœ…" if score > 0.8 else "âš ï¸" if score > 0.5 else "âŒ"
            print(f"   {status} {test_name}: {score:.1%}")

        print(f"\nğŸ¯ æ€»ä½“è¯„åˆ†: {overall_score:.1%}")
        print(f"â±ï¸ æ€»æµ‹è¯•æ—¶é—´: {total_time:.1f}s")

        # é—®é¢˜ä¿®å¤çŠ¶æ€
        print(f"\nğŸ”§ å…³é”®é—®é¢˜ä¿®å¤çŠ¶æ€:")

        if stability_score > 0.8:
            print("   âœ… é—®é¢˜1 (æ•°å€¼ç¨³å®šæ€§): å·²ä¿®å¤")
        else:
            print("   âŒ é—®é¢˜1 (æ•°å€¼ç¨³å®šæ€§): æœªå®Œå…¨ä¿®å¤")

        if refinement_score > 0.8:
            print("   âœ… é—®é¢˜2 (å‚æ•°ç²¾åŒ–é€»è¾‘): å·²ä¿®å¤")
        else:
            print("   âŒ é—®é¢˜2 (å‚æ•°ç²¾åŒ–é€»è¾‘): æœªå®Œå…¨ä¿®å¤")

        if convergence_score > 0.6:
            print("   âœ… é—®é¢˜3 (è¿­ä»£æ”¶æ•›): å·²ä¿®å¤")
        else:
            print("   âŒ é—®é¢˜3 (è¿­ä»£æ”¶æ•›): æœªå®Œå…¨ä¿®å¤")

        # æ€»ç»“å»ºè®®
        print(f"\nğŸ’¡ ä¿®å¤æ•ˆæœè¯„ä¼°:")

        if overall_score > 0.8:
            print("   ğŸ‰ ä¿®å¤æ•ˆæœä¼˜ç§€ï¼ç®—æ³•å·²æˆåŠŸè§£å†³äº†æ ¸å¿ƒé—®é¢˜")
            print("   ğŸ“‹ å»ºè®®ï¼šå¯ä»¥è¿›å…¥ç”Ÿäº§çº§éªŒè¯å’Œå®é™…åº”ç”¨é˜¶æ®µ")
        elif overall_score > 0.6:
            print("   âœ… ä¿®å¤æ•ˆæœè‰¯å¥½ï¼ä¸»è¦é—®é¢˜å·²è§£å†³")
            print("   ğŸ“‹ å»ºè®®ï¼šç»§ç»­ä¼˜åŒ–ç»†èŠ‚ï¼Œæé«˜ç¨³å®šæ€§")
        else:
            print("   âš ï¸ ä¿®å¤æ•ˆæœæœ‰é™ï¼Œä»æœ‰å…³é”®é—®é¢˜éœ€è¦è§£å†³")
            print("   ğŸ“‹ å»ºè®®ï¼šé‡æ–°å®¡è§†ä¿®å¤ç­–ç•¥ï¼Œæ·±å…¥è°ƒè¯•")


def main():
    """è¿è¡Œä¿®å¤æ•ˆæœéªŒè¯æµ‹è¯•"""
    print("ğŸ”¬ ASCç®—æ³•ä¿®å¤æ•ˆæœéªŒè¯æµ‹è¯•ç¨‹åº")
    print("è§£å†³next_work_goal.mdä¸­æåˆ°çš„ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜")
    print("=" * 80)

    # åˆ›å»ºéªŒè¯å™¨
    validator = AlgorithmFixValidator()

    # è¿è¡Œå®Œæ•´éªŒè¯
    results = validator.run_comprehensive_validation()

    return validator, results


if __name__ == "__main__":
    validator, results = main()
