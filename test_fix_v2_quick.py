"""
Quick Test for ASC Fix v2
å¿«é€Ÿæµ‹è¯•ä¿®å¤ç‰ˆv2æ•ˆæœ

é‡ç‚¹éªŒè¯ï¼š
1. MSTARæ•°æ®åŠ è½½NaNé—®é¢˜ä¿®å¤
2. è¿­ä»£æ”¶æ•›æ€§èƒ½æ”¹è¿›
3. ä¸v1ç‰ˆæœ¬æ€§èƒ½å¯¹æ¯”
"""

import numpy as np
import time
import os
from asc_extraction_fixed_v2 import ASCExtractionFixedV2, visualize_extraction_results


def test_mstar_compatibility_v2():
    """æµ‹è¯•MSTARæ•°æ®å…¼å®¹æ€§v2"""
    print("ğŸ§ª æµ‹è¯•MSTARæ•°æ®å…¼å®¹æ€§v2")
    print("-" * 40)

    # æŸ¥æ‰¾MSTARæ•°æ®æ–‡ä»¶
    mstar_files = []
    search_paths = [
        "datasets/SAR_ASC_Project/02_Data_Processed_raw/SN_S7/",
        "datasets/SAR_ASC_Project/02_Data_Processed_raw/",
        "datasets/",
    ]

    for search_path in search_paths:
        if os.path.exists(search_path):
            for root, dirs, files in os.walk(search_path):
                for file in files:
                    if file.endswith(".raw") and "HB" in file:
                        mstar_files.append(os.path.join(root, file))

    if not mstar_files:
        print("   âš ï¸ æœªæ‰¾åˆ°MSTARæ•°æ®æ–‡ä»¶")
        return {"success": False, "message": "æ— æ•°æ®æ–‡ä»¶"}

    test_file = mstar_files[0]
    print(f"   ğŸ“‚ æµ‹è¯•æ–‡ä»¶: {test_file}")

    # åˆå§‹åŒ–v2ç³»ç»Ÿ
    asc_v2 = ASCExtractionFixedV2(
        extraction_mode="point_only", adaptive_threshold=0.03, max_iterations=15, max_scatterers=10
    )

    try:
        # æµ‹è¯•ç¨³å¥æ•°æ®åŠ è½½
        start_time = time.time()
        magnitude, complex_image = asc_v2.load_mstar_data_robust(test_file)
        load_time = time.time() - start_time

        # æ£€æŸ¥æ•°æ®è´¨é‡
        has_nan = np.any(np.isnan(complex_image))
        has_inf = np.any(np.isinf(complex_image))
        signal_energy = np.linalg.norm(complex_image)

        print(f"   âœ… æ•°æ®åŠ è½½æµ‹è¯•:")
        print(f"      åŠ è½½æ—¶é—´: {load_time:.2f}s")
        print(f"      åŒ…å«NaN: {'æ˜¯' if has_nan else 'å¦'}")
        print(f"      åŒ…å«Inf: {'æ˜¯' if has_inf else 'å¦'}")
        print(f"      ä¿¡å·èƒ½é‡: {signal_energy:.3f}")
        print(f"      æ•°æ®æœ‰æ•ˆæ€§: {'âœ…' if not has_nan and not has_inf and signal_energy > 0 else 'âŒ'}")

        if not has_nan and not has_inf and signal_energy > 0:
            # æµ‹è¯•ASCæå–
            print(f"\n   ğŸ¯ æµ‹è¯•ASCæå–...")
            start_time = time.time()
            scatterers = asc_v2.extract_asc_scatterers_v2(complex_image)
            extraction_time = time.time() - start_time

            print(f"      æå–æ—¶é—´: {extraction_time:.1f}s")
            print(f"      æå–æ•£å°„ä¸­å¿ƒæ•°: {len(scatterers)}")

            if scatterers:
                # åˆ†ææ•£å°„ç±»å‹åˆ†å¸ƒ
                alpha_dist = {}
                for s in scatterers:
                    stype = s["scattering_type"]
                    alpha_dist[stype] = alpha_dist.get(stype, 0) + 1

                print(f"      æ•£å°„ç±»å‹åˆ†å¸ƒ: {alpha_dist}")

                result = {
                    "success": True,
                    "load_time": load_time,
                    "extraction_time": extraction_time,
                    "num_scatterers": len(scatterers),
                    "alpha_distribution": alpha_dist,
                    "data_quality": "clean",
                }
            else:
                result = {"success": True, "message": "æ•°æ®åŠ è½½æˆåŠŸä½†æœªæå–åˆ°æ•£å°„ä¸­å¿ƒ", "data_quality": "clean"}
        else:
            result = {
                "success": False,
                "message": "æ•°æ®è´¨é‡é—®é¢˜",
                "has_nan": has_nan,
                "has_inf": has_inf,
                "signal_energy": signal_energy,
            }

    except Exception as e:
        print(f"   âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        result = {"success": False, "error": str(e)}

    return result


def test_synthetic_convergence_v2():
    """æµ‹è¯•åˆæˆæ•°æ®æ”¶æ•›æ€§v2"""
    print("\nğŸ§ª æµ‹è¯•åˆæˆæ•°æ®æ”¶æ•›æ€§v2")
    print("-" * 40)

    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    print("   ğŸ”§ åˆ›å»ºåˆæˆæµ‹è¯•å›¾åƒ...")
    image_size = (128, 128)
    complex_image = np.zeros(image_size, dtype=complex)

    # æ·»åŠ å‡ ä¸ªæ•£å°„ä¸­å¿ƒ
    scatterer_positions = [
        (64, 64, 1.0, 0.0),  # ä¸»æ•£å°„ä¸­å¿ƒ
        (80, 48, 0.5, np.pi / 4),  # æ¬¡æ•£å°„ä¸­å¿ƒ
        (48, 80, 0.3, np.pi / 2),  # å¼±æ•£å°„ä¸­å¿ƒ
    ]

    for x, y, amplitude, phase in scatterer_positions:
        # é«˜æ–¯å½¢çŠ¶æ•£å°„ä¸­å¿ƒ
        for i in range(max(0, x - 3), min(image_size[0], x + 4)):
            for j in range(max(0, y - 3), min(image_size[1], y + 4)):
                distance = np.sqrt((i - x) ** 2 + (j - y) ** 2)
                weight = np.exp(-(distance**2) / 4)
                complex_image[i, j] += amplitude * weight * np.exp(1j * phase)

    # æ·»åŠ é€‚é‡å™ªå£°
    noise_level = 0.02
    noise = noise_level * (np.random.randn(*image_size) + 1j * np.random.randn(*image_size))
    complex_image += noise

    print(f"      å›¾åƒå°ºå¯¸: {complex_image.shape}")
    print(f"      ä¿¡å·èƒ½é‡: {np.linalg.norm(complex_image):.3f}")
    print(f"      ä¿¡å™ªæ¯”: ~{1/noise_level:.1f}")

    # æµ‹è¯•v2æå–
    asc_v2 = ASCExtractionFixedV2(
        extraction_mode="point_only", adaptive_threshold=0.05, max_iterations=15, max_scatterers=10
    )

    try:
        start_time = time.time()
        scatterers = asc_v2.extract_asc_scatterers_v2(complex_image)
        extraction_time = time.time() - start_time

        print(f"\n   ğŸ“Š æ”¶æ•›æ€§èƒ½åˆ†æ:")
        print(f"      æå–æ—¶é—´: {extraction_time:.1f}s")
        print(f"      æ•£å°„ä¸­å¿ƒæ•°: {len(scatterers)}")

        if scatterers:
            # åˆ†æç»“æœè´¨é‡
            alpha_dist = {}
            positions = []
            amplitudes = []

            for s in scatterers:
                stype = s["scattering_type"]
                alpha_dist[stype] = alpha_dist.get(stype, 0) + 1
                positions.append((s["x"], s["y"]))
                amplitudes.append(s["estimated_amplitude"])

            print(f"      æ•£å°„ç±»å‹åˆ†å¸ƒ: {alpha_dist}")
            print(f"      å¹…åº¦èŒƒå›´: [{min(amplitudes):.3f}, {max(amplitudes):.3f}]")
            print(f"      ä½ç½®åˆ†å¸ƒ: æ£€æµ‹åˆ°{len(positions)}ä¸ªä½ç½®")

            # è¯„ä¼°æ”¶æ•›è´¨é‡
            if len(scatterers) >= 2:
                convergence_quality = "è‰¯å¥½"
                if max(amplitudes) / min(amplitudes) > 2:  # å¹…åº¦åˆ†å¸ƒåˆç†
                    convergence_quality = "ä¼˜ç§€"
            else:
                convergence_quality = "éœ€è¦æ”¹è¿›"

            print(f"      æ”¶æ•›è´¨é‡: {convergence_quality}")

            result = {
                "success": True,
                "extraction_time": extraction_time,
                "num_scatterers": len(scatterers),
                "alpha_distribution": alpha_dist,
                "convergence_quality": convergence_quality,
                "amplitude_range": [min(amplitudes), max(amplitudes)],
            }
        else:
            result = {"success": False, "message": "æœªæå–åˆ°æ•£å°„ä¸­å¿ƒ"}

    except Exception as e:
        print(f"   âŒ æ”¶æ•›æµ‹è¯•å¤±è´¥: {str(e)}")
        result = {"success": False, "error": str(e)}

    return result


def test_numerical_stability_v2():
    """æµ‹è¯•æ•°å€¼ç¨³å®šæ€§v2"""
    print("\nğŸ§ª æµ‹è¯•æ•°å€¼ç¨³å®šæ€§v2")
    print("-" * 40)

    asc_v2 = ASCExtractionFixedV2()

    # æµ‹è¯•æ‰€æœ‰Î±å€¼çš„åŸå­ç”Ÿæˆ
    test_alphas = [-1.0, -0.5, 0.0, 0.5, 1.0]
    fx_range = np.linspace(-5e8, 5e8, 64)  # è¾ƒå°å°ºå¯¸åŠ å¿«æµ‹è¯•
    fy_range = np.linspace(-5e8, 5e8, 64)

    stability_results = {}

    for alpha in test_alphas:
        try:
            start_time = time.time()
            atom = asc_v2._generate_robust_asc_atom(0.5, 0.3, alpha, 0.0, 0.0, fx_range, fy_range)
            generation_time = time.time() - start_time

            atom_flat = atom.flatten()
            atom_energy = np.linalg.norm(atom_flat)
            has_nan = np.any(np.isnan(atom_flat))
            has_inf = np.any(np.isinf(atom_flat))

            stability_results[alpha] = {
                "success": not has_nan and not has_inf and atom_energy > 1e-12,
                "atom_energy": atom_energy,
                "generation_time": generation_time,
                "has_issues": has_nan or has_inf,
            }

            status = "âœ…" if stability_results[alpha]["success"] else "âŒ"
            print(f"   Î±={alpha:4.1f}: {status} (èƒ½é‡: {atom_energy:.2e}, æ—¶é—´: {generation_time:.3f}s)")

        except Exception as e:
            stability_results[alpha] = {"success": False, "error": str(e)}
            print(f"   Î±={alpha:4.1f}: âŒ å¼‚å¸¸: {str(e)}")

    # ç»Ÿè®¡ç»“æœ
    successful_count = sum(1 for result in stability_results.values() if result.get("success", False))
    success_rate = successful_count / len(test_alphas)

    print(f"\n   ğŸ“Š æ•°å€¼ç¨³å®šæ€§æ€»ç»“:")
    print(f"      æˆåŠŸç‡: {success_rate:.1%} ({successful_count}/{len(test_alphas)})")

    return {"success_rate": success_rate, "detailed_results": stability_results}


def run_quick_validation_v2():
    """è¿è¡Œv2ç‰ˆæœ¬å¿«é€ŸéªŒè¯"""
    print("ğŸš€ ASCä¿®å¤ç‰ˆv2å¿«é€ŸéªŒè¯")
    print("=" * 60)

    start_time = time.time()

    # æ‰§è¡Œæµ‹è¯•
    results = {
        "numerical_stability": test_numerical_stability_v2(),
        "synthetic_convergence": test_synthetic_convergence_v2(),
        "mstar_compatibility": test_mstar_compatibility_v2(),
    }

    total_time = time.time() - start_time

    # ç”Ÿæˆç®€åŒ–æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š v2ç‰ˆæœ¬éªŒè¯æŠ¥å‘Š")
    print("=" * 60)

    # è¯„ä¼°å„é¡¹æµ‹è¯•
    scores = {}

    # æ•°å€¼ç¨³å®šæ€§
    stability = results["numerical_stability"]
    scores["æ•°å€¼ç¨³å®šæ€§"] = stability["success_rate"]

    # åˆæˆæ•°æ®æ”¶æ•›
    convergence = results["synthetic_convergence"]
    if convergence.get("success", False):
        quality = convergence.get("convergence_quality", "éœ€è¦æ”¹è¿›")
        scores["æ”¶æ•›æ€§èƒ½"] = 1.0 if quality == "ä¼˜ç§€" else 0.8 if quality == "è‰¯å¥½" else 0.4
    else:
        scores["æ”¶æ•›æ€§èƒ½"] = 0.0

    # MSTARå…¼å®¹æ€§
    mstar = results["mstar_compatibility"]
    scores["MSTARå…¼å®¹æ€§"] = 1.0 if mstar.get("success", False) else 0.0

    # æ€»ä½“è¯„åˆ†
    overall_score = np.mean(list(scores.values()))

    print(f"\nğŸ“ˆ æµ‹è¯•ç»“æœ:")
    for test_name, score in scores.items():
        status = "âœ…" if score > 0.8 else "âš ï¸" if score > 0.5 else "âŒ"
        print(f"   {status} {test_name}: {score:.1%}")

    print(f"\nğŸ¯ v2ç‰ˆæœ¬æ€»ä½“è¯„åˆ†: {overall_score:.1%}")
    print(f"â±ï¸ æµ‹è¯•æ—¶é—´: {total_time:.1f}s")

    # æ”¹è¿›è¯„ä¼°
    print(f"\nğŸ’¡ v2ç‰ˆæœ¬æ”¹è¿›æ•ˆæœ:")
    if overall_score > 0.8:
        print("   ğŸ‰ v2ç‰ˆæœ¬ä¿®å¤æ•ˆæœä¼˜ç§€ï¼å…³é”®é—®é¢˜å·²è§£å†³")
    elif overall_score > 0.6:
        print("   âœ… v2ç‰ˆæœ¬ä¿®å¤æ•ˆæœè‰¯å¥½ï¼Œä¸»è¦é—®é¢˜å·²è§£å†³")
    else:
        print("   âš ï¸ v2ç‰ˆæœ¬ä»éœ€è¿›ä¸€æ­¥æ”¹è¿›")

    # å…·ä½“å»ºè®®
    if scores["æ•°å€¼ç¨³å®šæ€§"] < 1.0:
        print("   ğŸ“‹ å»ºè®®ï¼šç»§ç»­ä¼˜åŒ–æ•°å€¼ç¨³å®šæ€§")
    if scores["æ”¶æ•›æ€§èƒ½"] < 0.8:
        print("   ğŸ“‹ å»ºè®®ï¼šä¼˜åŒ–è¿­ä»£æ”¶æ•›ç®—æ³•")
    if scores["MSTARå…¼å®¹æ€§"] < 1.0:
        print("   ğŸ“‹ å»ºè®®ï¼šæ”¹è¿›MSTARæ•°æ®æ ¼å¼å…¼å®¹æ€§")

    return results


def test_fixed_algorithm_v3():
    """æµ‹è¯•å®Œå…¨ä¿®å¤çš„ç®—æ³•v3ç‰ˆæœ¬ - åŒ…å«å¯è§†åŒ–"""
    print("\nğŸš€ æµ‹è¯•å®Œå…¨ä¿®å¤çš„ç®—æ³•v3ç‰ˆæœ¬")
    print("=" * 60)

    # åˆ›å»ºä¿®å¤ç‰ˆç®—æ³•å®ä¾‹
    asc_v3 = ASCExtractionFixedV2(
        extraction_mode="point_only", adaptive_threshold=0.05, max_iterations=15, max_scatterers=10  # ç¨å¾®æ”¾å®½é˜ˆå€¼
    )

    print("ğŸ”§ ç®—æ³•é…ç½®:")
    print(f"   æå–æ¨¡å¼: point_only (ä¸“æ³¨Î±å€¼è¯†åˆ«)")
    print(f"   è‡ªé€‚åº”é˜ˆå€¼: 0.05")
    print(f"   æœ€å¤§è¿­ä»£: 15")
    print(f"   æœ€å¤§æ•£å°„ä¸­å¿ƒ: 10")

    # 1. æµ‹è¯•MSTARæ•°æ®åŠ è½½
    print(f"\nğŸ“‚ 1. æµ‹è¯•MSTARæ•°æ®å…¼å®¹æ€§...")

    # æŸ¥æ‰¾MSTARæ•°æ®æ–‡ä»¶
    mstar_files = []
    search_paths = [
        "datasets/SAR_ASC_Project/02_Data_Processed_raw/SN_S7/",
        "datasets/SAR_ASC_Project/02_Data_Processed_raw/",
        "datasets/",
    ]

    for search_path in search_paths:
        if os.path.exists(search_path):
            for root, dirs, files in os.walk(search_path):
                for file in files:
                    if file.endswith(".raw") and "HB" in file:
                        mstar_files.append(os.path.join(root, file))

    if mstar_files:
        test_file = mstar_files[0]
        print(f"   ä½¿ç”¨æµ‹è¯•æ–‡ä»¶: {test_file}")

        try:
            # ç¨³å¥æ•°æ®åŠ è½½
            magnitude, complex_image = asc_v3.load_mstar_data_robust(test_file)

            print(f"   âœ… æ•°æ®åŠ è½½æˆåŠŸ!")
            print(f"      å›¾åƒå°ºå¯¸: {complex_image.shape}")
            print(f"      ä¿¡å·èƒ½é‡: {np.linalg.norm(complex_image):.3f}")

            # 2. æµ‹è¯•ASCæ•£å°„ä¸­å¿ƒæå–
            print(f"\nğŸ¯ 2. æµ‹è¯•ASCæ•£å°„ä¸­å¿ƒæå–...")
            start_time = time.time()

            scatterers = asc_v3.extract_asc_scatterers_v2(complex_image)

            extraction_time = time.time() - start_time

            print(f"\nğŸ“Š æå–ç»“æœ:")
            print(f"   æå–æ—¶é—´: {extraction_time:.2f}s")
            print(f"   æ•£å°„ä¸­å¿ƒæ•°: {len(scatterers)}")

            if scatterers:
                print(f"   æå–æˆåŠŸ! è¯¦ç»†ä¿¡æ¯:")
                for i, sc in enumerate(scatterers):
                    opt_status = "âœ…" if sc.get("optimization_success", False) else "âš ï¸"
                    print(
                        f"     #{i+1}: {opt_status} ä½ç½®({sc['x']:.3f}, {sc['y']:.3f}), "
                        f"ç±»å‹: {sc['scattering_type']}, "
                        f"å¹…åº¦: {sc['estimated_amplitude']:.3f}"
                    )

                # 3. å¯è§†åŒ–ç»“æœ
                print(f"\nğŸ–¼ï¸ 3. ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
                try:
                    save_path = "results/asc_extraction_result_v3.png"
                    os.makedirs("results", exist_ok=True)

                    visualize_extraction_results(complex_image, scatterers, save_path)

                    print(f"   âœ… å¯è§†åŒ–æˆåŠŸ!")
                    print(f"   ç»“æœä¿å­˜è‡³: {save_path}")

                except Exception as e:
                    print(f"   âš ï¸ å¯è§†åŒ–å¼‚å¸¸: {str(e)}")

                # 4. ç»“æœè´¨é‡è¯„ä¼°
                print(f"\nğŸ“ˆ 4. ç»“æœè´¨é‡è¯„ä¼°...")

                # ç»Ÿè®¡æ•£å°„ç±»å‹åˆ†å¸ƒ
                alpha_dist = {}
                opt_success_count = 0
                amplitudes = []

                for sc in scatterers:
                    stype = sc["scattering_type"]
                    alpha_dist[stype] = alpha_dist.get(stype, 0) + 1
                    if sc.get("optimization_success", False):
                        opt_success_count += 1
                    amplitudes.append(sc["estimated_amplitude"])

                print(f"   æ•£å°„ç±»å‹åˆ†å¸ƒ: {alpha_dist}")
                print(
                    f"   ä¼˜åŒ–æˆåŠŸç‡: {opt_success_count}/{len(scatterers)} ({opt_success_count/len(scatterers)*100:.1f}%)"
                )
                print(f"   å¹…åº¦èŒƒå›´: [{min(amplitudes):.3f}, {max(amplitudes):.3f}]")

                # è´¨é‡è¯„åˆ†
                quality_score = 0
                if len(scatterers) >= 3:  # æå–åˆ°è¶³å¤Ÿæ•£å°„ä¸­å¿ƒ
                    quality_score += 30
                if opt_success_count / len(scatterers) > 0.5:  # ä¼˜åŒ–æˆåŠŸç‡ > 50%
                    quality_score += 30
                if len(alpha_dist) >= 2:  # è¯†åˆ«åˆ°å¤šç§æ•£å°„ç±»å‹
                    quality_score += 40

                print(f"\nğŸ¯ ç®—æ³•è´¨é‡è¯„åˆ†: {quality_score}/100")

                if quality_score >= 80:
                    print("   ğŸ‰ ä¼˜ç§€! ç®—æ³•ä¿®å¤éå¸¸æˆåŠŸ!")
                elif quality_score >= 60:
                    print("   âœ… è‰¯å¥½! ç®—æ³•ä¿®å¤åŸºæœ¬æˆåŠŸ!")
                else:
                    print("   âš ï¸ éœ€è¦æ”¹è¿›! è¯·æ£€æŸ¥å‚æ•°è®¾ç½®!")

                return {
                    "success": True,
                    "num_scatterers": len(scatterers),
                    "extraction_time": extraction_time,
                    "quality_score": quality_score,
                    "alpha_distribution": alpha_dist,
                    "optimization_success_rate": opt_success_count / len(scatterers),
                    "scatterers": scatterers,
                }

            else:
                print("   âŒ æœªæå–åˆ°æ•£å°„ä¸­å¿ƒ!")
                print("   å¯èƒ½åŸå› :")
                print("     - è‡ªé€‚åº”é˜ˆå€¼è¿‡ä¸¥æ ¼")
                print("     - æ•°æ®ä¿¡å·è¿‡å¼±")
                print("     - ç®—æ³•å‚æ•°éœ€è¦è°ƒæ•´")

                return {"success": False, "message": "æœªæå–åˆ°æ•£å°„ä¸­å¿ƒ"}

        except Exception as e:
            print(f"   âŒ ç®—æ³•æµ‹è¯•å¤±è´¥: {str(e)}")
            import traceback

            traceback.print_exc()
            return {"success": False, "error": str(e)}

    else:
        print("   âš ï¸ æœªæ‰¾åˆ°MSTARæ•°æ®æ–‡ä»¶")

        # ä½¿ç”¨åˆæˆæ•°æ®è¿›è¡Œæµ‹è¯•
        print(f"\nğŸ”§ 2. ä½¿ç”¨åˆæˆæ•°æ®æµ‹è¯•...")
        return test_with_synthetic_data_v3(asc_v3)


def test_with_synthetic_data_v3(asc_v3):
    """ä½¿ç”¨åˆæˆæ•°æ®æµ‹è¯•v3ç®—æ³•"""
    print("   åˆ›å»ºåˆæˆæµ‹è¯•æ•°æ®...")

    # åˆ›å»ºæ›´å¤æ‚çš„æµ‹è¯•å›¾åƒ
    image_size = (128, 128)
    complex_image = np.zeros(image_size, dtype=complex)

    # æ·»åŠ å¤šä¸ªä¸åŒç±»å‹çš„æ•£å°„ä¸­å¿ƒ
    scatterer_positions = [
        (0.3, 0.2, 1.0, 0.0),  # å¼ºæ•£å°„ä¸­å¿ƒ
        (-0.4, 0.5, 0.6, np.pi / 4),  # ä¸­ç­‰æ•£å°„ä¸­å¿ƒ
        (0.1, -0.3, 0.4, np.pi / 2),  # å¼±æ•£å°„ä¸­å¿ƒ
        (-0.2, -0.4, 0.8, 0.0),  # å¦ä¸€ä¸ªå¼ºæ•£å°„ä¸­å¿ƒ
    ]

    for x, y, amplitude, phase in scatterer_positions:
        # è½¬æ¢åˆ°åƒç´ åæ ‡
        px = int((x + 1) * image_size[0] / 2)
        py = int((y + 1) * image_size[1] / 2)

        # é«˜æ–¯å½¢çŠ¶æ•£å°„ä¸­å¿ƒ
        for i in range(max(0, px - 4), min(image_size[0], px + 5)):
            for j in range(max(0, py - 4), min(image_size[1], py + 5)):
                distance = np.sqrt((i - px) ** 2 + (j - py) ** 2)
                weight = np.exp(-(distance**2) / 8)
                complex_image[i, j] += amplitude * weight * np.exp(1j * phase)

    # æ·»åŠ é€‚é‡å™ªå£°
    noise_level = 0.05
    noise = noise_level * (np.random.randn(*image_size) + 1j * np.random.randn(*image_size))
    complex_image += noise

    print(f"   åˆæˆæ•°æ®ç‰¹å¾:")
    print(f"     å›¾åƒå°ºå¯¸: {complex_image.shape}")
    print(f"     ä¿¡å·èƒ½é‡: {np.linalg.norm(complex_image):.3f}")
    print(f"     ç†è®ºæ•£å°„ä¸­å¿ƒæ•°: {len(scatterer_positions)}")

    # æå–æ•£å°„ä¸­å¿ƒ
    print(f"\nğŸ¯ å¼€å§‹åˆæˆæ•°æ®ASCæå–...")
    start_time = time.time()

    scatterers = asc_v3.extract_asc_scatterers_v2(complex_image)

    extraction_time = time.time() - start_time

    print(f"\nğŸ“Š åˆæˆæ•°æ®æå–ç»“æœ:")
    print(f"   æå–æ—¶é—´: {extraction_time:.2f}s")
    print(f"   æå–æ•£å°„ä¸­å¿ƒæ•°: {len(scatterers)}")
    print(f"   ç†è®ºæ•£å°„ä¸­å¿ƒæ•°: {len(scatterer_positions)}")

    if scatterers:
        # å¯è§†åŒ–
        try:
            save_path = "results/asc_synthetic_result_v3.png"
            os.makedirs("results", exist_ok=True)

            visualize_extraction_results(complex_image, scatterers, save_path)
            print(f"   âœ… åˆæˆæ•°æ®å¯è§†åŒ–ä¿å­˜è‡³: {save_path}")

        except Exception as e:
            print(f"   âš ï¸ å¯è§†åŒ–å¼‚å¸¸: {str(e)}")

        return {
            "success": True,
            "num_scatterers": len(scatterers),
            "extraction_time": extraction_time,
            "synthetic_test": True,
            "expected_count": len(scatterer_positions),
        }
    else:
        return {"success": False, "message": "åˆæˆæ•°æ®æµ‹è¯•å¤±è´¥"}


if __name__ == "__main__":
    # è¿è¡ŒåŸå§‹æµ‹è¯•
    print("ğŸš€ ASCä¿®å¤ç‰ˆv2å¿«é€ŸéªŒè¯")
    print("=" * 60)
    results = run_quick_validation_v2()

    # è¿è¡Œæ–°çš„v3ç®—æ³•æµ‹è¯•
    v3_results = test_fixed_algorithm_v3()

    # ç»¼åˆæŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ¯ ç»¼åˆæµ‹è¯•æŠ¥å‘Š")
    print("=" * 60)

    if v3_results.get("success", False):
        print("âœ… v3ä¿®å¤ç®—æ³•æµ‹è¯•æˆåŠŸ!")
        print(f"   æ•£å°„ä¸­å¿ƒæå–: {v3_results.get('num_scatterers', 0)}ä¸ª")
        print(f"   è´¨é‡è¯„åˆ†: {v3_results.get('quality_score', 0)}/100")
        if "optimization_success_rate" in v3_results:
            print(f"   ä¼˜åŒ–æˆåŠŸç‡: {v3_results['optimization_success_rate']:.1%}")
        print("\nğŸ‰ ç‰©ç†å°ºåº¦ã€å‚æ•°ç²¾åŒ–å’Œæ”¶æ•›æ€§é—®é¢˜å·²ä¿®å¤!")
        print("   ç®—æ³•ç°åœ¨èƒ½å¤Ÿæ­£ç¡®æå–å±æ€§æ•£å°„ä¸­å¿ƒå¹¶è¿›è¡Œå¯è§†åŒ–ã€‚")
    else:
        print("âŒ v3ä¿®å¤ç®—æ³•ä»éœ€è°ƒè¯•")
        print(f"   é”™è¯¯ä¿¡æ¯: {v3_results.get('message', 'Unknown error')}")

    print(f"\nğŸ’¡ åç»­å»ºè®®:")
    print(f"   1. æ£€æŸ¥results/ç›®å½•ä¸­çš„å¯è§†åŒ–ç»“æœ")
    print(f"   2. å¦‚æœæ•ˆæœè‰¯å¥½ï¼Œå¯ä»¥æ‰©å±•åˆ°'progressive'æ¨¡å¼")
    print(f"   3. è°ƒæ•´adaptive_thresholdå‚æ•°ä¼˜åŒ–æå–æ•ˆæœ")
