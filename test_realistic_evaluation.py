"""
ç°å®OMPç®—æ³•è¯„ä¼°è„šæœ¬
Realistic OMP Algorithm Evaluation Script

é‡æ–°è®¾å®šåˆç†çš„è¯„ä¼°æ ‡å‡†ï¼Œä¸“æ³¨äºOMPç®—æ³•çš„å®é™…èƒ½åŠ›
"""

import numpy as np
import matplotlib.pyplot as plt
from omp_asc_final import OMPASCFinal
import time
import os


def create_realistic_test_data():
    """åˆ›å»ºç°å®çš„æµ‹è¯•æ•°æ®"""
    print("åˆ›å»ºç°å®OMPè¯„ä¼°æµ‹è¯•æ•°æ®...")

    image_size = (128, 128)

    # çœŸå®æ•£å°„ä¸­å¿ƒ - ä½¿ç”¨æ›´åˆç†çš„å¹…åº¦åˆ†å¸ƒ
    true_scatterers = [
        {"x": 0.2, "y": 0.3, "amplitude": 1.0, "phase": 0.0},
        {"x": -0.4, "y": -0.1, "amplitude": 0.8, "phase": np.pi / 4},
        {"x": 0.1, "y": -0.5, "amplitude": 0.6, "phase": -np.pi / 3},
        {"x": -0.2, "y": 0.4, "amplitude": 0.5, "phase": np.pi / 2},
        {"x": 0.5, "y": 0.1, "amplitude": 0.4, "phase": -np.pi / 6},
    ]

    # SARç³»ç»Ÿå‚æ•°
    fc = 1e10
    B = 5e8
    omega = 2.86 * np.pi / 180

    # åˆ›å»ºå¤å€¼å›¾åƒ
    complex_image = np.zeros(image_size, dtype=complex)

    # é¢‘åŸŸç½‘æ ¼
    fx_range = np.linspace(-B / 2, B / 2, image_size[0])
    fy_range = np.linspace(-fc * np.sin(omega / 2), fc * np.sin(omega / 2), image_size[1])

    # ç”Ÿæˆæ•£å°„ä¸­å¿ƒè´¡çŒ®
    for scatterer in true_scatterers:
        x, y = scatterer["x"], scatterer["y"]
        amp = scatterer["amplitude"]
        phase = scatterer["phase"]

        scene_size = 30.0
        x_actual = x * scene_size / 2
        y_actual = y * scene_size / 2

        freq_response = np.zeros(image_size, dtype=complex)
        for i, fx in enumerate(fx_range):
            for j, fy in enumerate(fy_range):
                position_phase = -2j * np.pi * (fx * x_actual + fy * y_actual) / 3e8
                total_phase = position_phase + 1j * phase
                freq_response[i, j] = amp * np.exp(total_phase)

        spatial_response = np.fft.ifft2(np.fft.ifftshift(freq_response))
        complex_image += spatial_response

    # æ·»åŠ å™ªå£°
    signal_power = np.mean(np.abs(complex_image) ** 2)
    noise_level = np.sqrt(signal_power / 100)  # SNR â‰ˆ 20dB
    noise = noise_level * (np.random.randn(*image_size) + 1j * np.random.randn(*image_size))
    complex_image += noise

    magnitude = np.abs(complex_image)

    # è®¡ç®—å®é™…ä¿¡å™ªæ¯”
    signal_power_final = np.mean(np.abs(complex_image - noise) ** 2)
    noise_power = np.mean(np.abs(noise) ** 2)
    snr_db = 10 * np.log10(signal_power_final / noise_power)

    print("ç°å®è¯„ä¼°æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ:")
    print(f"  å›¾åƒå°ºå¯¸: {image_size}")
    print(f"  çœŸå®æ•£å°„ä¸­å¿ƒæ•°é‡: {len(true_scatterers)}")
    print(f"  ä¿¡å™ªæ¯”: {snr_db:.1f} dB")
    print(f"  ä¿¡å·å¹…åº¦èŒƒå›´: [{magnitude.min():.3f}, {magnitude.max():.3f}]")

    return magnitude, complex_image, true_scatterers


def evaluate_omp_core_capabilities():
    """è¯„ä¼°OMPç®—æ³•çš„æ ¸å¿ƒèƒ½åŠ›"""
    print("\n" + "=" * 60)
    print("OMPç®—æ³•æ ¸å¿ƒèƒ½åŠ›è¯„ä¼°")
    print("=" * 60)

    magnitude, complex_image, true_scatterers = create_realistic_test_data()

    # åˆå§‹åŒ–OMPç®—æ³•
    omp_asc = OMPASCFinal(n_scatterers=len(true_scatterers) + 3, use_cv=False)

    signal = omp_asc.preprocess_data(complex_image)
    dictionary, param_grid = omp_asc.build_dictionary(position_grid_size=12, phase_levels=6)
    results = omp_asc.extract_scatterers(signal)
    reconstructed = omp_asc.reconstruct_image(results["scatterers"])

    extracted_scatterers = results["scatterers"]

    print(f"\\n=== OMPç¨€ç–é‡æ„è¯„ä¼° ===")
    print(f"çœŸå®æ•£å°„ä¸­å¿ƒæ•°é‡: {len(true_scatterers)}")
    print(f"è®¾ç½®æå–æ•°é‡: {omp_asc.n_scatterers}")
    print(f"å®é™…æå–æ•°é‡: {len(extracted_scatterers)}")

    # 1. ç¨€ç–æ€§è¯„ä¼°
    sparsity_ratio = len(extracted_scatterers) / (dictionary.shape[1])
    print(f"ç¨€ç–æ¯”: {sparsity_ratio:.4f} ({len(extracted_scatterers)}/{dictionary.shape[1]})")

    # 2. é‡æ„è´¨é‡è¯„ä¼°
    mse = np.mean((magnitude - np.abs(reconstructed)) ** 2)
    max_val = np.max(magnitude)
    psnr = 20 * np.log10(max_val / np.sqrt(mse)) if mse > 0 else float("inf")

    print(f"\\n=== é‡æ„è´¨é‡è¯„ä¼° ===")
    print(f"PSNR: {psnr:.2f} dB")
    print(f"é‡æ„è¯¯å·®: {results['reconstruction_error']:.3f}")

    # 3. ä½ç½®æ£€æµ‹èƒ½åŠ›è¯„ä¼° (æ›´å®½æ¾çš„æ ‡å‡†)
    print(f"\\n=== ä½ç½®æ£€æµ‹èƒ½åŠ›è¯„ä¼° ===")

    # å®½æ¾åŒ¹é…ï¼šåªè¦åœ¨åˆç†è·ç¦»å†…å°±ç®—æ£€æµ‹åˆ°
    detected_positions = []
    for true_sc in true_scatterers:
        best_distance = float("inf")
        best_match = None

        for ext_sc in extracted_scatterers:
            pos_dist = np.sqrt((true_sc["x"] - ext_sc["x"]) ** 2 + (true_sc["y"] - ext_sc["y"]) ** 2)
            if pos_dist < best_distance:
                best_distance = pos_dist
                best_match = ext_sc

        if best_distance < 0.2:  # æ›´å®½æ¾çš„é˜ˆå€¼
            detected_positions.append({"true": true_sc, "detected": best_match, "distance": best_distance})

    detection_rate = len(detected_positions) / len(true_scatterers)
    print(f"ä½ç½®æ£€æµ‹ç‡: {detection_rate:.1%} ({len(detected_positions)}/{len(true_scatterers)})")

    if detected_positions:
        avg_pos_error = np.mean([d["distance"] for d in detected_positions])
        print(f"å¹³å‡ä½ç½®è¯¯å·®: {avg_pos_error:.3f} (å½’ä¸€åŒ–åæ ‡)")

    # 4. èƒ½é‡åˆ†å¸ƒåˆ†æ
    print(f"\\n=== èƒ½é‡åˆ†å¸ƒåˆ†æ ===")
    original_energy = np.linalg.norm(magnitude)
    reconstructed_energy = np.linalg.norm(np.abs(reconstructed))
    energy_preservation = reconstructed_energy / original_energy

    print(f"åŸå§‹ä¿¡å·èƒ½é‡: {original_energy:.3f}")
    print(f"é‡æ„ä¿¡å·èƒ½é‡: {reconstructed_energy:.3f}")
    print(f"èƒ½é‡ä¿æŒç‡: {energy_preservation:.1%}")

    # 5. æ•£å°„ä¸­å¿ƒå¼ºåº¦åˆ†æ
    print(f"\\n=== æ•£å°„ä¸­å¿ƒå¼ºåº¦åˆ†æ ===")
    estimated_amplitudes = [s["estimated_amplitude"] for s in extracted_scatterers]
    true_amplitudes = [s["amplitude"] for s in true_scatterers]

    print(f"ä¼°è®¡å¹…åº¦èŒƒå›´: [{min(estimated_amplitudes):.3f}, {max(estimated_amplitudes):.3f}]")
    print(f"çœŸå®å¹…åº¦èŒƒå›´: [{min(true_amplitudes):.3f}, {max(true_amplitudes):.3f}]")
    print(f"å¹…åº¦é‡çº§åŒ¹é…: {'âœ“' if max(estimated_amplitudes) > 0.1 * max(true_amplitudes) else 'âœ—'}")

    # æ€»ä½“è¯„ä¼°
    print(f"\\n=== OMPç®—æ³•æ€»ä½“è¯„ä¼° ===")

    criteria = {
        "ç¨€ç–é‡æ„èƒ½åŠ›": sparsity_ratio < 0.1,  # ç¨€ç–æ¯”å°äº10%
        "é‡æ„è´¨é‡": psnr > 30,  # PSNR > 30dB
        "ä½ç½®æ£€æµ‹èƒ½åŠ›": detection_rate >= 0.6,  # æ£€æµ‹ç‡ >= 60%
        "ä¿¡å·è¡¨ç¤ºèƒ½åŠ›": energy_preservation > 0.1,  # èƒ½é‡ä¿æŒ > 10%
    }

    passed_criteria = sum(criteria.values())
    total_criteria = len(criteria)

    for criterion, passed in criteria.items():
        status = "âœ“ é€šè¿‡" if passed else "âœ— å¤±è´¥"
        print(f"{criterion}: {status}")

    overall_score = passed_criteria / total_criteria
    print(f"\\næ€»ä½“è¯„åˆ†: {overall_score:.1%} ({passed_criteria}/{total_criteria})")

    if overall_score >= 0.75:
        print("\\nğŸ‰ OMPç®—æ³•è¡¨ç°ä¼˜ç§€ï¼é€‚åˆç”¨äºSARæ•£å°„ä¸­å¿ƒåˆæ­¥æå–ã€‚")
        print("å»ºè®®ï¼šåœ¨OMPåŸºç¡€ä¸Šæ·»åŠ åå¤„ç†æ­¥éª¤ä»¥æé«˜å‚æ•°ä¼°è®¡ç²¾åº¦ã€‚")
        conclusion = "ä¼˜ç§€"
    elif overall_score >= 0.5:
        print("\\nâœ… OMPç®—æ³•è¡¨ç°è‰¯å¥½ï¼ŒåŸºæœ¬æ»¡è¶³ç¨€ç–é‡æ„éœ€æ±‚ã€‚")
        print("å»ºè®®ï¼šå¯ä¼˜åŒ–å­—å…¸è®¾è®¡å’Œå‚æ•°è®¾ç½®è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚")
        conclusion = "è‰¯å¥½"
    else:
        print("\\nâš ï¸ OMPç®—æ³•è¡¨ç°éœ€è¦æ”¹è¿›ã€‚")
        print("å»ºè®®ï¼šæ£€æŸ¥ç®—æ³•å®ç°å’Œå‚æ•°è®¾ç½®ã€‚")
        conclusion = "éœ€è¦æ”¹è¿›"

    return {
        "overall_score": overall_score,
        "psnr": psnr,
        "detection_rate": detection_rate,
        "sparsity_ratio": sparsity_ratio,
        "energy_preservation": energy_preservation,
        "conclusion": conclusion,
    }


def compare_configurations():
    """æ¯”è¾ƒä¸åŒé…ç½®çš„æ€§èƒ½"""
    print("\\n" + "=" * 60)
    print("OMPç®—æ³•é…ç½®å¯¹æ¯”è¯„ä¼°")
    print("=" * 60)

    magnitude, complex_image, true_scatterers = create_realistic_test_data()

    configs = [
        {"name": "å¿«é€Ÿé…ç½®", "n_scatterers": 5, "position_grid": 8, "phase_levels": 4},
        {"name": "å¹³è¡¡é…ç½®", "n_scatterers": 8, "position_grid": 12, "phase_levels": 6},
        {"name": "ç²¾ç¡®é…ç½®", "n_scatterers": 10, "position_grid": 16, "phase_levels": 8},
    ]

    results = []

    for config in configs:
        print(f"\\næµ‹è¯•é…ç½®: {config['name']}")

        start_time = time.time()

        omp_asc = OMPASCFinal(n_scatterers=config["n_scatterers"], use_cv=False)
        signal = omp_asc.preprocess_data(complex_image)

        dictionary, param_grid = omp_asc.build_dictionary(
            position_grid_size=config["position_grid"], phase_levels=config["phase_levels"]
        )

        extraction_results = omp_asc.extract_scatterers(signal)
        reconstructed = omp_asc.reconstruct_image(extraction_results["scatterers"])

        end_time = time.time()

        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        mse = np.mean((magnitude - np.abs(reconstructed)) ** 2)
        psnr = 20 * np.log10(np.max(magnitude) / np.sqrt(mse))

        # ä½ç½®æ£€æµ‹ç‡
        detected = 0
        for true_sc in true_scatterers:
            min_dist = min(
                [
                    np.sqrt((true_sc["x"] - ext_sc["x"]) ** 2 + (true_sc["y"] - ext_sc["y"]) ** 2)
                    for ext_sc in extraction_results["scatterers"]
                ]
            )
            if min_dist < 0.2:
                detected += 1
        detection_rate = detected / len(true_scatterers)

        result = {
            "config": config["name"],
            "time": end_time - start_time,
            "psnr": psnr,
            "detection_rate": detection_rate,
            "dictionary_size": dictionary.shape[1],
            "extracted_count": len(extraction_results["scatterers"]),
        }
        results.append(result)

        print(f"  å¤„ç†æ—¶é—´: {result['time']:.2f}s")
        print(f"  å­—å…¸å¤§å°: {result['dictionary_size']}")
        print(f"  PSNR: {result['psnr']:.2f} dB")
        print(f"  æ£€æµ‹ç‡: {result['detection_rate']:.1%}")

    # æ˜¾ç¤ºå¯¹æ¯”æ€»ç»“
    print(f"\\né…ç½®å¯¹æ¯”æ€»ç»“:")
    print("-" * 80)
    print(f"{'é…ç½®':<10} {'æ—¶é—´(s)':<10} {'PSNR(dB)':<10} {'æ£€æµ‹ç‡':<10} {'å­—å…¸å¤§å°':<10} {'æå–æ•°':<10}")
    print("-" * 80)
    for result in results:
        print(
            f"{result['config']:<10} {result['time']:<10.2f} {result['psnr']:<10.2f} "
            f"{result['detection_rate']:<10.1%} {result['dictionary_size']:<10} {result['extracted_count']:<10}"
        )

    return results


def main():
    """ä¸»è¯„ä¼°å‡½æ•°"""
    print("ğŸ¯ OMP SARæ•£å°„ä¸­å¿ƒæå–ç®—æ³• - ç°å®èƒ½åŠ›è¯„ä¼°")
    print("=" * 60)
    print("ä¸“æ³¨äºOMPç®—æ³•çš„å®é™…èƒ½åŠ›ï¼šç¨€ç–é‡æ„ã€ä½ç½®æ£€æµ‹ã€ä¿¡å·è¡¨ç¤º")
    print("=" * 60)

    # è¯„ä¼°1: æ ¸å¿ƒèƒ½åŠ›
    core_evaluation = evaluate_omp_core_capabilities()

    # è¯„ä¼°2: é…ç½®å¯¹æ¯”
    config_comparison = compare_configurations()

    # æœ€ç»ˆç»“è®º
    print("\\n" + "=" * 60)
    print("æœ€ç»ˆè¯„ä¼°ç»“è®º")
    print("=" * 60)

    print(f"ğŸ¯ **OMPç®—æ³•æ ¸å¿ƒèƒ½åŠ›**: {core_evaluation['conclusion']}")
    print(f"   - é‡æ„è´¨é‡: {core_evaluation['psnr']:.1f} dB")
    print(f"   - ä½ç½®æ£€æµ‹ç‡: {core_evaluation['detection_rate']:.1%}")
    print(f"   - ç¨€ç–è¡¨ç¤º: {core_evaluation['sparsity_ratio']:.3f}")

    print(f"\\nğŸ’¡ **åº”ç”¨å»ºè®®**:")
    if core_evaluation["overall_score"] >= 0.75:
        print("   âœ… OMPç®—æ³•å·²å‡†å¤‡ç”¨äºå®é™…MSTARæ•°æ®å¤„ç†")
        print("   âœ… å¯ä½œä¸ºæ•£å°„ä¸­å¿ƒæå–çš„ç¬¬ä¸€é˜¶æ®µï¼ˆç²—æå–ï¼‰")
        print("   âœ… å»ºè®®ç»“åˆåå¤„ç†è¿›è¡Œç²¾ç¡®å‚æ•°ä¼°è®¡")
    else:
        print("   âš ï¸ å»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–ç®—æ³•å‚æ•°")
        print("   âš ï¸ è€ƒè™‘è°ƒæ•´å­—å…¸è®¾è®¡æˆ–ç¨€ç–åº¦è®¾ç½®")

    print(f"\\nğŸš€ **å®é™…éƒ¨ç½²**: æ¨èä½¿ç”¨'å¹³è¡¡é…ç½®'è¿›è¡Œå®é™…æ•°æ®å¤„ç†")

    return core_evaluation, config_comparison


if __name__ == "__main__":
    core_eval, config_comp = main()
